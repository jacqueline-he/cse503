{"task_id": 511, "text": "Write a python function to find minimum sum of factors of a given number.", "code": "def find_Min_Sum(num): \r\n    sum = 0\r\n    i = 2\r\n    while(i * i <= num): \r\n        while(num % i == 0): \r\n            sum += i \r\n            num /= i \r\n        i += 1\r\n    sum += num \r\n    return sum", "test_list": ["assert find_Min_Sum(12) == 7", "assert find_Min_Sum(105) == 15", "assert find_Min_Sum(2) == 2"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6844564"}, {"id": "20209", "text": "Function: python.library.fractions#fractions.Fraction.numerator\nSnippet: numerator Numerator of the Fraction in lowest term.", "score": "0.6608285"}, {"id": "18118", "text": "Function: python.library.audioop#audioop.findfactor\nSnippet: audioop.findfactor(fragment, reference) Return a factor F such that rms(add(fragment, mul(reference, -F))) is minimal, i.e., return the factor with which you should multiply reference to make it match as well as possible to fragment. The fragments should both contain 2-byte samples. The time taken by this routine is proportional to len(fragment).", "score": "0.66049993"}, {"id": "13013", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos#sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.65147144"}, {"id": "20205", "text": "Function: python.library.fractions#fractions.Fraction.denominator\nSnippet: denominator Denominator of the Fraction in lowest term.", "score": "0.6506967"}]}
{"task_id": 512, "text": "Write a function to count the element frequency in the mixed nested tuple.", "code": "def flatten(test_tuple): \r\n\tfor tup in test_tuple: \r\n\t\tif isinstance(tup, tuple): \r\n\t\t\tyield from flatten(tup) \r\n\t\telse: \r\n\t\t\tyield tup \r\ndef count_element_freq(test_tuple):\r\n  res = {}\r\n  for ele in flatten(test_tuple):\r\n    if ele not in res:\r\n      res[ele] = 0\r\n    res[ele] += 1\r\n  return (res) ", "test_list": ["assert count_element_freq((5, 6, (5, 6), 7, (8, 9), 9) ) == {5: 2, 6: 2, 7: 1, 8: 1, 9: 2}", "assert count_element_freq((6, 7, (6, 7), 8, (9, 10), 10) ) == {6: 2, 7: 2, 8: 1, 9: 1, 10: 2}", "assert count_element_freq((7, 8, (7, 8), 9, (10, 11), 11) ) == {7: 2, 8: 2, 9: 1, 10: 1, 11: 2}"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "22306", "text": "Function: python.library.operator#operator.countOf\nSnippet: operator.countOf(a, b) Return the number of occurrences of b in a.", "score": "0.70282906"}, {"id": "14927", "text": "Function: pandas.reference.api.pandas.period.freq\nSnippet: pandas.Period.freq Period.freq", "score": "0.6968256"}, {"id": "24342", "text": "Function: python.library.stdtypes#str.count\nSnippet: str.count(sub[, start[, end]]) Return the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation.", "score": "0.69644064"}, {"id": "17632", "text": "Function: python.library.array#array.array.count\nSnippet: array.count(x) Return the number of occurrences of x in the array.", "score": "0.6938086"}, {"id": "7402", "text": "Function: torch.generated.torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence.count\nSnippet: count() Return number of occurrences of value.", "score": "0.6893468"}]}
{"task_id": 513, "text": "Write a function to convert tuple into list by adding the given string after every element.", "code": "def add_str(test_tup, K):\r\n  res = [ele for sub in test_tup for ele in (sub, K)]\r\n  return (res) ", "test_list": ["assert add_str((5, 6, 7, 4, 9) , \"FDF\") == [5, 'FDF', 6, 'FDF', 7, 'FDF', 4, 'FDF', 9, 'FDF']", "assert add_str((7, 8, 9, 10) , \"PF\") == [7, 'PF', 8, 'PF', 9, 'PF', 10, 'PF']", "assert add_str((11, 14, 12, 1, 4) , \"JH\") == [11, 'JH', 14, 'JH', 12, 'JH', 1, 'JH', 4, 'JH']"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "17646", "text": "Function: python.library.array#array.array.tolist\nSnippet: array.tolist() Convert the array to an ordinary list with the same items.", "score": "0.69080776"}, {"id": "42756", "text": "Function: numpy.reference.distutils.misc_util#numpy.distutils.misc_util.as_list\nSnippet: numpy.distutils.misc_util.as_list(seq)[source]", "score": "0.66675574"}, {"id": "20295", "text": "Function: python.library.functions\nSnippet: aggregates elements from each of the iterables. Returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. The iterator stops when the shortest input iterable is exhausted. With a single iterable argument, it returns an iterator of 1-tuples. With no arguments, it returns an empty iterator. Equivalent to: def zip(*iterables): # zip('ABCD', 'xy') --> Ax By sentinel = object() iterators = [iter(it) for it in iterables] while iterators: result = [] for it in iterators: elem = next(it, sentinel) if elem is sentinel: return result.append(elem) yield tuple(result) The left-to-right evaluation order of the iterables is guaranteed. This makes possible an idiom for clustering a data series into n-length groups using zip(*[iter(s)]*n). This repeats the same iterator n times so that each output tuple has the result of n calls to the iterator. This has the effect of dividing the input into n-length chunks. zip() should only be used with unequal length inputs when you don’t care about trailing, unmatched values from the longer iterables. If those values are important, use itertools.zip_longest() instead. zip() in conjunction with the * operator can be used to unzip a list: >>> x = [1, 2, 3] >>> y = [4, 5, 6] >>> zipped = zip(x, y) >>> list(zipped) [(1, 4), (2, 5), (3, 6)] >>> x2, y2 = zip(*zip(x, y)) >>> x == list(x2) and y == list(y2) True __import__(name, globals=None, locals=None, fromlist=(), level=0) Note This is an advanced function that is not needed in everyday Python programming, unlike importlib.import_module(). This function is invoked by the import statement. It can be replaced (by importing the builtins module and assigning to builtins.__import__) in order to change semantics of the import statement, but doing so is strongly discouraged as it is usually simpler to use import hooks (see PEP 302) to attain the same goals and does not cause issues with code which assumes the default import implementation is in use. Direct use of __import__() is also discouraged in favor of importlib.import_module(). The function imports the module name, potentially using the given globals and locals to determine how to interpret the name in a package context. The fromlist gives the names of objects or submodules that should be imported from the module given by name. The standard implementation does not use its locals argument at all, and uses its globals only to determine the package context of the import statement. level specifies whether to use absolute or relative imports. 0 (the default) means only perform absolute imports. Positive values for level indicate the number of parent directories to search relative to the directory of the module calling __import__() (see PEP 328 for the details). When the name variable is of the form package.module, normally, the top-level package (the name up till the first dot) is returned, not the module named by name. However, when a non-empty fromlist argument is given, the module named by name is returned. For example, the statement import spam results", "score": "0.6579176"}, {"id": "25737", "text": "Function: python.library.stdtypes\nSnippet: a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below: if concatenating str objects, you can build a list and use str.join() at the end or else write to an io.StringIO instance and retrieve its value when complete if concatenating bytes objects, you can similarly use bytes.join() or io.BytesIO, or you can do in-place concatenation with a bytearray object. bytearray objects are mutable and have an efficient overallocation mechanism if concatenating tuple objects, extend a list instead for other types, investigate the relevant class documentation Some sequence types (such as range) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition. index raises ValueError when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using s[i:j].index(x), only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. Immutable Sequence Types The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the hash() built-in. This support allows immutable sequences, such as tuple instances, to be used as dict keys and stored in set and frozenset instances. Attempting to hash an immutable sequence that contains unhashable values will result in TypeError. Mutable Sequence Types The operations in the following table are defined on mutable sequence types. The collections.abc.MutableSequence ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, bytearray only accepts integers that meet the value restriction 0 <= x <= 255). Operation Result Notes s[i] = x item i of s is replaced by x s[i:j] = t slice of s from i to j is replaced by the contents of the iterable t del s[i:j] same as s[i:j] = [] s[i:j:k] = t the elements of s[i:j:k] are replaced by those of t (1) del s[i:j:k] removes the elements of s[i:j:k] from the list s.append(x) appends x to the end of the sequence (same as s[len(s):len(s)] = [x]) s.clear() removes all items from s (same as del s[:]) (5) s.copy() creates a shallow copy of s (same as s[:]) (5) s.extend(t) or s += t extends s with the contents of t (for the most part the same as s[len(s):len(s)] = t) s *= n updates s with its contents repeated n times (6) s.insert(i, x) inserts x into s at the index given by i (same as s[i:i] = [x]) s.pop([i]) retrieves the item at i and also removes it", "score": "0.65754026"}, {"id": "17774", "text": "Function: python.library.ast#ast.Tuple\nSnippet: class ast.List(elts, ctx) class ast.Tuple(elts, ctx) A list or tuple. elts holds a list of nodes representing the elements. ctx is Store if the container is an assignment target (i.e. (x,y)=something), and Load otherwise. >>> print(ast.dump(ast.parse('[1, 2, 3]', mode='eval'), indent=4)) Expression( body=List( elts=[ Constant(value=1), Constant(value=2), Constant(value=3)], ctx=Load())) >>> print(ast.dump(ast.parse('(1, 2, 3)', mode='eval'), indent=4)) Expression( body=Tuple( elts=[ Constant(value=1), Constant(value=2), Constant(value=3)], ctx=Load()))", "score": "0.65611875"}]}
{"task_id": 514, "text": "Write a function to find the summation of tuple elements in the given tuple list.", "code": "def sum_elements(test_tup):\r\n  res = sum(list(test_tup))\r\n  return (res) ", "test_list": ["assert sum_elements((7, 8, 9, 1, 10, 7)) == 42", "assert sum_elements((1, 2, 3, 4, 5, 6)) == 21", "assert sum_elements((11, 12 ,13 ,45, 14)) == 95"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.7254942"}, {"id": "21289", "text": "Function: python.library.itertools\nSnippet: AD BB BC BD CC CD DD Itertool functions The following module functions all construct and return iterators. Some provide streams of infinite length, so they should only be accessed by functions or loops that truncate the stream. itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter. itertools.chain(*iterables) Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the", "score": "0.7210939"}, {"id": "24549", "text": "Function: python.library.functions#sum\nSnippet: sum(iterable, /, start=0) Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument.", "score": "0.7072035"}, {"id": "43881", "text": "Function: numpy.reference.generated.numpy.recarray.sum\nSnippet: numpy.recarray.sum method recarray.sum(axis=None, dtype=None, out=None, keepdims=False, initial=0, where=True) Return the sum of the array elements over the given axis. Refer to numpy.sum for full documentation. See also numpy.sum equivalent function", "score": "0.68690073"}, {"id": "42345", "text": "Function: numpy.reference.generated.numpy.ma.sum\nSnippet: numpy.ma.sum ma.sum(self, axis=None, dtype=None, out=None, keepdims=<no value>) = <numpy.ma.core._frommethod object> Return the sum of the array elements over the given axis. Masked elements are set to 0 internally. Refer to numpy.sum for full documentation. See also numpy.ndarray.sum corresponding function for ndarrays numpy.sum equivalent function Examples >>> x = np.ma.array([[1,2,3],[4,5,6],[7,8,9]], mask=[0] + [1,0]*4) >>> x masked_array( data=[[1, --, 3], [--, 5, --], [7, --, 9]], mask=[[False, True, False], [ True, False, True], [False, True, False]], fill_value=999999) >>> x.sum() 25 >>> x.sum(axis=1) masked_array(data=[4, 5, 16], mask=[False, False, False], fill_value=999999) >>> x.sum(axis=0) masked_array(data=[8, 5, 12], mask=[False, False, False], fill_value=999999) >>> print(type(x.sum(axis=0, dtype=np.int64)[0])) <class 'numpy.int64'>", "score": "0.68583405"}]}
{"task_id": 515, "text": "Write a function to check if there is a subset with sum divisible by m.", "code": "def modular_sum(arr, n, m): \r\n\tif (n > m): \r\n\t\treturn True\r\n\tDP = [False for i in range(m)] \r\n\tfor i in range(n): \r\n\t\tif (DP[0]): \r\n\t\t\treturn True\r\n\t\ttemp = [False for i in range(m)] \r\n\t\tfor j in range(m): \r\n\t\t\tif (DP[j] == True): \r\n\t\t\t\tif (DP[(j + arr[i]) % m] == False): \r\n\t\t\t\t\ttemp[(j + arr[i]) % m] = True\r\n\t\tfor j in range(m): \r\n\t\t\tif (temp[j]): \r\n\t\t\t\tDP[j] = True\r\n\t\tDP[arr[i] % m] = True\r\n\treturn DP[0]", "test_list": ["assert modular_sum([3, 1, 7, 5], 4, 6) == True", "assert modular_sum([1, 7], 2, 5) == False", "assert modular_sum([1, 6], 2, 5) == False"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21774", "text": "Function: python.library.math\nSnippet: m is a float and e is an integer such that x == m * 2**e exactly. If x is zero, returns (0.0, 0), otherwise 0.5 <= abs(m) < 1. This is used to “pick apart” the internal representation of a float in a portable way. math.fsum(iterable) Return an accurate floating point sum of values in the iterable. Avoids loss of precision by tracking multiple intermediate partial sums: >>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]) 0.9999999999999999 >>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]) 1.0 The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the typical case where the rounding mode is half-even. On some non-Windows builds, the underlying C library uses extended precision addition and may occasionally double-round an intermediate sum causing it to be off in its least significant bit. For further discussion and two alternative approaches, see the ASPN cookbook recipes for accurate floating point summation. math.gcd(*integers) Return the greatest common divisor of the specified integer arguments. If any of the arguments is nonzero, then the returned value is the largest positive integer that is a divisor of all arguments. If all arguments are zero, then the returned value is 0. gcd() without arguments returns 0. New in version 3.5. Changed in version 3.9: Added support for an arbitrary number of arguments. Formerly, only two arguments were supported. math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0) Return True if the values a and b are close to each other and False otherwise. Whether or not two values are considered close is determined according to given absolute and relative tolerances. rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be greater than zero. abs_tol is the minimum absolute tolerance – useful for comparisons near zero. abs_tol must be at least zero. If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol). The IEEE 754 special values of NaN, inf, and -inf will be handled according to IEEE rules. Specifically, NaN is not considered close to any other value, including NaN. inf and -inf are only considered close to themselves. New in version 3.5. See also PEP 485 – A function for testing approximate equality math.isfinite(x) Return True if x is neither an infinity nor a NaN, and False otherwise. (Note that 0.0 is considered finite.) New in version 3.2. math.isinf(x) Return True if x is a positive or negative infinity, and False otherwise. math.isnan(x) Return True if x is a NaN (not a number), and False otherwise. math.isqrt(n) Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or equivalently the greatest integer a such that a² ≤ n. For", "score": "0.6666946"}, {"id": "25734", "text": "Function: python.library.stdtypes\nSnippet: in detail: If x = m / n is a nonnegative rational number and n is not divisible by P, define hash(x) as m * invmod(n, P) % P, where invmod(n, P) gives the inverse of n modulo P. If x = m / n is a nonnegative rational number and n is divisible by P (but m is not) then n has no inverse modulo P and the rule above doesn’t apply; in this case define hash(x) to be the constant value sys.hash_info.inf. If x = m / n is a negative rational number define hash(x) as -hash(-x). If the resulting hash is -1, replace it with -2. The particular values sys.hash_info.inf, -sys.hash_info.inf and sys.hash_info.nan are used as hash values for positive infinity, negative infinity, or nans (respectively). (All hashable nans have the same hash value.) For a complex number z, the hash values of the real and imaginary parts are combined by computing hash(z.real) + sys.hash_info.imag * hash(z.imag), reduced modulo 2**sys.hash_info.width so that it lies in range(-2**(sys.hash_info.width - 1), 2**(sys.hash_info.width - 1)). Again, if the result is -1, it’s replaced with -2. To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash of a rational number, float, or complex: import sys, math def hash_fraction(m, n): \"\"\"Compute the hash of a rational number m / n. Assumes m and n are integers, with n positive. Equivalent to hash(fractions.Fraction(m, n)). \"\"\" P = sys.hash_info.modulus # Remove common factors of P. (Unnecessary if m and n already coprime.) while m % P == n % P == 0: m, n = m // P, n // P if n % P == 0: hash_value = sys.hash_info.inf else: # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P. hash_value = (abs(m) % P) * pow(n, P - 2, P) % P if m < 0: hash_value = -hash_value if hash_value == -1: hash_value = -2 return hash_value def hash_float(x): \"\"\"Compute the hash of a float x.\"\"\" if math.isnan(x): return sys.hash_info.nan elif math.isinf(x): return sys.hash_info.inf if x > 0 else -sys.hash_info.inf else: return hash_fraction(*x.as_integer_ratio()) def hash_complex(z): \"\"\"Compute the hash of a complex number z.\"\"\" hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag) # do a signed reduction modulo 2**sys.hash_info.width M = 2**(sys.hash_info.width - 1) hash_value = (hash_value & (M - 1)) - (hash_value & M) if hash_value == -1: hash_value = -2 return hash_value Iterator Types Python supports a concept of iteration over containers. This is implemented using two distinct methods; these are used to allow user-defined classes to support iteration. Sequences, described below in more detail, always support the iteration methods. One method needs to be defined for container objects to provide iteration support: container.__iter__() Return an iterator object. The object is required to support the iterator protocol described below. If a container supports different types of iteration, additional methods can be provided to specifically request iterators for those iteration types. (An example", "score": "0.6594112"}, {"id": "25766", "text": "Function: python.library.stdtypes\nSnippet: is less than another set if and only if the first set is a proper subset of the second set (is a subset, but is not equal). A set is greater than another set if and only if the first set is a proper superset of the second set (is a superset, but is not equal). Instances of set are compared to instances of frozenset based on their members. For example, set('abc') == frozenset('abc') returns True and so does set('abc') in set([frozenset('abc')]). The subset and equality comparisons do not generalize to a total ordering function. For example, any two nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return False: a<b, a==b, or a>b. Since sets only define partial ordering (subset relationships), the output of the list.sort() method is undefined for lists of sets. Set elements, like dictionary keys, must be hashable. Binary operations that mix set instances with frozenset return the type of the first operand. For example: frozenset('ab') | set('bc') returns an instance of frozenset. The following table lists operations available for set that do not apply to immutable instances of frozenset: update(*others) set |= other | ... Update the set, adding elements from all others. intersection_update(*others) set &= other & ... Update the set, keeping only elements found in it and all others. difference_update(*others) set -= other | ... Update the set, removing elements found in others. symmetric_difference_update(other) set ^= other Update the set, keeping only elements found in either set, but not in both. add(elem) Add element elem to the set. remove(elem) Remove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem) Remove element elem from the set if it is present. pop() Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear() Remove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(), and symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To support searching for an equivalent frozenset, a temporary one is created from elem. Mapping Types — dict A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and the collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictionaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (such as 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. (Note however, that since computers store floating-point numbers as approximations it is usually unwise to use them as dictionary keys.) Dictionaries can", "score": "0.65585625"}, {"id": "20225", "text": "Function: python.library.stdtypes#frozenset.issubset\nSnippet: issubset(other) set <= other Test whether every element in the set is in other.", "score": "0.6359162"}, {"id": "23564", "text": "Function: python.library.stdtypes#set\nSnippet: and are not subsets of each other, so all of the following return False: a<b, a==b, or a>b. Since sets only define partial ordering (subset relationships), the output of the list.sort() method is undefined for lists of sets. Set elements, like dictionary keys, must be hashable. Binary operations that mix set instances with frozenset return the type of the first operand. For example: frozenset('ab') | set('bc') returns an instance of frozenset. The following table lists operations available for set that do not apply to immutable instances of frozenset: update(*others) set |= other | ... Update the set, adding elements from all others. intersection_update(*others) set &= other & ... Update the set, keeping only elements found in it and all others. difference_update(*others) set -= other | ... Update the set, removing elements found in others. symmetric_difference_update(other) set ^= other Update the set, keeping only elements found in either set, but not in both. add(elem) Add element elem to the set. remove(elem) Remove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem) Remove element elem from the set if it is present. pop() Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear() Remove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(), and symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To support searching for an equivalent frozenset, a temporary one is created from elem.", "score": "0.62881947"}]}
{"task_id": 516, "text": "Write a function to sort a list of elements using radix sort.", "code": "def radix_sort(nums):\r\n    RADIX = 10\r\n    placement = 1\r\n    max_digit = max(nums)\r\n\r\n    while placement < max_digit:\r\n      buckets = [list() for _ in range( RADIX )]\r\n      for i in nums:\r\n        tmp = int((i / placement) % RADIX)\r\n        buckets[tmp].append(i)\r\n      a = 0\r\n      for b in range( RADIX ):\r\n        buck = buckets[b]\r\n        for i in buck:\r\n          nums[a] = i\r\n          a += 1\r\n      placement *= RADIX\r\n    return nums", "test_list": ["assert radix_sort([15, 79, 25, 68, 37]) == [15, 25, 37, 68, 79]", "assert radix_sort([9, 11, 8, 7, 3, 2]) == [2, 3, 7, 8, 9, 11]", "assert radix_sort([36, 12, 24, 26, 29]) == [12, 24, 26, 29, 36]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43196", "text": "Function: numpy.reference.generated.numpy.sort\nSnippet: sorted. It, along with ‘mergesort’ is currently mapped to timsort or radix sort depending on the data type. API forward compatibility currently limits the ability to select the implementation and it is hardwired for the different data types. New in version 1.17.0. Timsort is added for better performance on already or nearly sorted data. On random data timsort is almost identical to mergesort. It is now used for stable sort while quicksort is still the default sort if none is chosen. For timsort details, refer to CPython listsort.txt. ‘mergesort’ and ‘stable’ are mapped to radix sort for integer data types. Radix sort is an O(n) sort instead of O(n log n). Changed in version 1.18.0. NaT now sorts to the end of arrays for consistency with NaN. Examples >>> a = np.array([[1,4],[3,1]]) >>> np.sort(a) # sort along the last axis array([[1, 4], [1, 3]]) >>> np.sort(a, axis=None) # sort the flattened array array([1, 1, 3, 4]) >>> np.sort(a, axis=0) # sort along the first axis array([[1, 1], [3, 4]]) Use the order keyword to specify a field to use when sorting a structured array: >>> dtype = [('name', 'S10'), ('height', float), ('age', int)] >>> values = [('Arthur', 1.8, 41), ('Lancelot', 1.9, 38), ... ('Galahad', 1.7, 38)] >>> a = np.array(values, dtype=dtype) # create a structured array >>> np.sort(a, order='height') array([('Galahad', 1.7, 38), ('Arthur', 1.8, 41), ('Lancelot', 1.8999999999999999, 38)], dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')]) Sort by age, then height if ages are equal: >>> np.sort(a, order=['age', 'height']) array([('Galahad', 1.7, 38), ('Lancelot', 1.8999999999999999, 38), ('Arthur', 1.8, 41)], dtype=[('name', '|S10'), ('height', '<f8'), ('age', '<i4')])", "score": "0.70924354"}, {"id": "21358", "text": "Function: python.library.stdtypes#list.sort\nSnippet: sort(*, key=None, reverse=False) This method sorts the list in place, using only < comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). sort() accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value. The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function. reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use sorted() to explicitly request a new sorted list instance). The sort() method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting HOW TO. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises ValueError if it can detect that the list has been mutated during a sort.", "score": "0.7020438"}, {"id": "42341", "text": "Function: numpy.reference.generated.numpy.ma.sort\nSnippet: numpy.ma.sort ma.sort(a, axis=- 1, kind=None, order=None, endwith=True, fill_value=None)[source] Return a sorted copy of the masked array. Equivalent to creating a copy of the array and applying the MaskedArray sort() method. Refer to MaskedArray.sort for the full documentation See also MaskedArray.sort equivalent method", "score": "0.6946104"}, {"id": "43940", "text": "Function: numpy.reference.generated.numpy.record.sort\nSnippet: numpy.record.sort method record.sort() Scalar method identical to the corresponding array attribute. Please see ndarray.sort.", "score": "0.6898304"}, {"id": "43832", "text": "Function: numpy.reference.generated.numpy.recarray.argsort\nSnippet: numpy.recarray.argsort method recarray.argsort(axis=- 1, kind=None, order=None) Returns the indices that would sort this array. Refer to numpy.argsort for full documentation. See also numpy.argsort equivalent function", "score": "0.6879813"}]}
{"task_id": 517, "text": "Write a python function to find the largest postive number from the given list.", "code": "def largest_pos(list1): \r\n    max = list1[0] \r\n    for x in list1: \r\n        if x > max : \r\n             max = x  \r\n    return max", "test_list": ["assert largest_pos([1,2,3,4,-1]) == 4", "assert largest_pos([0,1,2,-5,-1,6]) == 6", "assert largest_pos([0,0,1,0]) == 1"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21837", "text": "Function: python.library.functions#max\nSnippet: max(iterable, *[, key, default]) max(arg1, arg2, *args[, key]) Return the largest item in an iterable or the largest of two or more arguments. If one positional argument is provided, it should be an iterable. The largest item in the iterable is returned. If two or more positional arguments are provided, the largest of the positional arguments is returned. There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function like that used for list.sort(). The default argument specifies an object to return if the provided iterable is empty. If the iterable is empty and default is not provided, a ValueError is raised. If multiple items are maximal, the function returns the first one encountered. This is consistent with other sort-stability preserving tools such as sorted(iterable, key=keyfunc, reverse=True)[0] and heapq.nlargest(1, iterable, key=keyfunc). New in version 3.4: The default keyword-only argument. Changed in version 3.8: The key can be None.", "score": "0.7058572"}, {"id": "19490", "text": "Function: python.library.decimal#decimal.Context.max\nSnippet: max(x, y) Compares two values numerically and returns the maximum.", "score": "0.6775765"}, {"id": "19496", "text": "Function: python.library.decimal#decimal.Context.next_minus\nSnippet: next_minus(x) Returns the largest representable number smaller than x.", "score": "0.676857"}, {"id": "20488", "text": "Function: python.library.heapq#heapq.nlargest\nSnippet: heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n].", "score": "0.67384994"}, {"id": "15240", "text": "Function: pandas.reference.api.pandas.series.nlargest\nSnippet: pandas.Series.nlargest Series.nlargest(n=5, keep='first')[source] Return the largest n elements. Parameters n:int, default 5 Return this many descending sorted values. keep:{‘first’, ‘last’, ‘all’}, default ‘first’ When there are duplicate values that cannot all fit in a Series of n elements: first : return the first n occurrences in order of appearance. last : return the last n occurrences in reverse order of appearance. all : keep all occurrences. This can result in a Series of size larger than n. Returns Series The n largest values in the Series, sorted in decreasing order. See also Series.nsmallest Get the n smallest elements. Series.sort_values Sort Series by values. Series.head Return the first n rows. Notes Faster than .sort_values(ascending=False).head(n) for small n relative to the size of the Series object. Examples >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000, ... \"Malta\": 434000, \"Maldives\": 434000, ... \"Brunei\": 434000, \"Iceland\": 337000, ... \"Nauru\": 11300, \"Tuvalu\": 11300, ... \"Anguilla\": 11300, \"Montserrat\": 5200} >>> s = pd.Series(countries_population) >>> s Italy 59000000 France 65000000 Malta 434000 Maldives 434000 Brunei 434000 Iceland 337000 Nauru 11300 Tuvalu 11300 Anguilla 11300 Montserrat 5200 dtype: int64 The n largest elements where n=5 by default. >>> s.nlargest() France 65000000 Italy 59000000 Malta 434000 Maldives 434000 Brunei 434000 dtype: int64 The n largest elements where n=3. Default keep value is ‘first’ so Malta will be kept. >>> s.nlargest(3) France 65000000 Italy 59000000 Malta 434000 dtype: int64 The n largest elements where n=3 and keeping the last duplicates. Brunei will be kept since it is the last with value 434000 based on the index order. >>> s.nlargest(3, keep='last') France 65000000 Italy 59000000 Brunei 434000 dtype: int64 The n largest elements where n=3 with all duplicates kept. Note that the returned Series has five elements due to the three duplicates. >>> s.nlargest(3, keep='all') France 65000000 Italy 59000000 Malta 434000 Maldives 434000 Brunei 434000 dtype: int64", "score": "0.66499525"}]}
{"task_id": 518, "text": "Write a function to find the square root of a perfect number.", "code": "import math\r\ndef sqrt_root(num):\r\n sqrt_root = math.pow(num, 0.5)\r\n return sqrt_root ", "test_list": ["assert sqrt_root(4)==2", "assert sqrt_root(16)==4", "assert sqrt_root(400)==20"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21831", "text": "Function: python.library.math#math.sqrt\nSnippet: math.sqrt(x) Return the square root of x.", "score": "0.75534636"}, {"id": "19570", "text": "Function: python.library.decimal#decimal.Decimal.sqrt\nSnippet: sqrt(context=None) Return the square root of the argument to full precision.", "score": "0.7186128"}, {"id": "19511", "text": "Function: python.library.decimal#decimal.Context.sqrt\nSnippet: sqrt(x) Square root of a non-negative number to context precision.", "score": "0.7031133"}, {"id": "21812", "text": "Function: python.library.math#math.isqrt\nSnippet: math.isqrt(n) Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or equivalently the greatest integer a such that a² ≤ n. For some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8.", "score": "0.69582915"}, {"id": "18484", "text": "Function: python.library.cmath#cmath.sqrt\nSnippet: cmath.sqrt(x) Return the square root of x. This has the same branch cut as log().", "score": "0.6951681"}]}
{"task_id": 519, "text": "Write a function to calculate volume of a tetrahedron.", "code": "import math\r\ndef volume_tetrahedron(num):\r\n\tvolume = (num ** 3 / (6 * math.sqrt(2)))\t\r\n\treturn round(volume, 2)", "test_list": ["assert volume_tetrahedron(10)==117.85", "assert volume_tetrahedron(15)==397.75", "assert volume_tetrahedron(20)==942.81"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43169", "text": "Function: numpy.reference.generated.numpy.savetxt\nSnippet: delimiter=',') # X is an array >>> np.savetxt('test.out', (x,y,z)) # x,y,z equal sized 1D arrays >>> np.savetxt('test.out', x, fmt='%1.4e') # use exponential notation", "score": "0.6355597"}, {"id": "42696", "text": "Function: numpy.reference.arrays.scalars#numpy.clongfloat\nSnippet: numpy.clongfloat[source] alias of numpy.clongdouble", "score": "0.6318505"}, {"id": "36544", "text": "Function: django.ref.contrib.gis.gdal#django.contrib.gis.gdal.OGRGeometry.tuple\nSnippet: tuple", "score": "0.6315607"}, {"id": "42994", "text": "Function: numpy.reference.arrays.scalars#numpy.longcomplex\nSnippet: numpy.longcomplex[source] alias of numpy.clongdouble", "score": "0.63144296"}, {"id": "33502", "text": "Function: matplotlib._as_gen.matplotlib.quiver.quiver#matplotlib.quiver.Quiver.quiver_doc\nSnippet: symbolize a quantity that is not based on\\n *X*, *Y* data coordinates.\\n\\n - 'xy': Arrows point from (x, y) to (x+u, y+v).\\n Use this for plotting a gradient field, for example.\\n\\n - Alternatively, arbitrary angles may be specified explicitly as an array\\n of values in degrees, counter-clockwise from the horizontal axis.\\n\\n In this case *U*, *V* is only used to determine the length of the\\n arrows.\\n\\n Note: inverting a data axis will correspondingly invert the\\n arrows only with ``angles='xy'``.\\n\\nscale : float, optional\\n Number of data units per arrow length unit, e.g., m/s per plot width; a\\n smaller scale parameter makes the arrow longer. Default is *None*.\\n\\n If *None*, a simple autoscaling algorithm is used, based on the average\\n vector length and the number of vectors. The arrow length unit is given by\\n the *scale_units* parameter.\\n\\nscale_units : {'width', 'height', 'dots', 'inches', 'x', 'y', 'xy'}, optional\\n If the *scale* kwarg is *None*, the arrow length unit. Default is *None*.\\n\\n e.g. *scale_units* is 'inches', *scale* is 2.0, and ``(u, v) = (1, 0)``,\\n then the vector will be 0.5 inches long.\\n\\n If *scale_units* is 'width' or 'height', then the vector will be half the\\n width/height of the axes.\\n\\n If *scale_units* is 'x' then the vector will be 0.5 x-axis\\n units. To plot vectors in the x-y plane, with u and v having\\n the same units as x and y, use\\n ``angles='xy', scale_units='xy', scale=1``.\\n\\nwidth : float, optional\\n Shaft width in arrow units; default depends on choice of units,\\n above, and number of vectors; a typical starting value is about\\n 0.005 times the width of the plot.\\n\\nheadwidth : float, default: 3\\n Head width as multiple of shaft width.\\n\\nheadlength : float, default: 5\\n Head length as multiple of shaft width.\\n\\nheadaxislength : float, default: 4.5\\n Head length at shaft intersection.\\n\\nminshaft : float, default: 1\\n Length below which arrow scales, in units of head length. Do not\\n set this to less than 1, or small arrows will look terrible!\\n\\nminlength : float, default: 1\\n Minimum length as a multiple of shaft width; if an arrow length\\n is less than this, plot a dot (hexagon) of this diameter instead.\\n\\npivot : {'tail', 'mid', 'middle', 'tip'}, default: 'tail'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The arrow\\n rotates about this point.\\n\\n 'mid' is a synonym for 'middle'.\\n\\ncolor : color or color sequence, optional\\n Explicit color(s) for the arrows. If *C* has been set, *color* has no\\n effect.\\n\\n This is a synonym for the `.PolyCollection` *facecolor* parameter.\\n\\nOther Parameters\\n----------------\\ndata : indexable object, optional\\n DATA_PARAMETER_PLACEHOLDER\\n\\n**kwargs : `~matplotlib.collections.PolyCollection` properties, optional\\n All other keyword arguments are passed on to `.PolyCollection`:\\n\\n \\n .. table::\\n :class: property-table\\n\\n ================================================================================================= =====================================================================================================\\n Property Description \\n ================================================================================================= =====================================================================================================\\n :meth:`agg_filter <matplotlib.artist.Artist.set_agg_filter>` a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array\\n :meth:`alpha <matplotlib.collections.Collection.set_alpha>` array-like or scalar or None \\n :meth:`animated <matplotlib.artist.Artist.set_animated>` bool \\n :meth:`antialiased <matplotlib.collections.Collection.set_antialiased>` or aa or antialiaseds bool or list of bools \\n :meth:`array <matplotlib.cm.ScalarMappable.set_array>` array-like or None \\n :meth:`capstyle <matplotlib.collections.Collection.set_capstyle>` `.CapStyle` or {'butt',", "score": "0.63109034"}]}
{"task_id": 520, "text": "Write a function to find the lcm of the given array elements.", "code": "def find_lcm(num1, num2): \r\n\tif(num1>num2): \r\n\t\tnum = num1 \r\n\t\tden = num2 \r\n\telse: \r\n\t\tnum = num2 \r\n\t\tden = num1 \r\n\trem = num % den \r\n\twhile (rem != 0): \r\n\t\tnum = den \r\n\t\tden = rem \r\n\t\trem = num % den \r\n\tgcd = den \r\n\tlcm = int(int(num1 * num2)/int(gcd)) \r\n\treturn lcm \r\ndef get_lcm(l):\r\n  num1 = l[0]\r\n  num2 = l[1]\r\n  lcm = find_lcm(num1, num2)\r\n  for i in range(2, len(l)):\r\n    lcm = find_lcm(lcm, l[i])\r\n  return lcm ", "test_list": ["assert get_lcm([2, 7, 3, 9, 4]) == 252", "assert get_lcm([1, 2, 8, 3]) == 24", "assert get_lcm([3, 8, 4, 10, 5]) == 120"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "6697", "text": "Function: torch.generated.torch.lcm#torch.lcm\nSnippet: torch.lcm(input, other, *, out=None) → Tensor Computes the element-wise least common multiple (LCM) of input and other. Both input and other must have integer types. Note This defines lcm(0,0)=0lcm(0, 0) = 0 and lcm(0,a)=0lcm(0, a) = 0 . Parameters input (Tensor) – the input tensor. other (Tensor) – the second input tensor Keyword Arguments out (Tensor, optional) – the output tensor. Example: >>> a = torch.tensor([5, 10, 15]) >>> b = torch.tensor([3, 4, 5]) >>> torch.lcm(a, b) tensor([15, 20, 15]) >>> c = torch.tensor([3]) >>> torch.lcm(a, c) tensor([15, 30, 15])", "score": "0.7557352"}, {"id": "42933", "text": "Function: numpy.reference.generated.numpy.lcm\nSnippet: numpy.lcm numpy.lcm(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'lcm'> Returns the lowest common multiple of |x1| and |x2| Parameters x1, x2array_like, int Arrays of values. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). Returns yndarray or scalar The lowest common multiple of the absolute value of the inputs This is a scalar if both x1 and x2 are scalars. See also gcd The greatest common divisor Examples >>> np.lcm(12, 20) 60 >>> np.lcm.reduce([3, 12, 20]) 60 >>> np.lcm.reduce([40, 12, 20]) 120 >>> np.lcm(np.arange(6), 20) array([ 0, 20, 20, 60, 20, 20])", "score": "0.752061"}, {"id": "21813", "text": "Function: python.library.math#math.lcm\nSnippet: math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9.", "score": "0.75092864"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.7185911"}, {"id": "7927", "text": "Function: torch.tensors#torch.Tensor.lcm_\nSnippet: lcm_(other) → Tensor In-place version of lcm()", "score": "0.6873133"}]}
{"task_id": 521, "text": "Write a function to print check if the triangle is scalene or not.", "code": "def check_isosceles(x,y,z):\r\n  if x!=y & y!=z & z!=x:\r\n\t   return True\r\n  else:\r\n     return False", "test_list": ["assert check_isosceles(6,8,12)==True", "assert check_isosceles(6,6,12)==False", "assert check_isosceles(6,15,20)==True"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "33496", "text": "Function: matplotlib._as_gen.matplotlib.quiver.quiver\nSnippet: generated as a uniform integer meshgrid based\\n on the dimensions of *U* and *V*.\\n\\n If *X* and *Y* are 1D but *U*, *V* are 2D, *X*, *Y* are expanded to 2D\\n using ``X, Y = np.meshgrid(X, Y)``. In this case ``len(X)`` and ``len(Y)``\\n must match the column and row dimensions of *U* and *V*.\\n\\nU, V : 1D or 2D array-like\\n The x and y direction components of the arrow vectors.\\n\\n They must have the same number of elements, matching the number of arrow\\n locations. *U* and *V* may be masked. Only locations unmasked in\\n *U*, *V*, and *C* will be drawn.\\n\\nC : 1D or 2D array-like, optional\\n Numeric data that defines the arrow colors by colormapping via *norm* and\\n *cmap*.\\n\\n This does not support explicit colors. If you want to set colors directly,\\n use *color* instead. The size of *C* must match the number of arrow\\n locations.\\n\\nunits : {'width', 'height', 'dots', 'inches', 'x', 'y', 'xy'}, default: 'width'\\n The arrow dimensions (except for *length*) are measured in multiples of\\n this unit.\\n\\n The following values are supported:\\n\\n - 'width', 'height': The width or height of the axis.\\n - 'dots', 'inches': Pixels or inches based on the figure dpi.\\n - 'x', 'y', 'xy': *X*, *Y* or :math:`\\\\sqrt{X^2 + Y^2}` in data units.\\n\\n The arrows scale differently depending on the units. For\\n 'x' or 'y', the arrows get larger as one zooms in; for other\\n units, the arrow size is independent of the zoom state. For\\n 'width or 'height', the arrow size increases with the width and\\n height of the axes, respectively, when the window is resized;\\n for 'dots' or 'inches', resizing does not change the arrows.\\n\\nangles : {'uv', 'xy'} or array-like, default: 'uv'\\n Method for determining the angle of the arrows.\\n\\n - 'uv': The arrow axis aspect ratio is 1 so that\\n if *U* == *V* the orientation of the arrow on the plot is 45 degrees\\n counter-clockwise from the horizontal axis (positive to the right).\\n\\n Use this if the arrows symbolize a quantity that is not based on\\n *X*, *Y* data coordinates.\\n\\n - 'xy': Arrows point from (x, y) to (x+u, y+v).\\n Use this for plotting a gradient field, for example.\\n\\n - Alternatively, arbitrary angles may be specified explicitly as an array\\n of values in degrees, counter-clockwise from the horizontal axis.\\n\\n In this case *U*, *V* is only used to determine the length of the\\n arrows.\\n\\n Note: inverting a data axis will correspondingly invert the\\n arrows only with ``angles='xy'``.\\n\\nscale : float, optional\\n Number of data units per arrow length unit, e.g., m/s per plot width; a\\n smaller scale parameter makes the arrow longer. Default is *None*.\\n\\n If *None*, a simple autoscaling algorithm is used, based on the average\\n vector length and the number of vectors. The arrow length unit is given by\\n the *scale_units* parameter.\\n\\nscale_units : {'width', 'height', 'dots', 'inches', 'x', 'y', 'xy'}, optional\\n If the *scale* kwarg is *None*, the arrow length unit. Default is *None*.\\n\\n e.g. *scale_units* is 'inches', *scale* is 2.0, and ``(u, v) = (1, 0)``,\\n then the", "score": "0.69108343"}, {"id": "33502", "text": "Function: matplotlib._as_gen.matplotlib.quiver.quiver#matplotlib.quiver.Quiver.quiver_doc\nSnippet: symbolize a quantity that is not based on\\n *X*, *Y* data coordinates.\\n\\n - 'xy': Arrows point from (x, y) to (x+u, y+v).\\n Use this for plotting a gradient field, for example.\\n\\n - Alternatively, arbitrary angles may be specified explicitly as an array\\n of values in degrees, counter-clockwise from the horizontal axis.\\n\\n In this case *U*, *V* is only used to determine the length of the\\n arrows.\\n\\n Note: inverting a data axis will correspondingly invert the\\n arrows only with ``angles='xy'``.\\n\\nscale : float, optional\\n Number of data units per arrow length unit, e.g., m/s per plot width; a\\n smaller scale parameter makes the arrow longer. Default is *None*.\\n\\n If *None*, a simple autoscaling algorithm is used, based on the average\\n vector length and the number of vectors. The arrow length unit is given by\\n the *scale_units* parameter.\\n\\nscale_units : {'width', 'height', 'dots', 'inches', 'x', 'y', 'xy'}, optional\\n If the *scale* kwarg is *None*, the arrow length unit. Default is *None*.\\n\\n e.g. *scale_units* is 'inches', *scale* is 2.0, and ``(u, v) = (1, 0)``,\\n then the vector will be 0.5 inches long.\\n\\n If *scale_units* is 'width' or 'height', then the vector will be half the\\n width/height of the axes.\\n\\n If *scale_units* is 'x' then the vector will be 0.5 x-axis\\n units. To plot vectors in the x-y plane, with u and v having\\n the same units as x and y, use\\n ``angles='xy', scale_units='xy', scale=1``.\\n\\nwidth : float, optional\\n Shaft width in arrow units; default depends on choice of units,\\n above, and number of vectors; a typical starting value is about\\n 0.005 times the width of the plot.\\n\\nheadwidth : float, default: 3\\n Head width as multiple of shaft width.\\n\\nheadlength : float, default: 5\\n Head length as multiple of shaft width.\\n\\nheadaxislength : float, default: 4.5\\n Head length at shaft intersection.\\n\\nminshaft : float, default: 1\\n Length below which arrow scales, in units of head length. Do not\\n set this to less than 1, or small arrows will look terrible!\\n\\nminlength : float, default: 1\\n Minimum length as a multiple of shaft width; if an arrow length\\n is less than this, plot a dot (hexagon) of this diameter instead.\\n\\npivot : {'tail', 'mid', 'middle', 'tip'}, default: 'tail'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The arrow\\n rotates about this point.\\n\\n 'mid' is a synonym for 'middle'.\\n\\ncolor : color or color sequence, optional\\n Explicit color(s) for the arrows. If *C* has been set, *color* has no\\n effect.\\n\\n This is a synonym for the `.PolyCollection` *facecolor* parameter.\\n\\nOther Parameters\\n----------------\\ndata : indexable object, optional\\n DATA_PARAMETER_PLACEHOLDER\\n\\n**kwargs : `~matplotlib.collections.PolyCollection` properties, optional\\n All other keyword arguments are passed on to `.PolyCollection`:\\n\\n \\n .. table::\\n :class: property-table\\n\\n ================================================================================================= =====================================================================================================\\n Property Description \\n ================================================================================================= =====================================================================================================\\n :meth:`agg_filter <matplotlib.artist.Artist.set_agg_filter>` a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array\\n :meth:`alpha <matplotlib.collections.Collection.set_alpha>` array-like or scalar or None \\n :meth:`animated <matplotlib.artist.Artist.set_animated>` bool \\n :meth:`antialiased <matplotlib.collections.Collection.set_antialiased>` or aa or antialiaseds bool or list of bools \\n :meth:`array <matplotlib.cm.ScalarMappable.set_array>` array-like or None \\n :meth:`capstyle <matplotlib.collections.Collection.set_capstyle>` `.CapStyle` or {'butt',", "score": "0.68963784"}, {"id": "33497", "text": "Function: matplotlib._as_gen.matplotlib.quiver.quiver\nSnippet: vector will be 0.5 inches long.\\n\\n If *scale_units* is 'width' or 'height', then the vector will be half the\\n width/height of the axes.\\n\\n If *scale_units* is 'x' then the vector will be 0.5 x-axis\\n units. To plot vectors in the x-y plane, with u and v having\\n the same units as x and y, use\\n ``angles='xy', scale_units='xy', scale=1``.\\n\\nwidth : float, optional\\n Shaft width in arrow units; default depends on choice of units,\\n above, and number of vectors; a typical starting value is about\\n 0.005 times the width of the plot.\\n\\nheadwidth : float, default: 3\\n Head width as multiple of shaft width.\\n\\nheadlength : float, default: 5\\n Head length as multiple of shaft width.\\n\\nheadaxislength : float, default: 4.5\\n Head length at shaft intersection.\\n\\nminshaft : float, default: 1\\n Length below which arrow scales, in units of head length. Do not\\n set this to less than 1, or small arrows will look terrible!\\n\\nminlength : float, default: 1\\n Minimum length as a multiple of shaft width; if an arrow length\\n is less than this, plot a dot (hexagon) of this diameter instead.\\n\\npivot : {'tail', 'mid', 'middle', 'tip'}, default: 'tail'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The arrow\\n rotates about this point.\\n\\n 'mid' is a synonym for 'middle'.\\n\\ncolor : color or color sequence, optional\\n Explicit color(s) for the arrows. If *C* has been set, *color* has no\\n effect.\\n\\n This is a synonym for the `.PolyCollection` *facecolor* parameter.\\n\\nOther Parameters\\n----------------\\ndata : indexable object, optional\\n DATA_PARAMETER_PLACEHOLDER\\n\\n**kwargs : `~matplotlib.collections.PolyCollection` properties, optional\\n All other keyword arguments are passed on to `.PolyCollection`:\\n\\n \\n .. table::\\n :class: property-table\\n\\n ================================================================================================= =====================================================================================================\\n Property Description \\n ================================================================================================= =====================================================================================================\\n :meth:`agg_filter <matplotlib.artist.Artist.set_agg_filter>` a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array\\n :meth:`alpha <matplotlib.collections.Collection.set_alpha>` array-like or scalar or None \\n :meth:`animated <matplotlib.artist.Artist.set_animated>` bool \\n :meth:`antialiased <matplotlib.collections.Collection.set_antialiased>` or aa or antialiaseds bool or list of bools \\n :meth:`array <matplotlib.cm.ScalarMappable.set_array>` array-like or None \\n :meth:`capstyle <matplotlib.collections.Collection.set_capstyle>` `.CapStyle` or {'butt', 'projecting', 'round'} \\n :meth:`clim <matplotlib.cm.ScalarMappable.set_clim>` (vmin: float, vmax: float) \\n :meth:`clip_box <matplotlib.artist.Artist.set_clip_box>` `.Bbox` \\n :meth:`clip_on <matplotlib.artist.Artist.set_clip_on>` bool \\n :meth:`clip_path <matplotlib.artist.Artist.set_clip_path>` Patch or (Path, Transform) or None \\n :meth:`cmap <matplotlib.cm.ScalarMappable.set_cmap>` `.Colormap` or str or None \\n :meth:`color <matplotlib.collections.Collection.set_color>` color or list of rgba tuples \\n :meth:`edgecolor <matplotlib.collections.Collection.set_edgecolor>` or ec or edgecolors color or list of colors or 'face' \\n :meth:`facecolor <matplotlib.collections.Collection.set_facecolor>` or facecolors or fc color or list of colors \\n :meth:`figure <matplotlib.artist.Artist.set_figure>` `.Figure` \\n :meth:`gid <matplotlib.artist.Artist.set_gid>` str \\n :meth:`hatch <matplotlib.collections.Collection.set_hatch>` {'/', '\\\\\\\\', '|', '-', '+', 'x', 'o', 'O', '.', '*'} \\n :meth:`in_layout <matplotlib.artist.Artist.set_in_layout>` bool \\n :meth:`joinstyle <matplotlib.collections.Collection.set_joinstyle>` `.JoinStyle` or {'miter', 'round', 'bevel'} \\n :meth:`label <matplotlib.artist.Artist.set_label>` object \\n :meth:`linestyle <matplotlib.collections.Collection.set_linestyle>` or dashes or linestyles or ls str or tuple or list thereof \\n :meth:`linewidth <matplotlib.collections.Collection.set_linewidth>` or linewidths or lw float or list of floats \\n :meth:`norm <matplotlib.cm.ScalarMappable.set_norm>` `.Normalize` or None \\n :meth:`offset_transform <matplotlib.collections.Collection.set_offset_transform>` `.Transform` \\n :meth:`offsets <matplotlib.collections.Collection.set_offsets>` (N, 2) or (2,) array-like \\n :meth:`path_effects <matplotlib.artist.Artist.set_path_effects>` `.AbstractPathEffect` \\n :meth:`paths <matplotlib.collections.PolyCollection.set_verts>` list of array-like \\n :meth:`picker <matplotlib.artist.Artist.set_picker>` None or bool or float or callable \\n", "score": "0.68820745"}, {"id": "33487", "text": "Function: matplotlib._as_gen.matplotlib.quiver.barbs#matplotlib.quiver.Barbs.barbs_doc\nSnippet: barbs_doc='\\nPlot a 2D field of barbs.\\n\\nCall signature::\\n\\n barbs([X, Y], U, V, [C], **kw)\\n\\nWhere *X*, *Y* define the barb locations, *U*, *V* define the barb\\ndirections, and *C* optionally sets the color.\\n\\nAll arguments may be 1D or 2D. *U*, *V*, *C* may be masked arrays, but masked\\n*X*, *Y* are not supported at present.\\n\\nBarbs are traditionally used in meteorology as a way to plot the speed\\nand direction of wind observations, but can technically be used to\\nplot any two dimensional vector quantity. As opposed to arrows, which\\ngive vector magnitude by the length of the arrow, the barbs give more\\nquantitative information about the vector magnitude by putting slanted\\nlines or a triangle for various increments in magnitude, as show\\nschematically below::\\n\\n : /\\\\ \\\\\\n : / \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : ------------------------------\\n\\nThe largest increment is given by a triangle (or \"flag\"). After those\\ncome full lines (barbs). The smallest increment is a half line. There\\nis only, of course, ever at most 1 half line. If the magnitude is\\nsmall and only needs a single half-line and no full lines or\\ntriangles, the half-line is offset from the end of the barb so that it\\ncan be easily distinguished from barbs with a single full line. The\\nmagnitude for the barb shown above would nominally be 65, using the\\nstandard increments of 50, 10, and 5.\\n\\nSee also https://en.wikipedia.org/wiki/Wind_barb.\\n\\nParameters\\n----------\\nX, Y : 1D or 2D array-like, optional\\n The x and y coordinates of the barb locations. See *pivot* for how the\\n barbs are drawn to the x, y positions.\\n\\n If not given, they will be generated as a uniform integer meshgrid based\\n on the dimensions of *U* and *V*.\\n\\n If *X* and *Y* are 1D but *U*, *V* are 2D, *X*, *Y* are expanded to 2D\\n using ``X, Y = np.meshgrid(X, Y)``. In this case ``len(X)`` and ``len(Y)``\\n must match the column and row dimensions of *U* and *V*.\\n\\nU, V : 1D or 2D array-like\\n The x and y components of the barb shaft.\\n\\nC : 1D or 2D array-like, optional\\n Numeric data that defines the barb colors by colormapping via *norm* and\\n *cmap*.\\n\\n This does not support explicit colors. If you want to set colors directly,\\n use *barbcolor* instead.\\n\\nlength : float, default: 7\\n Length of the barb in points; the other parts of the barb\\n are scaled against this.\\n\\npivot : {\\'tip\\', \\'middle\\'} or float, default: \\'tip\\'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The barb\\n rotates about this point. This can also be a number, which shifts the\\n start of the barb that many points away from grid point.\\n\\nbarbcolor : color or color sequence\\n The color of all parts of the barb except for the flags. This parameter\\n is analogous to the *edgecolor* parameter for polygons, which can be used\\n instead. However this parameter will override facecolor.\\n\\nflagcolor : color or color sequence\\n The color of any flags on the barb. This parameter is analogous to the\\n *facecolor* parameter for polygons, which can be used instead. However,\\n this parameter will override facecolor. If", "score": "0.6815352"}, {"id": "14549", "text": "Function: pandas.reference.api.pandas.dataframe.truediv\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.67876804"}]}
{"task_id": 522, "text": "Write a function to find the longest bitonic subsequence for the given array.", "code": "def lbs(arr): \r\n\tn = len(arr) \r\n\tlis = [1 for i in range(n+1)] \r\n\tfor i in range(1 , n): \r\n\t\tfor j in range(0 , i): \r\n\t\t\tif ((arr[i] > arr[j]) and (lis[i] < lis[j] +1)): \r\n\t\t\t\tlis[i] = lis[j] + 1\r\n\tlds = [1 for i in range(n+1)] \r\n\tfor i in reversed(range(n-1)): \r\n\t\tfor j in reversed(range(i-1 ,n)): \r\n\t\t\tif(arr[i] > arr[j] and lds[i] < lds[j] + 1): \r\n\t\t\t\tlds[i] = lds[j] + 1\r\n\tmaximum = lis[0] + lds[0] - 1\r\n\tfor i in range(1 , n): \r\n\t\tmaximum = max((lis[i] + lds[i]-1), maximum) \r\n\treturn maximum", "test_list": ["assert lbs([0 , 8 , 4, 12, 2, 10 , 6 , 14 , 1 , 9 , 5 , 13, 3, 11 , 7 , 15]) == 7", "assert lbs([1, 11, 2, 10, 4, 5, 2, 1]) == 6", "assert lbs([80, 60, 30, 40, 20, 10]) == 5"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18285", "text": "Function: python.library.stdtypes#bytearray.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.7324041"}, {"id": "18264", "text": "Function: python.library.stdtypes#bytearray.find\nSnippet: bytes.find(sub[, start[, end]]) bytearray.find(sub[, start[, end]]) Return the lowest index in the data where the subsequence sub is found, such that sub is contained in the slice s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Note The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator: >>> b'Py' in b'Python' True Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.72589815"}, {"id": "18329", "text": "Function: python.library.stdtypes#bytes.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.7250281"}, {"id": "25754", "text": "Function: python.library.stdtypes\nSnippet: bytes or bytearray objects. The separator to search for may be any bytes-like object. bytes.replace(old, new[, count]) bytearray.replace(old, new[, count]) Return a copy of the sequence with all occurrences of subsequence old replaced by new. If the optional argument count is given, only the first count occurrences are replaced. The subsequence to search for and its replacement may be any bytes-like object. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence. bytes.rindex(sub[, start[, end]]) bytearray.rindex(sub[, start[, end]]) Like rfind() but raises ValueError when the subsequence sub is not found. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence. bytes.rpartition(sep) bytearray.rpartition(sep) Split the sequence at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return a 3-tuple containing two empty bytes or bytearray objects, followed by a copy of the original sequence. The separator to search for may be any bytes-like object. bytes.startswith(prefix[, start[, end]]) bytearray.startswith(prefix[, start[, end]]) Return True if the binary data starts with the specified prefix, otherwise return False. prefix can also be a tuple of prefixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position. The prefix(es) to search for may be any bytes-like object. bytes.translate(table, /, delete=b'') bytearray.translate(table, /, delete=b'') Return a copy of the bytes or bytearray object where all bytes occurring in the optional argument delete are removed, and the remaining bytes have been mapped through the given translation table, which must be a bytes object of length 256. You can use the bytes.maketrans() method to create a translation table. Set the table argument to None for translations that only delete characters: >>> b'read this short text'.translate(None, b'aeiou') b'rd ths shrt txt' Changed in version 3.6: delete is now supported as a keyword argument. The following methods on bytes and bytearray objects have default behaviours that assume the use of ASCII compatible binary formats, but can still be used with arbitrary binary data by passing appropriate arguments. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects. bytes.center(width[, fillbyte]) bytearray.center(width[, fillbyte]) Return a copy of the object centered in", "score": "0.72370505"}, {"id": "18308", "text": "Function: python.library.stdtypes#bytes.find\nSnippet: bytes.find(sub[, start[, end]]) bytearray.find(sub[, start[, end]]) Return the lowest index in the data where the subsequence sub is found, such that sub is contained in the slice s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Note The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator: >>> b'Py' in b'Python' True Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.72030765"}]}
{"task_id": 523, "text": "Write a function to check whether a given string has a capital letter, a lower case letter, a number and specified length using lambda function.", "code": "def check_string(str1):\r\n    messg = [\r\n    lambda str1: any(x.isupper() for x in str1) or 'String must have 1 upper case character.',\r\n    lambda str1: any(x.islower() for x in str1) or 'String must have 1 lower case character.',\r\n    lambda str1: any(x.isdigit() for x in str1) or 'String must have 1 number.',\r\n    lambda str1: len(str1) >= 7                 or 'String length should be atleast 8.',]\r\n    result = [x for x in [i(str1) for i in messg] if x != True]\r\n    if not result:\r\n        result.append('Valid string.')\r\n    return result  ", "test_list": ["assert check_string('python')==['String must have 1 upper case character.', 'String must have 1 number.', 'String length should be atleast 8.']", "assert check_string('123python')==['String must have 1 upper case character.']", "assert check_string('123Python')==['Valid string.']"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "24356", "text": "Function: python.library.stdtypes#str.islower\nSnippet: str.islower() Return True if all cased characters 4 in the string are lowercase and there is at least one cased character, False otherwise.", "score": "0.72297287"}, {"id": "24361", "text": "Function: python.library.stdtypes#str.isupper\nSnippet: str.isupper() Return True if all cased characters 4 in the string are uppercase and there is at least one cased character, False otherwise. >>> 'BANANA'.isupper() True >>> 'banana'.isupper() False >>> 'baNana'.isupper() False >>> ' '.isupper() False", "score": "0.71761435"}, {"id": "15343", "text": "Function: pandas.reference.api.pandas.series.str.isupper\nSnippet: pandas.Series.str.isupper Series.str.isupper()[source] Check whether all characters in each string are uppercase. This is equivalent to running the Python string method str.isupper() for each element of the Series/Index. If a string has zero characters, False is returned for that check. Returns Series or Index of bool Series or Index of boolean values with the same length as the original Series/Index. See also Series.str.isalpha Check whether all characters are alphabetic. Series.str.isnumeric Check whether all characters are numeric. Series.str.isalnum Check whether all characters are alphanumeric. Series.str.isdigit Check whether all characters are digits. Series.str.isdecimal Check whether all characters are decimal. Series.str.isspace Check whether all characters are whitespace. Series.str.islower Check whether all characters are lowercase. Series.str.isupper Check whether all characters are uppercase. Series.str.istitle Check whether all characters are titlecase. Examples Checks for Alphabetic and Numeric Characters >>> s1 = pd.Series(['one', 'one1', '1', '']) >>> s1.str.isalpha() 0 True 1 False 2 False 3 False dtype: bool >>> s1.str.isnumeric() 0 False 1 False 2 True 3 False dtype: bool >>> s1.str.isalnum() 0 True 1 True 2 True 3 False dtype: bool Note that checks against characters mixed with any additional punctuation or whitespace will evaluate to false for an alphanumeric check. >>> s2 = pd.Series(['A B', '1.5', '3,000']) >>> s2.str.isalnum() 0 False 1 False 2 False dtype: bool More Detailed Checks for Numeric Characters There are several different but overlapping sets of numeric characters that can be checked for. >>> s3 = pd.Series(['23', '³', '⅕', '']) The s3.str.isdecimal method checks for characters used to form numbers in base 10. >>> s3.str.isdecimal() 0 True 1 False 2 False 3 False dtype: bool The s.str.isdigit method is the same as s3.str.isdecimal but also includes special digits, like superscripted and subscripted digits in unicode. >>> s3.str.isdigit() 0 True 1 True 2 False 3 False dtype: bool The s.str.isnumeric method is the same as s3.str.isdigit but also includes other characters that can represent quantities such as unicode fractions. >>> s3.str.isnumeric() 0 True 1 True 2 True 3 False dtype: bool Checks for Whitespace >>> s4 = pd.Series([' ', '\\t\\r\\n ', '']) >>> s4.str.isspace() 0 True 1 True 2 False dtype: bool Checks for Character Case >>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', '']) >>> s5.str.islower() 0 True 1 False 2 False 3 False dtype: bool >>> s5.str.isupper() 0 False 1 False 2 True 3 False dtype: bool The s5.str.istitle method checks for whether all words are in title case (whether only the first letter of each word is capitalized). Words are assumed to be as any sequence of non-numeric characters separated by whitespace characters. >>> s5.str.istitle() 0 False 1 True 2 False 3 False dtype: bool", "score": "0.7168082"}, {"id": "15339", "text": "Function: pandas.reference.api.pandas.series.str.islower\nSnippet: pandas.Series.str.islower Series.str.islower()[source] Check whether all characters in each string are lowercase. This is equivalent to running the Python string method str.islower() for each element of the Series/Index. If a string has zero characters, False is returned for that check. Returns Series or Index of bool Series or Index of boolean values with the same length as the original Series/Index. See also Series.str.isalpha Check whether all characters are alphabetic. Series.str.isnumeric Check whether all characters are numeric. Series.str.isalnum Check whether all characters are alphanumeric. Series.str.isdigit Check whether all characters are digits. Series.str.isdecimal Check whether all characters are decimal. Series.str.isspace Check whether all characters are whitespace. Series.str.islower Check whether all characters are lowercase. Series.str.isupper Check whether all characters are uppercase. Series.str.istitle Check whether all characters are titlecase. Examples Checks for Alphabetic and Numeric Characters >>> s1 = pd.Series(['one', 'one1', '1', '']) >>> s1.str.isalpha() 0 True 1 False 2 False 3 False dtype: bool >>> s1.str.isnumeric() 0 False 1 False 2 True 3 False dtype: bool >>> s1.str.isalnum() 0 True 1 True 2 True 3 False dtype: bool Note that checks against characters mixed with any additional punctuation or whitespace will evaluate to false for an alphanumeric check. >>> s2 = pd.Series(['A B', '1.5', '3,000']) >>> s2.str.isalnum() 0 False 1 False 2 False dtype: bool More Detailed Checks for Numeric Characters There are several different but overlapping sets of numeric characters that can be checked for. >>> s3 = pd.Series(['23', '³', '⅕', '']) The s3.str.isdecimal method checks for characters used to form numbers in base 10. >>> s3.str.isdecimal() 0 True 1 False 2 False 3 False dtype: bool The s.str.isdigit method is the same as s3.str.isdecimal but also includes special digits, like superscripted and subscripted digits in unicode. >>> s3.str.isdigit() 0 True 1 True 2 False 3 False dtype: bool The s.str.isnumeric method is the same as s3.str.isdigit but also includes other characters that can represent quantities such as unicode fractions. >>> s3.str.isnumeric() 0 True 1 True 2 True 3 False dtype: bool Checks for Whitespace >>> s4 = pd.Series([' ', '\\t\\r\\n ', '']) >>> s4.str.isspace() 0 True 1 True 2 False dtype: bool Checks for Character Case >>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', '']) >>> s5.str.islower() 0 True 1 False 2 False 3 False dtype: bool >>> s5.str.isupper() 0 False 1 False 2 True 3 False dtype: bool The s5.str.istitle method checks for whether all words are in title case (whether only the first letter of each word is capitalized). Words are assumed to be as any sequence of non-numeric characters separated by whitespace characters. >>> s5.str.istitle() 0 False 1 True 2 False 3 False dtype: bool", "score": "0.7112148"}, {"id": "15336", "text": "Function: pandas.reference.api.pandas.series.str.isalpha\nSnippet: pandas.Series.str.isalpha Series.str.isalpha()[source] Check whether all characters in each string are alphabetic. This is equivalent to running the Python string method str.isalpha() for each element of the Series/Index. If a string has zero characters, False is returned for that check. Returns Series or Index of bool Series or Index of boolean values with the same length as the original Series/Index. See also Series.str.isalpha Check whether all characters are alphabetic. Series.str.isnumeric Check whether all characters are numeric. Series.str.isalnum Check whether all characters are alphanumeric. Series.str.isdigit Check whether all characters are digits. Series.str.isdecimal Check whether all characters are decimal. Series.str.isspace Check whether all characters are whitespace. Series.str.islower Check whether all characters are lowercase. Series.str.isupper Check whether all characters are uppercase. Series.str.istitle Check whether all characters are titlecase. Examples Checks for Alphabetic and Numeric Characters >>> s1 = pd.Series(['one', 'one1', '1', '']) >>> s1.str.isalpha() 0 True 1 False 2 False 3 False dtype: bool >>> s1.str.isnumeric() 0 False 1 False 2 True 3 False dtype: bool >>> s1.str.isalnum() 0 True 1 True 2 True 3 False dtype: bool Note that checks against characters mixed with any additional punctuation or whitespace will evaluate to false for an alphanumeric check. >>> s2 = pd.Series(['A B', '1.5', '3,000']) >>> s2.str.isalnum() 0 False 1 False 2 False dtype: bool More Detailed Checks for Numeric Characters There are several different but overlapping sets of numeric characters that can be checked for. >>> s3 = pd.Series(['23', '³', '⅕', '']) The s3.str.isdecimal method checks for characters used to form numbers in base 10. >>> s3.str.isdecimal() 0 True 1 False 2 False 3 False dtype: bool The s.str.isdigit method is the same as s3.str.isdecimal but also includes special digits, like superscripted and subscripted digits in unicode. >>> s3.str.isdigit() 0 True 1 True 2 False 3 False dtype: bool The s.str.isnumeric method is the same as s3.str.isdigit but also includes other characters that can represent quantities such as unicode fractions. >>> s3.str.isnumeric() 0 True 1 True 2 True 3 False dtype: bool Checks for Whitespace >>> s4 = pd.Series([' ', '\\t\\r\\n ', '']) >>> s4.str.isspace() 0 True 1 True 2 False dtype: bool Checks for Character Case >>> s5 = pd.Series(['leopard', 'Golden Eagle', 'SNAKE', '']) >>> s5.str.islower() 0 True 1 False 2 False 3 False dtype: bool >>> s5.str.isupper() 0 False 1 False 2 True 3 False dtype: bool The s5.str.istitle method checks for whether all words are in title case (whether only the first letter of each word is capitalized). Words are assumed to be as any sequence of non-numeric characters separated by whitespace characters. >>> s5.str.istitle() 0 False 1 True 2 False 3 False dtype: bool", "score": "0.7073934"}]}
{"task_id": 524, "text": "Write a function to find the sum of maximum increasing subsequence of the given array.", "code": "def max_sum_increasing_subsequence(arr, n): \r\n\tmax = 0\r\n\tmsis = [0 for x in range(n)] \r\n\tfor i in range(n): \r\n\t\tmsis[i] = arr[i] \r\n\tfor i in range(1, n): \r\n\t\tfor j in range(i): \r\n\t\t\tif (arr[i] > arr[j] and\r\n\t\t\t\tmsis[i] < msis[j] + arr[i]): \r\n\t\t\t\tmsis[i] = msis[j] + arr[i] \r\n\tfor i in range(n): \r\n\t\tif max < msis[i]: \r\n\t\t\tmax = msis[i] \r\n\treturn max", "test_list": ["assert max_sum_increasing_subsequence([1, 101, 2, 3, 100, 4, 5], 7) == 106", "assert max_sum_increasing_subsequence([3, 4, 5, 10], 4) == 22", "assert max_sum_increasing_subsequence([10, 5, 4, 3], 4) == 10"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18285", "text": "Function: python.library.stdtypes#bytearray.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.6612805"}, {"id": "18329", "text": "Function: python.library.stdtypes#bytes.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.6535316"}, {"id": "42807", "text": "Function: numpy.reference.generated.numpy.einsum\nSnippet: 64], [13, 40, 67, 94]]) >>> np.einsum('k...,jk', a, b) array([[10, 28, 46, 64], [13, 40, 67, 94]]) Chained array operations. For more complicated contractions, speed ups might be achieved by repeatedly computing a ‘greedy’ path or pre-computing the ‘optimal’ path and repeatedly applying it, using an einsum_path insertion (since version 1.12.0). Performance improvements can be particularly significant with larger arrays: >>> a = np.ones(64).reshape(2,4,8) Basic einsum: ~1520ms (benchmarked on 3.1GHz Intel i5.) >>> for iteration in range(500): ... _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a) Sub-optimal einsum (due to repeated path calculation time): ~330ms >>> for iteration in range(500): ... _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal') Greedy einsum (faster optimal path approximation): ~160ms >>> for iteration in range(500): ... _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy') Optimal einsum (best usage pattern in some use cases): ~110ms >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')[0] >>> for iteration in range(500): ... _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)", "score": "0.6523297"}, {"id": "43857", "text": "Function: numpy.reference.generated.numpy.recarray.max\nSnippet: numpy.recarray.max method recarray.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True) Return the maximum along a given axis. Refer to numpy.amax for full documentation. See also numpy.amax equivalent function", "score": "0.6522421"}, {"id": "42808", "text": "Function: numpy.reference.generated.numpy.einsum_path\nSnippet: numpy.einsum_path numpy.einsum_path(subscripts, *operands, optimize='greedy')[source] Evaluates the lowest cost contraction order for an einsum expression by considering the creation of intermediate arrays. Parameters subscriptsstr Specifies the subscripts for summation. *operandslist of array_like These are the arrays for the operation. optimize{bool, list, tuple, ‘greedy’, ‘optimal’} Choose the type of path. If a tuple is provided, the second argument is assumed to be the maximum intermediate size created. If only a single argument is provided the largest input or output array size is used as a maximum intermediate size. if a list is given that starts with einsum_path, uses this as the contraction path if False no optimization is taken if True defaults to the ‘greedy’ algorithm ‘optimal’ An algorithm that combinatorially explores all possible ways of contracting the listed tensors and choosest the least costly path. Scales exponentially with the number of terms in the contraction. ‘greedy’ An algorithm that chooses the best pair contraction at each step. Effectively, this algorithm searches the largest inner, Hadamard, and then outer products at each step. Scales cubically with the number of terms in the contraction. Equivalent to the ‘optimal’ path for most contractions. Default is ‘greedy’. Returns pathlist of tuples A list representation of the einsum path. string_reprstr A printable representation of the einsum path. See also einsum, linalg.multi_dot Notes The resulting path indicates which terms of the input contraction should be contracted first, the result of this contraction is then appended to the end of the contraction list. This list can then be iterated over until all intermediate contractions are complete. Examples We can begin with a chain dot example. In this case, it is optimal to contract the b and c tensors first as represented by the first element of the path (1, 2). The resulting tensor is added to the end of the contraction and the remaining contraction (0, 1) is then completed. >>> np.random.seed(123) >>> a = np.random.rand(2, 2) >>> b = np.random.rand(2, 5) >>> c = np.random.rand(5, 2) >>> path_info = np.einsum_path('ij,jk,kl->il', a, b, c, optimize='greedy') >>> print(path_info[0]) ['einsum_path', (1, 2), (0, 1)] >>> print(path_info[1]) Complete contraction: ij,jk,kl->il # may vary Naive scaling: 4 Optimized scaling: 3 Naive FLOP count: 1.600e+02 Optimized FLOP count: 5.600e+01 Theoretical speedup: 2.857 Largest intermediate: 4.000e+00 elements ------------------------------------------------------------------------- scaling current remaining ------------------------------------------------------------------------- 3 kl,jk->jl ij,jl->il 3 jl,ij->il il->il A more complex index transformation example. >>> I = np.random.rand(10, 10, 10, 10) >>> C = np.random.rand(10, 10) >>> path_info = np.einsum_path('ea,fb,abcd,gc,hd->efgh', C, C, I, C, C, ... optimize='greedy') >>> print(path_info[0]) ['einsum_path', (0, 2), (0, 3), (0, 2), (0, 1)] >>> print(path_info[1]) Complete contraction: ea,fb,abcd,gc,hd->efgh # may vary Naive scaling: 8 Optimized scaling: 5 Naive FLOP count: 8.000e+08 Optimized FLOP count: 8.000e+05 Theoretical speedup: 1000.000 Largest intermediate: 1.000e+04 elements -------------------------------------------------------------------------- scaling current remaining -------------------------------------------------------------------------- 5 abcd,ea->bcde fb,gc,hd,bcde->efgh 5 bcde,fb->cdef gc,hd,cdef->efgh 5 cdef,gc->defg hd,defg->efgh 5 defg,hd->efgh efgh->efgh", "score": "0.65073234"}]}
{"task_id": 525, "text": "Write a python function to check whether two given lines are parallel or not.", "code": "def parallel_lines(line1, line2):\r\n  return line1[0]/line1[1] == line2[0]/line2[1]", "test_list": ["assert parallel_lines([2,3,4], [2,3,8]) == True", "assert parallel_lines([2,3,4], [4,-3,8]) == False", "assert parallel_lines([3,3],[5,5]) == True"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "29093", "text": "Function: matplotlib.bezier_api#matplotlib.bezier.check_if_parallel\nSnippet: matplotlib.bezier.check_if_parallel(dx1, dy1, dx2, dy2, tolerance=1e-05)[source] Check if two lines are parallel. Parameters dx1, dy1, dx2, dy2float The gradients dy/dx of the two lines. tolerancefloat The angular tolerance in radians up to which the lines are considered parallel. Returns is_parallel 1 if two lines are parallel in same direction. -1 if two lines are parallel in opposite direction. False otherwise.", "score": "0.78528255"}, {"id": "42916", "text": "Function: numpy.reference.generated.numpy.isfortran\nSnippet: numpy.isfortran numpy.isfortran(a)[source] Check if the array is Fortran contiguous but not C contiguous. This function is obsolete and, because of changes due to relaxed stride checking, its return value for the same array may differ for versions of NumPy >= 1.10.0 and previous versions. If you only want to check if an array is Fortran contiguous use a.flags.f_contiguous instead. Parameters andarray Input array. Returns isfortranbool Returns True if the array is Fortran contiguous but not C contiguous. Examples np.array allows to specify whether the array is written in C-contiguous order (last index varies the fastest), or FORTRAN-contiguous order in memory (first index varies the fastest). >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C') >>> a array([[1, 2, 3], [4, 5, 6]]) >>> np.isfortran(a) False >>> b = np.array([[1, 2, 3], [4, 5, 6]], order='F') >>> b array([[1, 2, 3], [4, 5, 6]]) >>> np.isfortran(b) True The transpose of a C-ordered array is a FORTRAN-ordered array. >>> a = np.array([[1, 2, 3], [4, 5, 6]], order='C') >>> a array([[1, 2, 3], [4, 5, 6]]) >>> np.isfortran(a) False >>> b = a.T >>> b array([[1, 4], [2, 5], [3, 6]]) >>> np.isfortran(b) True C-ordered arrays evaluate as False even if they are also FORTRAN-ordered. >>> np.isfortran(np.array([1, 2], order='F')) False", "score": "0.68730277"}, {"id": "21154", "text": "Function: python.library.io#io.TextIOWrapper.line_buffering\nSnippet: line_buffering Whether line buffering is enabled.", "score": "0.6808046"}, {"id": "20182", "text": "Function: python.library.fileinput#fileinput.isfirstline\nSnippet: fileinput.isfirstline() Return True if the line just read is the first line of its file, otherwise return False.", "score": "0.6713367"}, {"id": "19648", "text": "Function: python.library.difflib#difflib.SequenceMatcher.get_matching_blocks\nSnippet: get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]", "score": "0.6700906"}]}
{"task_id": 526, "text": "Write a python function to capitalize first and last letters of each word of a given string.", "code": "def capitalize_first_last_letters(str1):\r\n     str1 = result = str1.title()\r\n     result =  \"\"\r\n     for word in str1.split():\r\n        result += word[:-1] + word[-1].upper() + \" \"\r\n     return result[:-1]  ", "test_list": ["assert capitalize_first_last_letters(\"python\") == \"PythoN\"", "assert capitalize_first_last_letters(\"bigdata\") == \"BigdatA\"", "assert capitalize_first_last_letters(\"Hadoop\") == \"HadooP\""], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "24339", "text": "Function: python.library.stdtypes#str.capitalize\nSnippet: str.capitalize() Return a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that characters like digraphs will only have their first letter capitalized, instead of the full character.", "score": "0.7600112"}, {"id": "24402", "text": "Function: python.library.string#string.capwords\nSnippet: string.capwords(s, sep=None) Split the argument into words using str.split(), capitalize each word using str.capitalize(), and join the capitalized words using str.join(). If the optional second argument sep is absent or None, runs of whitespace characters are replaced by a single space and leading and trailing whitespace are removed, otherwise sep is used to split and join the words.", "score": "0.75580925"}, {"id": "25742", "text": "Function: python.library.stdtypes\nSnippet: Strings also support two styles of string formatting, one providing a large degree of flexibility and customization (see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style formatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the cases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various text related utilities (including regular expression support in the re module). str.capitalize() Return a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that characters like digraphs will only have their first letter capitalized, instead of the full character. str.casefold() Return a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions in a string. For example, the German lowercase letter 'ß' is equivalent to \"ss\". Since it is already lowercase, lower() would do nothing to 'ß'; casefold() converts it to \"ss\". The casefolding algorithm is described in section 3.13 of the Unicode Standard. New in version 3.3. str.center(width[, fillchar]) Return centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII space). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]]) Return the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. str.encode(encoding=\"utf-8\", errors=\"strict\") Return an encoded version of the string as a bytes object. Default encoding is 'utf-8'. errors may be given to set a different error handling scheme. The default for errors is 'strict', meaning that encoding errors raise a UnicodeError. Other possible values are 'ignore', 'replace', 'xmlcharrefreplace', 'backslashreplace' and any other name registered via codecs.register_error(), see section Error Handlers. For a list of possible encodings, see section Standard Encodings. By default, the errors argument is not checked for best performances, but only used at the first encoding error. Enable the Python Development Mode, or use a debug build to check errors. Changed in version 3.1: Support for keyword arguments added. Changed in version 3.9: The errors is now checked in development mode and in debug mode. str.endswith(suffix[, start[, end]]) Return True if the string ends with the specified suffix, otherwise return False. suffix can also be a tuple of suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at that position. str.expandtabs(tabsize=8) Return a copy of the string where all tab characters are replaced by one or more spaces, depending on the current column and the given tab size. Tab positions occur every tabsize characters (default is 8, giving tab positions at columns 0, 8, 16 and so", "score": "0.72622854"}, {"id": "24382", "text": "Function: python.library.stdtypes#str.title\nSnippet: str.title() Return a titlecased version of the string where words start with an uppercase character and the remaining characters are lowercase. For example: >>> 'Hello world'.title() 'Hello World' The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The definition works in many contexts but it means that apostrophes in contractions and possessives form word boundaries, which may not be the desired result: >>> \"they're bill's friends from the UK\".title() \"They'Re Bill'S Friends From The Uk\" A workaround for apostrophes can be constructed using regular expressions: >>> import re >>> def titlecase(s): ... return re.sub(r\"[A-Za-z]+('[A-Za-z]+)?\", ... lambda mo: mo.group(0).capitalize(), ... s) ... >>> titlecase(\"they're bill's friends.\") \"They're Bill's Friends.\"", "score": "0.72571737"}, {"id": "41637", "text": "Function: numpy.reference.generated.numpy.char.capitalize\nSnippet: numpy.char.capitalize char.capitalize(a)[source] Return a copy of a with only the first character of each element capitalized. Calls str.capitalize element-wise. For 8-bit strings, this method is locale-dependent. Parameters aarray_like of str or unicode Input array of strings to capitalize. Returns outndarray Output array of str or unicode, depending on input types See also str.capitalize Examples >>> c = np.array(['a1b2','1b2a','b2a1','2a1b'],'S4'); c array(['a1b2', '1b2a', 'b2a1', '2a1b'], dtype='|S4') >>> np.char.capitalize(c) array(['A1b2', '1b2a', 'B2a1', '2a1b'], dtype='|S4')", "score": "0.7254989"}]}
{"task_id": 527, "text": "Write a function to find all pairs in an integer array whose sum is equal to a given number.", "code": "def get_pairs_count(arr, n, sum):\r\n    count = 0 \r\n    for i in range(0, n):\r\n        for j in range(i + 1, n):\r\n            if arr[i] + arr[j] == sum:\r\n                count += 1\r\n    return count", "test_list": ["assert get_pairs_count([1, 5, 7, -1, 5], 5, 6) == 3", "assert get_pairs_count([1, 5, 7, -1], 4, 6) == 2", "assert get_pairs_count([1, 1, 1, 1], 4, 2) == 6"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21297", "text": "Function: python.library.itertools\nSnippet: * (n - k + i) // i if index < 0: index += c if index < 0 or index >= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index >= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)", "score": "0.66371495"}, {"id": "24549", "text": "Function: python.library.functions#sum\nSnippet: sum(iterable, /, start=0) Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument.", "score": "0.6559051"}, {"id": "25736", "text": "Function: python.library.stdtypes\nSnippet: s.index(x[, i[, j]]) index of the first occurrence of x in s (at or after index i and before index j) (8) s.count(x) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Notes: While the in and not in operations are used only for simple containment testing in the general case, some specialised sequences (such as str, bytes and bytearray) also use them for subsequence testing: >>> \"gg\" in \"eggs\" True Values of n less than 0 are treated as 0 (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: >>> lists = [[]] * 3 >>> lists [[], [], []] >>> lists[0].append(3) >>> lists [[3], [3], [3]] What has happened is that [[]] is a one-element list containing an empty list, so all three elements of [[]] * 3 are references to this single empty list. Modifying any of the elements of lists modifies this single list. You can create a list of different lists this way: >>> lists = [[] for i in range(3)] >>> lists[0].append(3) >>> lists[1].append(5) >>> lists[2].append(7) >>> lists [[3], [5], [7]] Further explanation is available in the FAQ entry How do I create a multidimensional list?. If i or j is negative, the index is relative to the end of sequence s: len(s) + i or len(s) + j is substituted. But note that -0 is still 0. The slice of s from i to j is defined as the sequence of items with index k such that i <= k < j. If i or j is greater than len(s), use len(s). If i is omitted or None, use 0. If j is omitted or None, use len(s). If i is greater than or equal to j, the slice is empty. The slice of s from i to j with step k is defined as the sequence of items with index x = i + n*k such that 0 <= n < (j-i)/k. In other words, the indices are i, i+k, i+2*k, i+3*k and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to len(s) if they are greater. When k is negative, i and j are reduced to len(s) - 1 if they are greater. If i or j are omitted or None, they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is None, it is treated like 1. Concatenating immutable sequences always results in a new object. This means that building up", "score": "0.65159905"}, {"id": "42960", "text": "Function: numpy.user.basics.rec#numpy.lib.recfunctions.find_duplicates\nSnippet: numpy.lib.recfunctions.find_duplicates(a, key=None, ignoremask=True, return_index=False)[source] Find the duplicates in a structured array along a given key Parameters aarray-like Input array key{string, None}, optional Name of the fields along which to check the duplicates. If None, the search is performed by records ignoremask{True, False}, optional Whether masked data should be discarded or considered as duplicates. return_index{False, True}, optional Whether to return the indices of the duplicated values. Examples >>> from numpy.lib import recfunctions as rfn >>> ndtype = [('a', int)] >>> a = np.ma.array([1, 1, 1, 2, 2, 3, 3], ... mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype) >>> rfn.find_duplicates(a, ignoremask=True, return_index=True) (masked_array(data=[(1,), (1,), (2,), (2,)], mask=[(False,), (False,), (False,), (False,)], fill_value=(999999,), dtype=[('a', '<i8')]), array([0, 1, 3, 4]))", "score": "0.6510198"}, {"id": "21070", "text": "Function: python.library.stdtypes#int.as_integer_ratio\nSnippet: int.as_integer_ratio() Return a pair of integers whose ratio is exactly equal to the original integer and with a positive denominator. The integer ratio of integers (whole numbers) is always the integer as the numerator and 1 as the denominator. New in version 3.8.", "score": "0.64831054"}]}
{"task_id": 528, "text": "Write a function to find the list of lists with minimum length.", "code": "def min_length(list1):\r\n   min_length = min(len(x) for x in  list1 )  \r\n   min_list = min((x) for x in   list1)\r\n   return(min_length, min_list)     ", "test_list": ["assert min_length([[0], [1, 3], [5, 7], [9, 11], [13, 15, 17]])==(1, [0])", "assert min_length([[1], [5, 7], [10, 12, 14,15]])==(1, [1])", "assert min_length([[5], [15,20,25]])==(1, [5])"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21889", "text": "Function: python.library.functions#min\nSnippet: min(iterable, *[, key, default]) min(arg1, arg2, *args[, key]) Return the smallest item in an iterable or the smallest of two or more arguments. If one positional argument is provided, it should be an iterable. The smallest item in the iterable is returned. If two or more positional arguments are provided, the smallest of the positional arguments is returned. There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function like that used for list.sort(). The default argument specifies an object to return if the provided iterable is empty. If the iterable is empty and default is not provided, a ValueError is raised. If multiple items are minimal, the function returns the first one encountered. This is consistent with other sort-stability preserving tools such as sorted(iterable, key=keyfunc)[0] and heapq.nsmallest(1, iterable, key=keyfunc). New in version 3.4: The default keyword-only argument. Changed in version 3.8: The key can be None.", "score": "0.69213283"}, {"id": "21919", "text": "Function: python.library.mmap#mmap.mmap.find\nSnippet: find(sub[, start[, end]]) Returns the lowest index in the object where the subsequence sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Returns -1 on failure. Changed in version 3.5: Writable bytes-like object is now accepted.", "score": "0.6818942"}, {"id": "43859", "text": "Function: numpy.reference.generated.numpy.recarray.min\nSnippet: numpy.recarray.min method recarray.min(axis=None, out=None, keepdims=False, initial=<no value>, where=True) Return the minimum along a given axis. Refer to numpy.amin for full documentation. See also numpy.amin equivalent function", "score": "0.6765219"}, {"id": "42756", "text": "Function: numpy.reference.distutils.misc_util#numpy.distutils.misc_util.as_list\nSnippet: numpy.distutils.misc_util.as_list(seq)[source]", "score": "0.6711629"}, {"id": "41654", "text": "Function: numpy.reference.generated.numpy.char.chararray.find\nSnippet: numpy.char.chararray.find method char.chararray.find(sub, start=0, end=None)[source] For each element, return the lowest index in the string where substring sub is found. See also char.find", "score": "0.66902554"}]}
{"task_id": 529, "text": "Write a function to find the nth jacobsthal-lucas number.", "code": "def jacobsthal_lucas(n): \r\n\tdp=[0] * (n + 1) \r\n\tdp[0] = 2\r\n\tdp[1] = 1\r\n\tfor i in range(2, n+1): \r\n\t\tdp[i] = dp[i - 1] + 2 * dp[i - 2]; \r\n\treturn dp[n]", "test_list": ["assert jacobsthal_lucas(5) == 31", "assert jacobsthal_lucas(2) == 5", "assert jacobsthal_lucas(4) == 17"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43141", "text": "Function: numpy.reference.generated.numpy.ravel\nSnippet: 3, 4, 5, 6, 7, 8, 9, 10, 11])", "score": "0.6679266"}, {"id": "35797", "text": "Function: django.ref.models.database-functions#django.db.models.functions.NthValue\nSnippet: class NthValue(expression, nth=1, **extra)", "score": "0.65621364"}, {"id": "22281", "text": "Function: python.library.numbers#numbers.Rational.numerator\nSnippet: numerator Abstract.", "score": "0.6466055"}, {"id": "43079", "text": "Function: numpy.reference.generated.numpy.pad\nSnippet: 100], [100, 100, 100, 100, 100, 100, 100]])", "score": "0.64628327"}, {"id": "7524", "text": "Function: torch.generated.torch.polygamma#torch.polygamma\nSnippet: torch.polygamma(n, input, *, out=None) → Tensor Computes the nthn^{th} derivative of the digamma function on input. n≥0n \\geq 0 is called the order of the polygamma function. ψ(n)(x)=d(n)dx(n)ψ(x)\\psi^{(n)}(x) = \\frac{d^{(n)}}{dx^{(n)}} \\psi(x) Note This function is implemented only for nonnegative integers n≥0n \\geq 0 . Parameters n (int) – the order of the polygamma function input (Tensor) – the input tensor. Keyword Arguments out (Tensor, optional) – the output tensor. Example:: >>> a = torch.tensor([1, 0.5]) >>> torch.polygamma(1, a) tensor([1.64493, 4.9348]) >>> torch.polygamma(2, a) tensor([ -2.4041, -16.8288]) >>> torch.polygamma(3, a) tensor([ 6.4939, 97.4091]) >>> torch.polygamma(4, a) tensor([ -24.8863, -771.4742])", "score": "0.64544135"}]}
{"task_id": 530, "text": "Write a function to find the ration of negative numbers in an array of integers.", "code": "from array import array\r\ndef negative_count(nums):\r\n    n = len(nums)\r\n    n1 = 0\r\n    for x in nums:\r\n        if x < 0:\r\n            n1 += 1\r\n        else:\r\n          None\r\n    return round(n1/n,2)", "test_list": ["assert negative_count([0, 1, 2, -1, -5, 6, 0, -3, -2, 3, 4, 6, 8])==0.31", "assert negative_count([2, 1, 2, -1, -5, 6, 4, -3, -2, 3, 4, 6, 8])==0.31", "assert negative_count([2, 4, -6, -9, 11, -12, 14, -5, 17])==0.44"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "6236", "text": "Function: torch.distributions#torch.distributions.negative_binomial.NegativeBinomial.support\nSnippet: support = IntegerGreaterThan(lower_bound=0)", "score": "0.6823731"}, {"id": "20204", "text": "Function: python.library.fractions#fractions.Fraction.as_integer_ratio\nSnippet: as_integer_ratio() Return a tuple of two integers, whose ratio is equal to the Fraction and with a positive denominator. New in version 3.8.", "score": "0.6743587"}, {"id": "21070", "text": "Function: python.library.stdtypes#int.as_integer_ratio\nSnippet: int.as_integer_ratio() Return a pair of integers whose ratio is exactly equal to the original integer and with a positive denominator. The integer ratio of integers (whole numbers) is always the integer as the numerator and 1 as the denominator. New in version 3.8.", "score": "0.6648759"}, {"id": "13013", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos#sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.66367024"}, {"id": "12778", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.6600215"}]}
{"task_id": 531, "text": "Write a function to find minimum number of coins that make a given value.", "code": "import sys \r\ndef min_coins(coins, m, V): \r\n    if (V == 0): \r\n        return 0\r\n    res = sys.maxsize \r\n    for i in range(0, m): \r\n        if (coins[i] <= V): \r\n            sub_res = min_coins(coins, m, V-coins[i]) \r\n            if (sub_res != sys.maxsize and sub_res + 1 < res): \r\n                res = sub_res + 1  \r\n    return res ", "test_list": ["assert min_coins([9, 6, 5, 1] ,4,11)==2", "assert min_coins([4,5,6,7,8,9],6,9)==1", "assert min_coins([1, 2, 3],3,4)==2"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19492", "text": "Function: python.library.decimal#decimal.Context.min\nSnippet: min(x, y) Compares two values numerically and returns the minimum.", "score": "0.6838985"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6803576"}, {"id": "21823", "text": "Function: python.library.math#math.perm\nSnippet: math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8.", "score": "0.6634635"}, {"id": "19589", "text": "Function: python.library.decimal#decimal.MIN_ETINY\nSnippet: decimal.MIN_ETINY", "score": "0.65187144"}, {"id": "13013", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos#sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.6477383"}]}
{"task_id": 532, "text": "Write a function to check if the two given strings are permutations of each other.", "code": "def check_permutation(str1, str2):\r\n  n1=len(str1)\r\n  n2=len(str2)\r\n  if(n1!=n2):\r\n    return False\r\n  a=sorted(str1)\r\n  str1=\" \".join(a)\r\n  b=sorted(str2)\r\n  str2=\" \".join(b)\r\n  for i in range(0, n1, 1):\r\n    if(str1[i] != str2[i]):\r\n      return False\r\n  return True", "test_list": ["assert check_permutation(\"abc\", \"cba\") == True", "assert check_permutation(\"test\", \"ttew\") == False", "assert check_permutation(\"xxyz\", \"yxzx\") == True"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21310", "text": "Function: python.library.itertools#itertools.permutations\nSnippet: itertools.permutations(iterable, r=None) Return successive r length permutations of elements in the iterable. If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.71714795"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.70916426"}, {"id": "21290", "text": "Function: python.library.itertools\nSnippet: iterables are exhausted. Used for treating consecutive sequences as a single sequence. Roughly equivalent to: def chain(*iterables): # chain('ABC', 'DEF') --> A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily. Roughly equivalent to: def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n", "score": "0.666531"}, {"id": "21301", "text": "Function: python.library.itertools#itertools.combinations\nSnippet: itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.66530377"}, {"id": "42687", "text": "Function: numpy.reference.generated.numpy.char.chararray\nSnippet: sort this array. copy([order]) Return a copy of the array. count(sub[, start, end]) Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end]. decode([encoding, errors]) Calls str.decode element-wise. dump(file) Dump a pickle of the array to the specified file. dumps() Returns the pickle of the array as a string. encode([encoding, errors]) Calls str.encode element-wise. endswith(suffix[, start, end]) Returns a boolean array which is True where the string element in self ends with suffix, otherwise False. expandtabs([tabsize]) Return a copy of each string element where all tab characters are replaced by one or more spaces. fill(value) Fill the array with a scalar value. find(sub[, start, end]) For each element, return the lowest index in the string where substring sub is found. flatten([order]) Return a copy of the array collapsed into one dimension. getfield(dtype[, offset]) Returns a field of the given array as a certain type. index(sub[, start, end]) Like find, but raises ValueError when the substring is not found. isalnum() Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise. isalpha() Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise. isdecimal() For each element in self, return True if there are only decimal characters in the element. isdigit() Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise. islower() Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise. isnumeric() For each element in self, return True if there are only numeric characters in the element. isspace() Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise. istitle() Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise. isupper() Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise. item(*args) Copy an element of an array to a standard Python scalar and return it. join(seq) Return a string which is the concatenation of the strings in the sequence seq. ljust(width[, fillchar]) Return an array with the elements of self left-justified in a string of length width. lower() Return an array with the elements of self converted to lowercase. lstrip([chars]) For each element in self, return a copy with the leading characters removed. nonzero() Return the indices of the elements that are non-zero. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. replace(old, new[, count]) For each element in self, return a copy of the string with all occurrences of substring old replaced by new. reshape(shape[, order]) Returns an array containing the", "score": "0.66178685"}]}
{"task_id": 533, "text": "Write a function to remove particular data type elements from the given tuple.", "code": "def remove_datatype(test_tuple, data_type):\r\n  res = []\r\n  for ele in test_tuple:\r\n    if not isinstance(ele, data_type):\r\n      res.append(ele)\r\n  return (res) ", "test_list": ["assert remove_datatype((4, 5, 4, 7.7, 1.2), int) == [7.7, 1.2]", "assert remove_datatype((7, 8, 9, \"SR\"), str) == [7, 8, 9]", "assert remove_datatype((7, 1.1, 2, 2.2), float) == [7, 2]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19611", "text": "Function: python.library.stdtypes#dict.clear\nSnippet: clear() Remove all items from the dictionary.", "score": "0.7142135"}, {"id": "25756", "text": "Function: python.library.stdtypes\nSnippet: binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> b'Monty Python'.rstrip(b' Python') b'M' >>> b'Monty Python'.removesuffix(b' Python') b'Monty' Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. bytes.split(sep=None, maxsplit=-1) bytearray.split(sep=None, maxsplit=-1) Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object. For example: >>> b'1,2,3'.split(b',') [b'1', b'2', b'3'] >>> b'1,2,3'.split(b',', maxsplit=1) [b'1', b'2,3'] >>> b'1,2,,3,'.split(b',') [b'1', b'2', b'', b'3', b''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns []. For example: >>> b'1 2 3'.split() [b'1', b'2', b'3'] >>> b'1 2 3'.split(maxsplit=1) [b'1', b'2 3'] >>> b' 1 2 3 '.split() [b'1', b'2', b'3'] bytes.strip([chars]) bytearray.strip([chars]) Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped: >>> b' spacious '.strip() b'spacious' >>> b'www.example.com'.strip(b'cmowz.') b'example' The binary sequence of byte values to remove may be any bytes-like object. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. The following methods on bytes and bytearray objects assume the use of ASCII compatible binary formats and should not be applied to arbitrary binary data. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects. bytes.capitalize() bytearray.capitalize() Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized and the rest", "score": "0.70854205"}, {"id": "20217", "text": "Function: python.library.stdtypes#frozenset.clear\nSnippet: clear() Remove all elements from the set.", "score": "0.70799756"}, {"id": "25738", "text": "Function: python.library.stdtypes\nSnippet: from s (2) s.remove(x) remove the first item from s where s[i] is equal to x (3) s.reverse() reverses the items of s in place (4) Notes: t must have the same length as the slice it is replacing. The optional argument i defaults to -1, so that by default the last item is removed and returned. remove() raises ValueError when x is not found in s. The reverse() method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence. clear() and copy() are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as dict and set). copy() is not part of the collections.abc.MutableSequence ABC, but most concrete mutable sequence classes provide it. New in version 3.3: clear() and copy() methods. The value n is an integer, or an object implementing __index__(). Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for s * n under Common Sequence Operations. Lists Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). class list([iterable]) Lists may be constructed in several ways: Using a pair of square brackets to denote the empty list: [] Using square brackets, separating items with commas: [a], [a, b, c] Using a list comprehension: [x for x in iterable] Using the type constructor: list() or list(iterable) The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to iterable[:]. For example, list('abc') returns ['a', 'b', 'c'] and list( (1, 2, 3) ) returns [1, 2, 3]. If no argument is given, the constructor creates a new empty list, []. Many other operations also produce lists, including the sorted() built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: sort(*, key=None, reverse=False) This method sorts the list in place, using only < comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). sort() accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value. The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function. reverse is", "score": "0.69702125"}, {"id": "18327", "text": "Function: python.library.stdtypes#bytes.removesuffix\nSnippet: bytes.removesuffix(suffix, /) bytearray.removesuffix(suffix, /) If the binary data ends with the suffix string and that suffix is not empty, return bytes[:-len(suffix)]. Otherwise, return a copy of the original binary data: >>> b'MiscTests'.removesuffix(b'Tests') b'Misc' >>> b'TmpDirMixin'.removesuffix(b'Tests') b'TmpDirMixin' The suffix may be any bytes-like object. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. New in version 3.9.", "score": "0.68709975"}]}
{"task_id": 534, "text": "Write a function to search a literals string in a string and also find the location within the original string where the pattern occurs.", "code": "import re\r\ndef search_literal(pattern,text):\r\n match = re.search(pattern, text)\r\n s = match.start()\r\n e = match.end()\r\n return (s, e)", "test_list": ["assert search_literal('python','python programming language')==(0,6)", "assert search_literal('programming','python programming language')==(7,18)", "assert search_literal('language','python programming language')==(19,27)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23361", "text": "Function: python.library.re#re.Pattern.search\nSnippet: Pattern.search(string[, pos[, endpos]]) Scan through string looking for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\"", "score": "0.75961155"}, {"id": "23367", "text": "Function: python.library.re#re.search\nSnippet: re.search(pattern, string, flags=0) Scan through string looking for the first location where the regular expression pattern produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string.", "score": "0.74109465"}, {"id": "23310", "text": "Function: python.library.re\nSnippet: for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\" Pattern.match(string[, pos[, endpos]]) If zero or more characters at the beginning of string match this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o\") >>> pattern.match(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.match(\"dog\", 1) # Match as \"o\" is the 2nd character of \"dog\". <re.Match object; span=(1, 2), match='o'> If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()). Pattern.fullmatch(string[, pos[, endpos]]) If the whole string matches this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o[gh]\") >>> pattern.fullmatch(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.fullmatch(\"ogre\") # No match as not the full string matches. >>> pattern.fullmatch(\"doggie\", 1, 3) # Matches within given limits. <re.Match object; span=(1, 3), match='og'> New in version 3.4. Pattern.split(string, maxsplit=0) Identical to the split() function, using the compiled pattern. Pattern.findall(string[, pos[, endpos]]) Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.finditer(string[, pos[, endpos]]) Similar to the finditer() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.sub(repl, string, count=0) Identical to the sub() function, using the compiled pattern. Pattern.subn(repl, string, count=0) Identical to the subn() function, using the compiled pattern. Pattern.flags The regex", "score": "0.7410381"}, {"id": "23353", "text": "Function: python.library.re#re.Pattern.findall\nSnippet: Pattern.findall(string[, pos[, endpos]]) Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search().", "score": "0.7207191"}, {"id": "23359", "text": "Function: python.library.re#re.Pattern.match\nSnippet: Pattern.match(string[, pos[, endpos]]) If zero or more characters at the beginning of string match this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o\") >>> pattern.match(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.match(\"dog\", 1) # Match as \"o\" is the 2nd character of \"dog\". <re.Match object; span=(1, 2), match='o'> If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()).", "score": "0.7193577"}]}
{"task_id": 535, "text": "Write a function to find the top or bottom surface area of a cylinder.", "code": "def topbottom_surfacearea(r):\r\n  toporbottomarea=3.1415*r*r\r\n  return toporbottomarea", "test_list": ["assert topbottom_surfacearea(10)==314.15000000000003", "assert topbottom_surfacearea(5)==78.53750000000001", "assert topbottom_surfacearea(4)==50.264"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "33487", "text": "Function: matplotlib._as_gen.matplotlib.quiver.barbs#matplotlib.quiver.Barbs.barbs_doc\nSnippet: barbs_doc='\\nPlot a 2D field of barbs.\\n\\nCall signature::\\n\\n barbs([X, Y], U, V, [C], **kw)\\n\\nWhere *X*, *Y* define the barb locations, *U*, *V* define the barb\\ndirections, and *C* optionally sets the color.\\n\\nAll arguments may be 1D or 2D. *U*, *V*, *C* may be masked arrays, but masked\\n*X*, *Y* are not supported at present.\\n\\nBarbs are traditionally used in meteorology as a way to plot the speed\\nand direction of wind observations, but can technically be used to\\nplot any two dimensional vector quantity. As opposed to arrows, which\\ngive vector magnitude by the length of the arrow, the barbs give more\\nquantitative information about the vector magnitude by putting slanted\\nlines or a triangle for various increments in magnitude, as show\\nschematically below::\\n\\n : /\\\\ \\\\\\n : / \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : ------------------------------\\n\\nThe largest increment is given by a triangle (or \"flag\"). After those\\ncome full lines (barbs). The smallest increment is a half line. There\\nis only, of course, ever at most 1 half line. If the magnitude is\\nsmall and only needs a single half-line and no full lines or\\ntriangles, the half-line is offset from the end of the barb so that it\\ncan be easily distinguished from barbs with a single full line. The\\nmagnitude for the barb shown above would nominally be 65, using the\\nstandard increments of 50, 10, and 5.\\n\\nSee also https://en.wikipedia.org/wiki/Wind_barb.\\n\\nParameters\\n----------\\nX, Y : 1D or 2D array-like, optional\\n The x and y coordinates of the barb locations. See *pivot* for how the\\n barbs are drawn to the x, y positions.\\n\\n If not given, they will be generated as a uniform integer meshgrid based\\n on the dimensions of *U* and *V*.\\n\\n If *X* and *Y* are 1D but *U*, *V* are 2D, *X*, *Y* are expanded to 2D\\n using ``X, Y = np.meshgrid(X, Y)``. In this case ``len(X)`` and ``len(Y)``\\n must match the column and row dimensions of *U* and *V*.\\n\\nU, V : 1D or 2D array-like\\n The x and y components of the barb shaft.\\n\\nC : 1D or 2D array-like, optional\\n Numeric data that defines the barb colors by colormapping via *norm* and\\n *cmap*.\\n\\n This does not support explicit colors. If you want to set colors directly,\\n use *barbcolor* instead.\\n\\nlength : float, default: 7\\n Length of the barb in points; the other parts of the barb\\n are scaled against this.\\n\\npivot : {\\'tip\\', \\'middle\\'} or float, default: \\'tip\\'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The barb\\n rotates about this point. This can also be a number, which shifts the\\n start of the barb that many points away from grid point.\\n\\nbarbcolor : color or color sequence\\n The color of all parts of the barb except for the flags. This parameter\\n is analogous to the *edgecolor* parameter for polygons, which can be used\\n instead. However this parameter will override facecolor.\\n\\nflagcolor : color or color sequence\\n The color of any flags on the barb. This parameter is analogous to the\\n *facecolor* parameter for polygons, which can be used instead. However,\\n this parameter will override facecolor. If", "score": "0.6628839"}, {"id": "17024", "text": "Function: skimage.api.skimage.measure#skimage.measure.mesh_surface_area\nSnippet: skimage.measure.mesh_surface_area(verts, faces) [source] Compute surface area, given vertices & triangular faces Parameters verts(V, 3) array of floats Array containing (x, y, z) coordinates for V unique mesh vertices. faces(F, 3) array of ints List of length-3 lists of integers, referencing vertex coordinates as provided in verts Returns areafloat Surface area of mesh. Units now [coordinate units] ** 2. See also skimage.measure.marching_cubes skimage.measure.marching_cubes_classic Notes The arguments expected by this function are the first two outputs from skimage.measure.marching_cubes. For unit correct output, ensure correct spacing was passed to skimage.measure.marching_cubes. This algorithm works properly only if the faces provided are all triangles.", "score": "0.6576484"}, {"id": "13179", "text": "Function: pygame.ref.draw\nSnippet: the given surface. The line has a thickness of one pixel and the endpoints have a height and width of one pixel each. The way a line and it's endpoints are drawn: If both endpoints are equal, only a single pixel is drawn (after rounding floats to nearest integer). Otherwise if the line is not steep (i.e. if the length along the x-axis is greater than the height along the y-axis): For each endpoint: If x, the endpoint's x-coordinate, is a whole number find which pixels would be covered by it and draw them. Otherwise: Calculate the position of the nearest point with a whole number for it's x-coordinate, when extending the line past the endpoint. Find which pixels would be covered and how much by that point. If the endpoint is the left one, multiply the coverage by (1 - the decimal part of x). Otherwise multiply the coverage by the decimal part of x. Then draw those pixels. e.g.: The left endpoint of the line ((1, 1.3), (5, 3)) would cover 70% of the pixel (1, 1) and 30% of the pixel (1, 2) while the right one would cover 100% of the pixel (5, 3). The left endpoint of the line ((1.2, 1.4), (4.6, 3.1)) would cover 56% (i.e. 0.8 * 70%) of the pixel (1, 1) and 24% (i.e. 0.8 * 30%) of the pixel (1, 2) while the right one would cover 42% (i.e. 0.6 * 70%) of the pixel (5, 3) and 18% (i.e. 0.6 * 30%) of the pixel (5, 4) while the right Then for each point between the endpoints, along the line, whose x-coordinate is a whole number: Find which pixels would be covered and how much by that point and draw them. e.g.: The points along the line ((1, 1), (4, 2.5)) would be (2, 1.5) and (3, 2) and would cover 50% of the pixel (2, 1), 50% of the pixel (2, 2) and 100% of the pixel (3, 2). The points along the line ((1.2, 1.4), (4.6, 3.1)) would be (2, 1.8) (covering 20% of the pixel (2, 1) and 80% of the pixel (2, 2)), (3, 2.3) (covering 70% of the pixel (3, 2) and 30% of the pixel (3, 3)) and (4, 2.8) (covering 20% of the pixel (2, 1) and 80% of the pixel (2, 2)) Otherwise do the same for steep lines as for non-steep lines except along the y-axis instead of the x-axis (using y instead of x, top instead of left and bottom instead of right). Note Regarding float values for coordinates, a point with coordinate consisting of two whole numbers is considered being right in the center of said pixel (and having a height and width of 1 pixel would therefore completely cover it), while a point with coordinate where one (or both) of the numbers have non-zero decimal parts would be partially covering two (or four if both numbers have decimal parts) adjacent pixels, e.g. the point (1.4, 2) covers", "score": "0.6567912"}, {"id": "16631", "text": "Function: skimage.api.skimage.draw\nSnippet: ellipsoid_stats skimage.draw.ellipsoid_stats(a, b, c) [source] Calculates analytical surface area and volume for ellipsoid with semimajor axes aligned with grid dimensions of specified spacing. Parameters afloat Length of semimajor axis aligned with x-axis. bfloat Length of semimajor axis aligned with y-axis. cfloat Length of semimajor axis aligned with z-axis. Returns volfloat Calculated volume of ellipsoid. surffloat Calculated surface area of ellipsoid. line skimage.draw.line(r0, c0, r1, c1) [source] Generate line pixel coordinates. Parameters r0, c0int Starting position (row, column). r1, c1int End position (row, column). Returns rr, cc(N,) ndarray of int Indices of pixels that belong to the line. May be used to directly index into an array, e.g. img[rr, cc] = 1. Notes Anti-aliased line generator is available with line_aa. Examples >>> from skimage.draw import line >>> img = np.zeros((10, 10), dtype=np.uint8) >>> rr, cc = line(1, 1, 8, 8) >>> img[rr, cc] = 1 >>> img array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8) line_aa skimage.draw.line_aa(r0, c0, r1, c1) [source] Generate anti-aliased line pixel coordinates. Parameters r0, c0int Starting position (row, column). r1, c1int End position (row, column). Returns rr, cc, val(N,) ndarray (int, int, float) Indices of pixels (rr, cc) and intensity values (val). img[rr, cc] = val. References 1 A Rasterizing Algorithm for Drawing Curves, A. Zingl, 2012 http://members.chello.at/easyfilter/Bresenham.pdf Examples >>> from skimage.draw import line_aa >>> img = np.zeros((10, 10), dtype=np.uint8) >>> rr, cc, val = line_aa(1, 1, 8, 8) >>> img[rr, cc] = val * 255 >>> img array([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 255, 74, 0, 0, 0, 0, 0, 0, 0], [ 0, 74, 255, 74, 0, 0, 0, 0, 0, 0], [ 0, 0, 74, 255, 74, 0, 0, 0, 0, 0], [ 0, 0, 0, 74, 255, 74, 0, 0, 0, 0], [ 0, 0, 0, 0, 74, 255, 74, 0, 0, 0], [ 0, 0, 0, 0, 0, 74, 255, 74, 0, 0], [ 0, 0, 0, 0, 0, 0, 74, 255, 74, 0], [ 0, 0, 0, 0, 0, 0, 0, 74, 255, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8) line_nd skimage.draw.line_nd(start, stop, *, endpoint=False, integer=True) [source] Draw a single-pixel thick line in n dimensions. The line produced will be ndim-connected. That is, two subsequent pixels in the line will be either direct or diagonal neighbours in n dimensions. Parameters startarray-like, shape (N,) The start coordinates of the line. stoparray-like, shape (N,) The end coordinates", "score": "0.6488901"}, {"id": "25627", "text": "Function: python.library.turtle#turtle.dot\nSnippet: turtle.dot(size=None, *color) Parameters size – an integer >= 1 (if given) color – a colorstring or a numeric color tuple Draw a circular dot with diameter size, using color. If size is not given, the maximum of pensize+4 and 2*pensize is used. >>> turtle.home() >>> turtle.dot() >>> turtle.fd(50); turtle.dot(20, \"blue\"); turtle.fd(50) >>> turtle.position() (100.00,-0.00) >>> turtle.heading() 0.0", "score": "0.64838415"}]}
{"task_id": 536, "text": "Write a function to select the nth items of a list.", "code": "def nth_items(list,n):\r\n return list[::n]", "test_list": ["assert nth_items([1, 2, 3, 4, 5, 6, 7, 8, 9],2)==[1, 3, 5, 7, 9] ", "assert nth_items([10,15,19,17,16,18],3)==[10,17] ", "assert nth_items([14,16,19,15,17],4)==[14,17]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "26754", "text": "Function: python.library.xml.dom#xml.dom.NodeList.item\nSnippet: NodeList.item(i) Return the i’th item from the sequence, if there is one, or None. The index i is not allowed to be less than zero or greater than or equal to the length of the sequence.", "score": "0.69928646"}, {"id": "21291", "text": "Function: python.library.itertools\nSnippet: = len(pool) for indices in product(range(n), repeat=r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is (n+r-1)! / r! / (n-1)! when n > 0. New in version 3.1. itertools.compress(data, selectors) Make an iterator that filters elements from data returning only those that have a corresponding element in selectors that evaluates to True. Stops when either the data or selectors iterables has been exhausted. Roughly equivalent to: def compress(data, selectors): # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F return (d for d, s in zip(data, selectors) if s) New in version 3.1. itertools.count(start=0, step=1) Make an iterator that returns evenly spaced values starting with number start. Often used as an argument to map() to generate consecutive data points. Also, used with zip() to add sequence numbers. Roughly equivalent to: def count(start=0, step=1): # count(10) --> 10 11 12 13 14 ... # count(2.5, 0.5) -> 2.5 3.0 3.5 ... n = start while True: yield n n += step When counting with floating point numbers, better accuracy can sometimes be achieved by substituting multiplicative code such as: (start + step * i for i in count()). Changed in version 3.1: Added step argument and allowed non-integer arguments. itertools.cycle(iterable) Make an iterator returning elements from the iterable and saving a copy of each. When the iterable is exhausted, return elements from the saved copy. Repeats indefinitely. Roughly equivalent to: def cycle(iterable): # cycle('ABCD') --> A B C D A B C D A B C D ... saved = [] for element in iterable: yield element saved.append(element) while saved: for element in saved: yield element Note, this member of the toolkit may require significant auxiliary storage (depending on the length of the iterable). itertools.dropwhile(predicate, iterable) Make an iterator that drops elements from the iterable as long as the predicate is true; afterwards, returns every element. Note, the iterator does not produce any output until the predicate first becomes false, so it may have a lengthy start-up time. Roughly equivalent to: def dropwhile(predicate, iterable): # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1 iterable = iter(iterable) for x in iterable: if not predicate(x): yield x break for x in iterable: yield x itertools.filterfalse(predicate, iterable) Make an iterator that filters elements from iterable returning only those for which the predicate is False. If predicate is None, return the items that are false. Roughly equivalent to: def filterfalse(predicate, iterable): # filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8 if predicate is None: predicate = bool for x in iterable: if not predicate(x): yield x itertools.groupby(iterable, key=None) Make an iterator that returns consecutive keys and groups from the iterable. The key is a function computing a key value for each element. If not specified or is None, key defaults to an identity function and returns the element unchanged. Generally, the iterable needs to already be sorted on the same key function. The operation of groupby() is similar to the uniq filter in Unix. It generates a", "score": "0.6864302"}, {"id": "25318", "text": "Function: python.library.tkinter.ttk\nSnippet: the options to the corresponding values as given by kw. move(item, parent, index) Moves item to position index in parent’s list of children. It is illegal to move an item under one of its descendants. If index is less than or equal to zero, item is moved to the beginning; if greater than or equal to the number of children, it is moved to the end. If item was detached it is reattached. next(item) Returns the identifier of item’s next sibling, or ‘’ if item is the last child of its parent. parent(item) Returns the ID of the parent of item, or ‘’ if item is at the top level of the hierarchy. prev(item) Returns the identifier of item’s previous sibling, or ‘’ if item is the first child of its parent. reattach(item, parent, index) An alias for Treeview.move(). see(item) Ensure that item is visible. Sets all of item’s ancestors open option to True, and scrolls the widget if necessary so that item is within the visible portion of the tree. selection() Returns a tuple of selected items. Changed in version 3.8: selection() no longer takes arguments. For changing the selection state use the following selection methods. selection_set(*items) items becomes the new selection. Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple. selection_add(*items) Add items to the selection. Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple. selection_remove(*items) Remove items from the selection. Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple. selection_toggle(*items) Toggle the selection state of each item in items. Changed in version 3.6: items can be passed as separate arguments, not just as a single tuple. set(item, column=None, value=None) With one argument, returns a dictionary of column/value pairs for the specified item. With two arguments, returns the current value of the specified column. With three arguments, sets the value of given column in given item to the specified value. tag_bind(tagname, sequence=None, callback=None) Bind a callback for the given event sequence to the tag tagname. When an event is delivered to an item, the callbacks for each of the item’s tags option are called. tag_configure(tagname, option=None, **kw) Query or modify the options for the specified tagname. If kw is not given, returns a dict of the option settings for tagname. If option is specified, returns the value for that option for the specified tagname. Otherwise, sets the options to the corresponding values for the given tagname. tag_has(tagname, item=None) If item is specified, returns 1 or 0 depending on whether the specified item has the given tagname. Otherwise, returns a list of all items that have the specified tag. Availability: Tk 8.6 xview(*args) Query or modify horizontal position of the treeview. yview(*args) Query or modify vertical position of the treeview. Ttk Styling Each widget in ttk is assigned a style, which specifies the set of elements making up the widget and how they are arranged,", "score": "0.683918"}, {"id": "21309", "text": "Function: python.library.itertools#itertools.islice\nSnippet: itertools.islice(iterable, stop) itertools.islice(iterable, start, stop[, step]) Make an iterator that returns selected elements from the iterable. If start is non-zero, then elements from the iterable are skipped until start is reached. Afterward, elements are returned consecutively unless step is set higher than one which results in items being skipped. If stop is None, then iteration continues until the iterator is exhausted, if at all; otherwise, it stops at the specified position. Unlike regular slicing, islice() does not support negative values for start, stop, or step. Can be used to extract related fields from data where the internal structure has been flattened (for example, a multi-line report may list a name field on every third line). Roughly equivalent to: def islice(iterable, *args): # islice('ABCDEFG', 2) --> A B # islice('ABCDEFG', 2, 4) --> C D # islice('ABCDEFG', 2, None) --> C D E F G # islice('ABCDEFG', 0, None, 2) --> A C E G s = slice(*args) start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1 it = iter(range(start, stop, step)) try: nexti = next(it) except StopIteration: # Consume *iterable* up to the *start* position. for i, element in zip(range(start), iterable): pass return try: for i, element in enumerate(iterable): if i == nexti: yield element nexti = next(it) except StopIteration: # Consume to *stop*. for i, element in zip(range(i + 1, stop), iterable): pass If start is None, then iteration starts at zero. If step is None, then the step defaults to one.", "score": "0.67587554"}, {"id": "21296", "text": "Function: python.library.itertools\nSnippet: D E B F C\" # Recipe credited to George Sakkis num_active = len(iterables) nexts = cycle(iter(it).__next__ for it in iterables) while num_active: try: for next in nexts: yield next() except StopIteration: # Remove the iterator we just exhausted from the cycle. num_active -= 1 nexts = cycle(islice(nexts, num_active)) def partition(pred, iterable): \"Use a predicate to partition entries into false entries and true entries\" # partition(is_odd, range(10)) --> 0 2 4 6 8 and 1 3 5 7 9 t1, t2 = tee(iterable) return filterfalse(pred, t1), filter(pred, t2) def powerset(iterable): \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\" s = list(iterable) return chain.from_iterable(combinations(s, r) for r in range(len(s)+1)) def unique_everseen(iterable, key=None): \"List unique elements, preserving order. Remember all elements ever seen.\" # unique_everseen('AAAABBBCCDAABBB') --> A B C D # unique_everseen('ABBCcAD', str.lower) --> A B C D seen = set() seen_add = seen.add if key is None: for element in filterfalse(seen.__contains__, iterable): seen_add(element) yield element else: for element in iterable: k = key(element) if k not in seen: seen_add(k) yield element def unique_justseen(iterable, key=None): \"List unique elements, preserving order. Remember only the element just seen.\" # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B # unique_justseen('ABBCcAD', str.lower) --> A B C A D return map(next, map(operator.itemgetter(1), groupby(iterable, key))) def iter_except(func, exception, first=None): \"\"\" Call a function repeatedly until an exception is raised. Converts a call-until-exception interface to an iterator interface. Like builtins.iter(func, sentinel) but uses an exception instead of a sentinel to end the loop. Examples: iter_except(functools.partial(heappop, h), IndexError) # priority queue iterator iter_except(d.popitem, KeyError) # non-blocking dict iterator iter_except(d.popleft, IndexError) # non-blocking deque iterator iter_except(q.get_nowait, Queue.Empty) # loop over a producer Queue iter_except(s.pop, KeyError) # non-blocking set iterator \"\"\" try: if first is not None: yield first() # For database APIs needing an initial cast to db.first() while True: yield func() except exception: pass def first_true(iterable, default=False, pred=None): \"\"\"Returns the first true value in the iterable. If no true value is found, returns *default* If *pred* is not None, returns the first item for which pred(item) is true. \"\"\" # first_true([a,b,c], x) --> a or b or c or x # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x return next(filter(pred, iterable), default) def random_product(*args, repeat=1): \"Random selection from itertools.product(*args, **kwds)\" pools = [tuple(pool) for pool in args] * repeat return tuple(map(random.choice, pools)) def random_permutation(iterable, r=None): \"Random selection from itertools.permutations(iterable, r)\" pool = tuple(iterable) r = len(pool) if r is None else r return tuple(random.sample(pool, r)) def random_combination(iterable, r): \"Random selection from itertools.combinations(iterable, r)\" pool = tuple(iterable) n = len(pool) indices = sorted(random.sample(range(n), r)) return tuple(pool[i] for i in indices) def random_combination_with_replacement(iterable, r): \"Random selection from itertools.combinations_with_replacement(iterable, r)\" pool = tuple(iterable) n = len(pool) indices = sorted(random.choices(range(n), k=r)) return tuple(pool[i] for i in indices) def nth_combination(iterable, r, index): \"Equivalent to list(combinations(iterable, r))[index]\" pool = tuple(iterable) n = len(pool) if r < 0 or r > n: raise ValueError c = 1 k = min(r, n-r) for i in range(1, k+1): c = c", "score": "0.67194015"}]}
{"task_id": 537, "text": "Write a python function to find the first repeated word in a given string.", "code": "def first_repeated_word(str1):\r\n  temp = set()\r\n  for word in str1.split():\r\n    if word in temp:\r\n      return word;\r\n    else:\r\n      temp.add(word)\r\n  return 'None'", "test_list": ["assert first_repeated_word(\"ab ca bc ab\") == \"ab\"", "assert first_repeated_word(\"ab ca bc\") == 'None'", "assert first_repeated_word(\"ab ca bc ca ab bc\") == \"ca\""], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23308", "text": "Function: python.library.re\nSnippet: the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string. re.findall(pattern, string, flags=0) Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.finditer(pattern, string, flags=0) Return an iterator yielding match objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.sub(pattern, repl, string, count=0, flags=0) Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. For example: >>> re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', ... r'static PyObject*\\npy_\\1(void)\\n{', ... 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. For example: >>> def dashrepl(matchobj): ... if matchobj.group(0) == '-': return ' ' ... else: return '-' >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' >>> re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' The pattern may be a string or a pattern object. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern", "score": "0.69354945"}, {"id": "23368", "text": "Function: python.library.re#re.split\nSnippet: re.split(pattern, string, maxsplit=0, flags=0) Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. >>> re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] >>> re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] >>> re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.", "score": "0.6856166"}, {"id": "23310", "text": "Function: python.library.re\nSnippet: for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\" Pattern.match(string[, pos[, endpos]]) If zero or more characters at the beginning of string match this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o\") >>> pattern.match(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.match(\"dog\", 1) # Match as \"o\" is the 2nd character of \"dog\". <re.Match object; span=(1, 2), match='o'> If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()). Pattern.fullmatch(string[, pos[, endpos]]) If the whole string matches this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o[gh]\") >>> pattern.fullmatch(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.fullmatch(\"ogre\") # No match as not the full string matches. >>> pattern.fullmatch(\"doggie\", 1, 3) # Matches within given limits. <re.Match object; span=(1, 3), match='og'> New in version 3.4. Pattern.split(string, maxsplit=0) Identical to the split() function, using the compiled pattern. Pattern.findall(string[, pos[, endpos]]) Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.finditer(string[, pos[, endpos]]) Similar to the finditer() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.sub(repl, string, count=0) Identical to the sub() function, using the compiled pattern. Pattern.subn(repl, string, count=0) Identical to the subn() function, using the compiled pattern. Pattern.flags The regex", "score": "0.682895"}, {"id": "23367", "text": "Function: python.library.re#re.search\nSnippet: re.search(pattern, string, flags=0) Scan through string looking for the first location where the regular expression pattern produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string.", "score": "0.68211293"}, {"id": "23361", "text": "Function: python.library.re#re.Pattern.search\nSnippet: Pattern.search(string[, pos[, endpos]]) Scan through string looking for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\"", "score": "0.681939"}]}
{"task_id": 538, "text": "Write a python function to convert a given string list to a tuple.", "code": "def string_list_to_tuple(str1):\r\n    result = tuple(x for x in str1 if not x.isspace()) \r\n    return result", "test_list": ["assert string_list_to_tuple((\"python 3.0\")) == ('p', 'y', 't', 'h', 'o', 'n', '3', '.', '0')", "assert string_list_to_tuple((\"bigdata\")) == ('b', 'i', 'g', 'd', 'a', 't', 'a')", "assert string_list_to_tuple((\"language\")) == ('l', 'a', 'n', 'g', 'u', 'a', 'g','e')"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18617", "text": "Function: python.library.collections\nSnippet: a new instance of the named tuple replacing specified fields with new values: >>> p = Point(x=11, y=22) >>> p._replace(x=33) Point(x=33, y=22) >>> for partnum, record in inventory.items(): ... inventory[partnum] = record._replace(price=newprices[partnum], timestamp=time.now()) somenamedtuple._fields Tuple of strings listing the field names. Useful for introspection and for creating new named tuple types from existing named tuples. >>> p._fields # view the field names ('x', 'y') >>> Color = namedtuple('Color', 'red green blue') >>> Pixel = namedtuple('Pixel', Point._fields + Color._fields) >>> Pixel(11, 22, 128, 255, 0) Pixel(x=11, y=22, red=128, green=255, blue=0) somenamedtuple._field_defaults Dictionary mapping field names to default values. >>> Account = namedtuple('Account', ['type', 'balance'], defaults=[0]) >>> Account._field_defaults {'balance': 0} >>> Account('premium') Account(type='premium', balance=0) To retrieve a field whose name is stored in a string, use the getattr() function: >>> getattr(p, 'x') 11 To convert a dictionary to a named tuple, use the double-star-operator (as described in Unpacking Argument Lists): >>> d = {'x': 11, 'y': 22} >>> Point(**d) Point(x=11, y=22) Since a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how to add a calculated field and a fixed-width print format: >>> class Point(namedtuple('Point', ['x', 'y'])): ... __slots__ = () ... @property ... def hypot(self): ... return (self.x ** 2 + self.y ** 2) ** 0.5 ... def __str__(self): ... return 'Point: x=%6.3f y=%6.3f hypot=%6.3f' % (self.x, self.y, self.hypot) >>> for p in Point(3, 4), Point(14, 5/7): ... print(p) Point: x= 3.000 y= 4.000 hypot= 5.000 Point: x=14.000 y= 0.714 hypot=14.018 The subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by preventing the creation of instance dictionaries. Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the _fields attribute: >>> Point3D = namedtuple('Point3D', Point._fields + ('z',)) Docstrings can be customized by making direct assignments to the __doc__ fields: >>> Book = namedtuple('Book', ['id', 'title', 'authors']) >>> Book.__doc__ += ': Hardcover book in active collection' >>> Book.id.__doc__ = '13-digit ISBN' >>> Book.title.__doc__ = 'Title of first printing' >>> Book.authors.__doc__ = 'List of authors sorted by last name' Changed in version 3.5: Property docstrings became writeable. See also See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation using the class keyword: class Component(NamedTuple): part_number: int weight: float description: Optional[str] = None See types.SimpleNamespace() for a mutable namespace based on an underlying dictionary instead of a tuple. The dataclasses module provides a decorator and functions for automatically adding generated special methods to user-defined classes. OrderedDict objects Ordered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in dict class gained the ability to remember insertion order (this new behavior became guaranteed in Python 3.7). Some differences from dict still remain: The regular dict was designed to be very good at mapping operations. Tracking insertion order was secondary. The OrderedDict was designed to be", "score": "0.6935161"}, {"id": "36422", "text": "Function: django.ref.contrib.gis.gdal#django.contrib.gis.gdal.Envelope.tuple\nSnippet: tuple", "score": "0.6870726"}, {"id": "25737", "text": "Function: python.library.stdtypes\nSnippet: a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below: if concatenating str objects, you can build a list and use str.join() at the end or else write to an io.StringIO instance and retrieve its value when complete if concatenating bytes objects, you can similarly use bytes.join() or io.BytesIO, or you can do in-place concatenation with a bytearray object. bytearray objects are mutable and have an efficient overallocation mechanism if concatenating tuple objects, extend a list instead for other types, investigate the relevant class documentation Some sequence types (such as range) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition. index raises ValueError when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using s[i:j].index(x), only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. Immutable Sequence Types The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the hash() built-in. This support allows immutable sequences, such as tuple instances, to be used as dict keys and stored in set and frozenset instances. Attempting to hash an immutable sequence that contains unhashable values will result in TypeError. Mutable Sequence Types The operations in the following table are defined on mutable sequence types. The collections.abc.MutableSequence ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, bytearray only accepts integers that meet the value restriction 0 <= x <= 255). Operation Result Notes s[i] = x item i of s is replaced by x s[i:j] = t slice of s from i to j is replaced by the contents of the iterable t del s[i:j] same as s[i:j] = [] s[i:j:k] = t the elements of s[i:j:k] are replaced by those of t (1) del s[i:j:k] removes the elements of s[i:j:k] from the list s.append(x) appends x to the end of the sequence (same as s[len(s):len(s)] = [x]) s.clear() removes all items from s (same as del s[:]) (5) s.copy() creates a shallow copy of s (same as s[:]) (5) s.extend(t) or s += t extends s with the contents of t (for the most part the same as s[len(s):len(s)] = t) s *= n updates s with its contents repeated n times (6) s.insert(i, x) inserts x into s at the index given by i (same as s[i:i] = [x]) s.pop([i]) retrieves the item at i and also removes it", "score": "0.6815162"}, {"id": "18685", "text": "Function: python.library.collections#collections.somenamedtuple._replace\nSnippet: somenamedtuple._replace(**kwargs) Return a new instance of the named tuple replacing specified fields with new values: >>> p = Point(x=11, y=22) >>> p._replace(x=33) Point(x=33, y=22) >>> for partnum, record in inventory.items(): ... inventory[partnum] = record._replace(price=newprices[partnum], timestamp=time.now())", "score": "0.67803276"}, {"id": "36544", "text": "Function: django.ref.contrib.gis.gdal#django.contrib.gis.gdal.OGRGeometry.tuple\nSnippet: tuple", "score": "0.67711985"}]}
{"task_id": 539, "text": "Write a function to create a list containing the power of said number in bases raised to the corresponding number in the index using map function.", "code": "def basesnum_coresspondingnum(bases_num,index):\r\n  result = list(map(pow, bases_num, index))\r\n  return result", "test_list": ["assert basesnum_coresspondingnum([10, 20, 30, 40, 50, 60, 70, 80, 90, 100],[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[10, 400, 27000, 2560000, 312500000, 46656000000, 8235430000000, 1677721600000000, 387420489000000000, 100000000000000000000]", "assert basesnum_coresspondingnum([1, 2, 3, 4, 5, 6, 7],[10, 20, 30, 40, 50, 60, 70])==[1, 1048576, 205891132094649, 1208925819614629174706176, 88817841970012523233890533447265625, 48873677980689257489322752273774603865660850176, 143503601609868434285603076356671071740077383739246066639249]", "assert basesnum_coresspondingnum([4, 8, 12, 16, 20, 24, 28],[3, 6, 9, 12, 15, 18, 21])==[64, 262144, 5159780352, 281474976710656, 32768000000000000000, 6979147079584381377970176, 2456510688823056210273111113728]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42052", "text": "Function: numpy.reference.generated.numpy.lib.scimath.power\nSnippet: numpy.lib.scimath.power lib.scimath.power(x, p)[source] Return x to the power p, (x**p). If x contains negative values, the output is converted to the complex domain. Parameters xarray_like The input value(s). parray_like of ints The power(s) to which x is raised. If x contains multiple values, p has to either be a scalar, or contain the same number of values as x. In the latter case, the result is x[0]**p[0], x[1]**p[1], .... Returns outndarray or scalar The result of x**p. If x and p are scalars, so is out, otherwise an array is returned. See also numpy.power Examples >>> np.set_printoptions(precision=4) >>> np.emath.power([2, 4], 2) array([ 4, 16]) >>> np.emath.power([2, 4], -2) array([0.25 , 0.0625]) >>> np.emath.power([-2, 4], 2) array([ 4.-0.j, 16.+0.j])", "score": "0.67584264"}, {"id": "43106", "text": "Function: numpy.reference.generated.numpy.power\nSnippet: numpy.power numpy.power(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'power'> First array elements raised to powers from second array, element-wise. Raise each base in x1 to the positionally-corresponding power in x2. x1 and x2 must be broadcastable to the same shape. An integer type raised to a negative integer power will raise a ValueError. Negative values raised to a non-integral value will return nan. To get complex results, cast the input to complex, or specify the dtype to be complex (see the example below). Parameters x1array_like The bases. x2array_like The exponents. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray The bases in x1 raised to the exponents in x2. This is a scalar if both x1 and x2 are scalars. See also float_power power function that promotes integers to float Examples Cube each element in an array. >>> x1 = np.arange(6) >>> x1 [0, 1, 2, 3, 4, 5] >>> np.power(x1, 3) array([ 0, 1, 8, 27, 64, 125]) Raise the bases to different exponents. >>> x2 = [1.0, 2.0, 3.0, 3.0, 2.0, 1.0] >>> np.power(x1, x2) array([ 0., 1., 8., 27., 16., 5.]) The effect of broadcasting. >>> x2 = np.array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) >>> x2 array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) >>> np.power(x1, x2) array([[ 0, 1, 8, 27, 16, 5], [ 0, 1, 8, 27, 16, 5]]) The ** operator can be used as a shorthand for np.power on ndarrays. >>> x2 = np.array([1, 2, 3, 3, 2, 1]) >>> x1 = np.arange(6) >>> x1 ** x2 array([ 0, 1, 8, 27, 16, 5]) Negative values raised to a non-integral value will result in nan (and a warning will be generated). >>> x3 = np.array([-1.0, -4.0]) >>> with np.errstate(invalid='ignore'): ... p = np.power(x3, 1.5) ... >>> p array([nan, nan]) To get complex results, give the argument dtype=complex. >>> np.power(x3, 1.5, dtype=complex) array([-1.83697020e-16-1.j, -1.46957616e-15-8.j])", "score": "0.6700414"}, {"id": "42838", "text": "Function: numpy.reference.generated.numpy.float_power\nSnippet: numpy.float_power numpy.float_power(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'float_power'> First array elements raised to powers from second array, element-wise. Raise each base in x1 to the positionally-corresponding power in x2. x1 and x2 must be broadcastable to the same shape. This differs from the power function in that integers, float16, and float32 are promoted to floats with a minimum precision of float64 so that the result is always inexact. The intent is that the function will return a usable result for negative powers and seldom overflow for positive powers. Negative values raised to a non-integral value will return nan. To get complex results, cast the input to complex, or specify the dtype to be complex (see the example below). New in version 1.12.0. Parameters x1array_like The bases. x2array_like The exponents. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray The bases in x1 raised to the exponents in x2. This is a scalar if both x1 and x2 are scalars. See also power power function that preserves type Examples Cube each element in a list. >>> x1 = range(6) >>> x1 [0, 1, 2, 3, 4, 5] >>> np.float_power(x1, 3) array([ 0., 1., 8., 27., 64., 125.]) Raise the bases to different exponents. >>> x2 = [1.0, 2.0, 3.0, 3.0, 2.0, 1.0] >>> np.float_power(x1, x2) array([ 0., 1., 8., 27., 16., 5.]) The effect of broadcasting. >>> x2 = np.array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) >>> x2 array([[1, 2, 3, 3, 2, 1], [1, 2, 3, 3, 2, 1]]) >>> np.float_power(x1, x2) array([[ 0., 1., 8., 27., 16., 5.], [ 0., 1., 8., 27., 16., 5.]]) Negative values raised to a non-integral value will result in nan (and a warning will be generated). >>> x3 = np.array([-1, -4]) >>> with np.errstate(invalid='ignore'): ... p = np.float_power(x3, 1.5) ... >>> p array([nan, nan]) To get complex results, give the argument dtype=complex. >>> np.float_power(x3, 1.5, dtype=complex) array([-1.83697020e-16-1.j, -1.46957616e-15-8.j])", "score": "0.6654652"}, {"id": "42329", "text": "Function: numpy.reference.generated.numpy.ma.power\nSnippet: numpy.ma.power ma.power(a, b, third=None)[source] Returns element-wise base array raised to power from second array. This is the masked array version of numpy.power. For details see numpy.power. See also numpy.power Notes The out argument to numpy.power is not supported, third has to be None.", "score": "0.645018"}, {"id": "23150", "text": "Function: python.library.functions#pow\nSnippet: pow(base, exp[, mod]) Return base to the power exp; if mod is present, return base to the power exp, modulo mod (computed more efficiently than pow(base, exp) % mod). The two-argument form pow(base, exp) is equivalent to using the power operator: base**exp. The arguments must have numeric types. With mixed operand types, the coercion rules for binary arithmetic operators apply. For int operands, the result has the same type as the operands (after coercion) unless the second argument is negative; in that case, all arguments are converted to float and a float result is delivered. For example, 10**2 returns 100, but 10**-2 returns 0.01. For int operands base and exp, if mod is present, mod must also be of integer type and mod must be nonzero. If mod is present and exp is negative, base must be relatively prime to mod. In that case, pow(inv_base, -exp, mod) is returned, where inv_base is an inverse to base modulo mod. Here’s an example of computing an inverse for 38 modulo 97: >>> pow(38, -1, mod=97) 23 >>> 23 * 38 % 97 == 1 True Changed in version 3.8: For int operands, the three-argument form of pow now allows the second argument to be negative, permitting computation of modular inverses. Changed in version 3.8: Allow keyword arguments. Formerly, only positional arguments were supported.", "score": "0.6447523"}]}
{"task_id": 540, "text": "Write a python function to find the difference between highest and least frequencies in a given array.", "code": "def find_Diff(arr,n): \r\n    arr.sort()  \r\n    count = 0; max_count = 0; min_count = n \r\n    for i in range(0,(n-1)): \r\n        if arr[i] == arr[i + 1]: \r\n            count += 1\r\n            continue\r\n        else: \r\n            max_count = max(max_count,count) \r\n            min_count = min(min_count,count) \r\n            count = 0\r\n    return max_count - min_count ", "test_list": ["assert find_Diff([1,1,2,2,7,8,4,5,1,4],10) == 2", "assert find_Diff([1,7,9,2,3,3,1,3,3],9) == 3", "assert find_Diff([1,2,1,2],4) == 0"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43968", "text": "Function: numpy.reference.generated.numpy.testing.assert_array_max_ulp\nSnippet: numpy.testing.assert_array_max_ulp testing.assert_array_max_ulp(a, b, maxulp=1, dtype=None)[source] Check that all items of arrays differ in at most N Units in the Last Place. Parameters a, barray_like Input arrays to be compared. maxulpint, optional The maximum number of units in the last place that elements of a and b can differ. Default is 1. dtypedtype, optional Data-type to convert a and b to if given. Default is None. Returns retndarray Array containing number of representable floating point numbers between items in a and b. Raises AssertionError If one or more elements differ by more than maxulp. See also assert_array_almost_equal_nulp Compare two arrays relatively to their spacing. Notes For computing the ULP difference, this API does not differentiate between various representations of NAN (ULP difference between 0x7fc00000 and 0xffc00000 is zero). Examples >>> a = np.linspace(0., 1., 100) >>> res = np.testing.assert_array_max_ulp(a, np.arcsin(np.sin(a)))", "score": "0.6935813"}, {"id": "41985", "text": "Function: numpy.reference.generated.numpy.fft.rfftfreq\nSnippet: numpy.fft.rfftfreq fft.rfftfreq(n, d=1.0)[source] Return the Discrete Fourier Transform sample frequencies (for usage with rfft, irfft). The returned float array f contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start). For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second. Given a window length n and a sample spacing d: f = [0, 1, ..., n/2-1, n/2] / (d*n) if n is even f = [0, 1, ..., (n-1)/2-1, (n-1)/2] / (d*n) if n is odd Unlike fftfreq (but like scipy.fftpack.rfftfreq) the Nyquist frequency component is considered to be positive. Parameters nint Window length. dscalar, optional Sample spacing (inverse of the sampling rate). Defaults to 1. Returns fndarray Array of length n//2 + 1 containing the sample frequencies. Examples >>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5, -3, 4], dtype=float) >>> fourier = np.fft.rfft(signal) >>> n = signal.size >>> sample_rate = 100 >>> freq = np.fft.fftfreq(n, d=1./sample_rate) >>> freq array([ 0., 10., 20., ..., -30., -20., -10.]) >>> freq = np.fft.rfftfreq(n, d=1./sample_rate) >>> freq array([ 0., 10., 20., 30., 40., 50.])", "score": "0.6809569"}, {"id": "13013", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos#sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.6785826"}, {"id": "41967", "text": "Function: numpy.reference.generated.numpy.fft.fftfreq\nSnippet: numpy.fft.fftfreq fft.fftfreq(n, d=1.0)[source] Return the Discrete Fourier Transform sample frequencies. The returned float array f contains the frequency bin centers in cycles per unit of the sample spacing (with zero at the start). For instance, if the sample spacing is in seconds, then the frequency unit is cycles/second. Given a window length n and a sample spacing d: f = [0, 1, ..., n/2-1, -n/2, ..., -1] / (d*n) if n is even f = [0, 1, ..., (n-1)/2, -(n-1)/2, ..., -1] / (d*n) if n is odd Parameters nint Window length. dscalar, optional Sample spacing (inverse of the sampling rate). Defaults to 1. Returns fndarray Array of length n containing the sample frequencies. Examples >>> signal = np.array([-2, 8, 6, 4, 1, 0, 3, 5], dtype=float) >>> fourier = np.fft.fft(signal) >>> n = signal.size >>> timestep = 0.1 >>> freq = np.fft.fftfreq(n, d=timestep) >>> freq array([ 0. , 1.25, 2.5 , ..., -3.75, -2.5 , -1.25])", "score": "0.6780826"}, {"id": "17638", "text": "Function: python.library.array#array.array.index\nSnippet: array.index(x) Return the smallest i such that i is the index of the first occurrence of x in the array.", "score": "0.6778387"}]}
{"task_id": 541, "text": "Write a function to find if the given number is abundant or not.", "code": "import math \r\ndef get_sum(n): \r\n\tsum = 0\r\n\ti = 1\r\n\twhile i <= (math.sqrt(n)): \r\n\t\tif n%i == 0: \r\n\t\t\tif n/i == i : \r\n\t\t\t\tsum = sum + i \r\n\t\t\telse: \r\n\t\t\t\tsum = sum + i \r\n\t\t\t\tsum = sum + (n / i ) \r\n\t\ti = i + 1\r\n\tsum = sum - n \r\n\treturn sum\r\ndef check_abundant(n): \r\n\tif (get_sum(n) > n): \r\n\t\treturn True\r\n\telse: \r\n\t\treturn False", "test_list": ["assert check_abundant(12) == True", "assert check_abundant(15) == False", "assert check_abundant(18) == True"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21823", "text": "Function: python.library.math#math.perm\nSnippet: math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8.", "score": "0.6553896"}, {"id": "21811", "text": "Function: python.library.math#math.isnan\nSnippet: math.isnan(x) Return True if x is a NaN (not a number), and False otherwise.", "score": "0.6414118"}, {"id": "21810", "text": "Function: python.library.math#math.isinf\nSnippet: math.isinf(x) Return True if x is a positive or negative infinity, and False otherwise.", "score": "0.6386505"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6363825"}, {"id": "19477", "text": "Function: python.library.decimal#decimal.Context.is_normal\nSnippet: is_normal(x) Returns True if x is a normal number; otherwise returns False.", "score": "0.6328274"}]}
{"task_id": 542, "text": "Write a function to replace all occurrences of spaces, commas, or dots with a colon in the given string by using regex.", "code": "import re\r\ndef fill_spaces(text):\r\n  return (re.sub(\"[ ,.]\", \":\", text))", "test_list": ["assert fill_spaces('Boult Curve Wireless Neckband') == 'Boult:Curve:Wireless:Neckband'", "assert fill_spaces('Stereo Sound Sweatproof') == 'Stereo:Sound:Sweatproof'", "assert fill_spaces('Probass Curve Audio') == 'Probass:Curve:Audio'"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23369", "text": "Function: python.library.re#re.sub\nSnippet: re.sub(pattern, repl, string, count=0, flags=0) Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. For example: >>> re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', ... r'static PyObject*\\npy_\\1(void)\\n{', ... 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. For example: >>> def dashrepl(matchobj): ... if matchobj.group(0) == '-': return ' ' ... else: return '-' >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' >>> re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' The pattern may be a string or a pattern object. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern are replaced only when not adjacent to a previous empty match, so sub('x*', '-', 'abxd') returns '-a-b--d-'. In string-type repl arguments, in addition to the character escapes and backreferences described above, \\g<name> will use the substring matched by the group named name, as defined by the (?P<name>...) syntax. \\g<number> uses the corresponding group number; \\g<2> is therefore equivalent to \\2, but isn’t ambiguous in a replacement such as \\g<2>0. \\20 would be interpreted as a reference to group 20, not a reference to group 2 followed by the literal character '0'. The backreference \\g<0> substitutes in the entire substring matched by the RE. Changed in version 3.1: Added the optional flags argument. Changed in version 3.5: Unmatched groups are replaced with an empty string. Changed in version 3.6: Unknown escapes in pattern consisting of '\\' and an ASCII letter now are errors. Changed in version 3.7: Unknown escapes in repl consisting of '\\' and an ASCII letter now are errors. Changed in version 3.7: Empty matches for the pattern are replaced when adjacent to a previous non-empty match.", "score": "0.71083844"}, {"id": "24398", "text": "Function: python.library.string\nSnippet: characters are replaced by a single space and leading and trailing whitespace are removed, otherwise sep is used to split and join the words.", "score": "0.7024534"}, {"id": "5309", "text": "Function: tensorflow.strings.regex_replace\nSnippet: tf.strings.regex_replace View source on GitHub Replace elements of input matching regex pattern with rewrite. View aliases Compat aliases for migration See Migration guide for more details. tf.compat.v1.regex_replace, tf.compat.v1.strings.regex_replace tf.strings.regex_replace( input, pattern, rewrite, replace_global=True, name=None ) tf.strings.regex_replace(\"Text with tags.<br /><b>contains html</b>\", \"<[^>]+>\", \" \") <tf.Tensor: shape=(), dtype=string, numpy=b'Text with tags. contains html '> Args input string Tensor, the source strings to process. pattern string or scalar string Tensor, regular expression to use, see more details at https://github.com/google/re2/wiki/Syntax rewrite string or scalar string Tensor, value to use in match replacement, supports backslash-escaped digits (\\1 to \\9) can be to insert text matching corresponding parenthesized group. replace_global bool, if True replace all non-overlapping matches, else replace only the first match. name A name for the operation (optional). Returns string Tensor of the same shape as input with specified replacements.", "score": "0.68425554"}, {"id": "15356", "text": "Function: pandas.reference.api.pandas.series.str.replace\nSnippet: pandas.Series.str.replace Series.str.replace(pat, repl, n=- 1, case=None, flags=0, regex=None)[source] Replace each occurrence of pattern/regex in the Series/Index. Equivalent to str.replace() or re.sub(), depending on the regex value. Parameters pat:str or compiled regex String can be a character sequence or regular expression. repl:str or callable Replacement string or a callable. The callable is passed the regex match object and must return a replacement string to be used. See re.sub(). n:int, default -1 (all) Number of replacements to make from start. case:bool, default None Determines if replace is case sensitive: If True, case sensitive (the default if pat is a string) Set to False for case insensitive Cannot be set if pat is a compiled regex. flags:int, default 0 (no flags) Regex module flags, e.g. re.IGNORECASE. Cannot be set if pat is a compiled regex. regex:bool, default True Determines if the passed-in pattern is a regular expression: If True, assumes the passed-in pattern is a regular expression. If False, treats the pattern as a literal string Cannot be set to False if pat is a compiled regex or repl is a callable. New in version 0.23.0. Returns Series or Index of object A copy of the object with all matching occurrences of pat replaced by repl. Raises ValueError if regex is False and repl is a callable or pat is a compiled regex if pat is a compiled regex and case or flags is set Notes When pat is a compiled regex, all flags should be included in the compiled regex. Use of case, flags, or regex=False with a compiled regex will raise an error. Examples When pat is a string and regex is True (the default), the given pat is compiled as a regex. When repl is a string, it replaces matching regex patterns as with re.sub(). NaN value(s) in the Series are left as is: >>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f.', 'ba', regex=True) 0 bao 1 baz 2 NaN dtype: object When pat is a string and regex is False, every pat is replaced with repl as with str.replace(): >>> pd.Series(['f.o', 'fuz', np.nan]).str.replace('f.', 'ba', regex=False) 0 bao 1 fuz 2 NaN dtype: object When repl is a callable, it is called on every pat using re.sub(). The callable should expect one positional argument (a regex object) and return a string. To get the idea: >>> pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr, regex=True) 0 <re.Match object; span=(0, 1), match='f'>oo 1 <re.Match object; span=(0, 1), match='f'>uz 2 NaN dtype: object Reverse every lowercase alphabetic word: >>> repl = lambda m: m.group(0)[::-1] >>> ser = pd.Series(['foo 123', 'bar baz', np.nan]) >>> ser.str.replace(r'[a-z]+', repl, regex=True) 0 oof 123 1 rab zab 2 NaN dtype: object Using regex groups (extract second group and swap case): >>> pat = r\"(?P<one>\\w+) (?P<two>\\w+) (?P<three>\\w+)\" >>> repl = lambda m: m.group('two').swapcase() >>> ser = pd.Series(['One Two Three', 'Foo Bar Baz']) >>> ser.str.replace(pat, repl, regex=True) 0 tWO 1 bAR dtype: object Using a compiled regex with flags >>> import re >>> regex_pat = re.compile(r'FUZ', flags=re.IGNORECASE) >>> pd.Series(['foo', 'fuz', np.nan]).str.replace(regex_pat, 'bar', regex=True) 0 foo 1 bar", "score": "0.68258107"}, {"id": "23326", "text": "Function: python.library.re#re.error.pattern\nSnippet: pattern The regular expression pattern.", "score": "0.6790708"}]}
{"task_id": 543, "text": "Write a function to add two numbers and print number of digits of sum.", "code": "def count_digits(num1,num2):\r\n    number=num1+num2\r\n    count = 0\r\n    while(number > 0):\r\n        number = number // 10\r\n        count = count + 1\r\n    return count", "test_list": ["assert count_digits(9875,10)==(4)", "assert count_digits(98759853034,100)==(11)", "assert count_digits(1234567,500)==(7)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19451", "text": "Function: python.library.decimal#decimal.Context.add\nSnippet: add(x, y) Return the sum of x and y.", "score": "0.71533823"}, {"id": "24549", "text": "Function: python.library.functions#sum\nSnippet: sum(iterable, /, start=0) Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument.", "score": "0.7001461"}, {"id": "22301", "text": "Function: python.library.operator#operator.add\nSnippet: operator.add(a, b) operator.__add__(a, b) Return a + b, for a and b numbers.", "score": "0.68839633"}, {"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.685494"}, {"id": "22355", "text": "Function: python.library.operator#operator.__add__\nSnippet: operator.add(a, b) operator.__add__(a, b) Return a + b, for a and b numbers.", "score": "0.68068254"}]}
{"task_id": 544, "text": "Write a function to flatten the tuple list to a string.", "code": "def flatten_tuple(test_list):\r\n  res = ' '.join([idx for tup in test_list for idx in tup])\r\n  return (res) ", "test_list": ["assert flatten_tuple([('1', '4', '6'), ('5', '8'), ('2', '9'), ('1', '10')]) == '1 4 6 5 8 2 9 1 10'", "assert flatten_tuple([('2', '3', '4'), ('6', '9'), ('3', '2'), ('2', '11')]) == '2 3 4 6 9 3 2 2 11'", "assert flatten_tuple([('14', '21', '9'), ('24', '19'), ('12', '29'), ('23', '17')]) == '14 21 9 24 19 12 29 23 17'"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43915", "text": "Function: numpy.reference.generated.numpy.record.flatten\nSnippet: numpy.record.flatten method record.flatten() Scalar method identical to the corresponding array attribute. Please see ndarray.flatten.", "score": "0.69930506"}, {"id": "41781", "text": "Function: numpy.reference.generated.numpy.chararray.flatten\nSnippet: numpy.chararray.flatten method chararray.flatten(order='C') Return a copy of the array collapsed into one dimension. Parameters order{‘C’, ‘F’, ‘A’, ‘K’}, optional ‘C’ means to flatten in row-major (C-style) order. ‘F’ means to flatten in column-major (Fortran- style) order. ‘A’ means to flatten in column-major order if a is Fortran contiguous in memory, row-major order otherwise. ‘K’ means to flatten a in the order the elements occur in memory. The default is ‘C’. Returns yndarray A copy of the input array, flattened to one dimension. See also ravel Return a flattened array. flat A 1-D flat iterator over the array. Examples >>> a = np.array([[1,2], [3,4]]) >>> a.flatten() array([1, 2, 3, 4]) >>> a.flatten('F') array([1, 3, 2, 4])", "score": "0.687269"}, {"id": "41657", "text": "Function: numpy.reference.generated.numpy.char.chararray.flatten\nSnippet: numpy.char.chararray.flatten method char.chararray.flatten(order='C') Return a copy of the array collapsed into one dimension. Parameters order{‘C’, ‘F’, ‘A’, ‘K’}, optional ‘C’ means to flatten in row-major (C-style) order. ‘F’ means to flatten in column-major (Fortran- style) order. ‘A’ means to flatten in column-major order if a is Fortran contiguous in memory, row-major order otherwise. ‘K’ means to flatten a in the order the elements occur in memory. The default is ‘C’. Returns yndarray A copy of the input array, flattened to one dimension. See also ravel Return a flattened array. flat A 1-D flat iterator over the array. Examples >>> a = np.array([[1,2], [3,4]]) >>> a.flatten() array([1, 2, 3, 4]) >>> a.flatten('F') array([1, 3, 2, 4])", "score": "0.6860942"}, {"id": "25737", "text": "Function: python.library.stdtypes\nSnippet: a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below: if concatenating str objects, you can build a list and use str.join() at the end or else write to an io.StringIO instance and retrieve its value when complete if concatenating bytes objects, you can similarly use bytes.join() or io.BytesIO, or you can do in-place concatenation with a bytearray object. bytearray objects are mutable and have an efficient overallocation mechanism if concatenating tuple objects, extend a list instead for other types, investigate the relevant class documentation Some sequence types (such as range) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition. index raises ValueError when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using s[i:j].index(x), only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. Immutable Sequence Types The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the hash() built-in. This support allows immutable sequences, such as tuple instances, to be used as dict keys and stored in set and frozenset instances. Attempting to hash an immutable sequence that contains unhashable values will result in TypeError. Mutable Sequence Types The operations in the following table are defined on mutable sequence types. The collections.abc.MutableSequence ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, bytearray only accepts integers that meet the value restriction 0 <= x <= 255). Operation Result Notes s[i] = x item i of s is replaced by x s[i:j] = t slice of s from i to j is replaced by the contents of the iterable t del s[i:j] same as s[i:j] = [] s[i:j:k] = t the elements of s[i:j:k] are replaced by those of t (1) del s[i:j:k] removes the elements of s[i:j:k] from the list s.append(x) appends x to the end of the sequence (same as s[len(s):len(s)] = [x]) s.clear() removes all items from s (same as del s[:]) (5) s.copy() creates a shallow copy of s (same as s[:]) (5) s.extend(t) or s += t extends s with the contents of t (for the most part the same as s[len(s):len(s)] = t) s *= n updates s with its contents repeated n times (6) s.insert(i, x) inserts x into s at the index given by i (same as s[i:i] = [x]) s.pop([i]) retrieves the item at i and also removes it", "score": "0.6844157"}, {"id": "25502", "text": "Function: python.library.traceback#traceback.format_list\nSnippet: traceback.format_list(extracted_list) Given a list of tuples or FrameSummary objects as returned by extract_tb() or extract_stack(), return a list of strings ready for printing. Each string in the resulting list corresponds to the item with the same index in the argument list. Each string ends in a newline; the strings may contain internal newlines as well, for those items whose source text line is not None.", "score": "0.6842847"}]}
{"task_id": 545, "text": "Write a python function to toggle only first and last bits of a given number.", "code": "def take_L_and_F_set_bits(n) : \r\n    n = n | n >> 1\r\n    n = n | n >> 2\r\n    n = n | n >> 4\r\n    n = n | n >> 8\r\n    n = n | n >> 16 \r\n    return ((n + 1) >> 1) + 1      \r\ndef toggle_F_and_L_bits(n) :  \r\n    if (n == 1) : \r\n        return 0 \r\n    return n ^ take_L_and_F_set_bits(n) ", "test_list": ["assert toggle_F_and_L_bits(10) == 3", "assert toggle_F_and_L_bits(15) == 6", "assert toggle_F_and_L_bits(20) == 5"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23298", "text": "Function: python.library.stdtypes#range.stop\nSnippet: stop The value of the stop parameter", "score": "0.6713008"}, {"id": "43158", "text": "Function: numpy.reference.generated.numpy.right_shift\nSnippet: numpy.right_shift numpy.right_shift(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'right_shift'> Shift the bits of an integer to the right. Bits are shifted to the right x2. Because the internal representation of numbers is in binary format, this operation is equivalent to dividing x1 by 2**x2. Parameters x1array_like, int Input values. x2array_like, int Number of bits to remove at the right of x1. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns outndarray, int Return x1 with bits shifted x2 times to the right. This is a scalar if both x1 and x2 are scalars. See also left_shift Shift the bits of an integer to the left. binary_repr Return the binary representation of the input number as a string. Examples >>> np.binary_repr(10) '1010' >>> np.right_shift(10, 1) 5 >>> np.binary_repr(5) '101' >>> np.right_shift(10, [1,2,3]) array([5, 2, 1]) The >> operator can be used as a shorthand for np.right_shift on ndarrays. >>> x1 = 10 >>> x2 = np.array([1,2,3]) >>> x1 >> x2 array([5, 2, 1])", "score": "0.6658152"}, {"id": "19587", "text": "Function: python.library.decimal#decimal.MAX_PREC\nSnippet: decimal.MAX_PREC", "score": "0.6629659"}, {"id": "25756", "text": "Function: python.library.stdtypes\nSnippet: binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> b'Monty Python'.rstrip(b' Python') b'M' >>> b'Monty Python'.removesuffix(b' Python') b'Monty' Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. bytes.split(sep=None, maxsplit=-1) bytearray.split(sep=None, maxsplit=-1) Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object. For example: >>> b'1,2,3'.split(b',') [b'1', b'2', b'3'] >>> b'1,2,3'.split(b',', maxsplit=1) [b'1', b'2,3'] >>> b'1,2,,3,'.split(b',') [b'1', b'2', b'', b'3', b''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns []. For example: >>> b'1 2 3'.split() [b'1', b'2', b'3'] >>> b'1 2 3'.split(maxsplit=1) [b'1', b'2 3'] >>> b' 1 2 3 '.split() [b'1', b'2', b'3'] bytes.strip([chars]) bytearray.strip([chars]) Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped: >>> b' spacious '.strip() b'spacious' >>> b'www.example.com'.strip(b'cmowz.') b'example' The binary sequence of byte values to remove may be any bytes-like object. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. The following methods on bytes and bytearray objects assume the use of ASCII compatible binary formats and should not be applied to arbitrary binary data. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects. bytes.capitalize() bytearray.capitalize() Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized and the rest", "score": "0.6597357"}, {"id": "19487", "text": "Function: python.library.decimal#decimal.Context.logical_invert\nSnippet: logical_invert(x) Invert all the digits in x.", "score": "0.65261996"}]}
{"task_id": 546, "text": "Write a function to find the last occurrence of a character in a string.", "code": "def last_occurence_char(string,char):\r\n flag = -1\r\n for i in range(len(string)):\r\n     if(string[i] == char):\r\n         flag = i\r\n if(flag == -1):\r\n    return None\r\n else:\r\n    return flag + 1", "test_list": ["assert last_occurence_char(\"hello world\",'l')==10", "assert last_occurence_char(\"language\",'g')==7", "assert last_occurence_char(\"little\",'y')==None"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "41724", "text": "Function: numpy.reference.generated.numpy.char.find\nSnippet: numpy.char.find char.find(a, sub, start=0, end=None)[source] For each element, return the lowest index in the string where substring sub is found. Calls str.find element-wise. For each element, return the lowest index in the string where substring sub is found, such that sub is contained in the range [start, end]. Parameters aarray_like of str or unicode substr or unicode start, endint, optional Optional arguments start and end are interpreted as in slice notation. Returns outndarray or int Output array of ints. Returns -1 if sub is not found. See also str.find", "score": "0.69920146"}, {"id": "41778", "text": "Function: numpy.reference.generated.numpy.chararray.find\nSnippet: numpy.chararray.find method chararray.find(sub, start=0, end=None)[source] For each element, return the lowest index in the string where substring sub is found. See also char.find", "score": "0.696446"}, {"id": "24346", "text": "Function: python.library.stdtypes#str.find\nSnippet: str.find(sub[, start[, end]]) Return the lowest index in the string where substring sub is found within the slice s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 if sub is not found. Note The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator: >>> 'Py' in 'Python' True", "score": "0.69557154"}, {"id": "41654", "text": "Function: numpy.reference.generated.numpy.char.chararray.find\nSnippet: numpy.char.chararray.find method char.chararray.find(sub, start=0, end=None)[source] For each element, return the lowest index in the string where substring sub is found. See also char.find", "score": "0.6950496"}, {"id": "23310", "text": "Function: python.library.re\nSnippet: for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\" Pattern.match(string[, pos[, endpos]]) If zero or more characters at the beginning of string match this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o\") >>> pattern.match(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.match(\"dog\", 1) # Match as \"o\" is the 2nd character of \"dog\". <re.Match object; span=(1, 2), match='o'> If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()). Pattern.fullmatch(string[, pos[, endpos]]) If the whole string matches this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o[gh]\") >>> pattern.fullmatch(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.fullmatch(\"ogre\") # No match as not the full string matches. >>> pattern.fullmatch(\"doggie\", 1, 3) # Matches within given limits. <re.Match object; span=(1, 3), match='og'> New in version 3.4. Pattern.split(string, maxsplit=0) Identical to the split() function, using the compiled pattern. Pattern.findall(string[, pos[, endpos]]) Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.finditer(string[, pos[, endpos]]) Similar to the finditer() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.sub(repl, string, count=0) Identical to the sub() function, using the compiled pattern. Pattern.subn(repl, string, count=0) Identical to the subn() function, using the compiled pattern. Pattern.flags The regex", "score": "0.6776657"}]}
{"task_id": 547, "text": "Write a python function to find the sum of hamming distances of all consecutive numbers from o to n.", "code": "def Total_Hamming_Distance(n):   \r\n    i = 1\r\n    sum = 0\r\n    while (n // i > 0):  \r\n        sum = sum + n // i  \r\n        i = i * 2     \r\n    return sum", "test_list": ["assert Total_Hamming_Distance(4) == 7", "assert Total_Hamming_Distance(2) == 3", "assert Total_Hamming_Distance(5) == 8"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.6835952"}, {"id": "42873", "text": "Function: numpy.reference.generated.numpy.hamming\nSnippet: numpy.hamming numpy.hamming(M)[source] Return the Hamming window. The Hamming window is a taper formed by using a weighted cosine. Parameters Mint Number of points in the output window. If zero or less, an empty array is returned. Returns outndarray The window, with the maximum value normalized to one (the value one appears only if the number of samples is odd). See also bartlett, blackman, hanning, kaiser Notes The Hamming window is defined as \\[w(n) = 0.54 - 0.46cos\\left(\\frac{2\\pi{n}}{M-1}\\right) \\qquad 0 \\leq n \\leq M-1\\] The Hamming was named for R. W. Hamming, an associate of J. W. Tukey and is described in Blackman and Tukey. It was recommended for smoothing the truncated autocovariance function in the time domain. Most references to the Hamming window come from the signal processing literature, where it is used as one of many windowing functions for smoothing values. It is also known as an apodization (which means “removing the foot”, i.e. smoothing discontinuities at the beginning and end of the sampled signal) or tapering function. References 1 Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover Publications, New York. 2 E.R. Kanasewich, “Time Sequence Analysis in Geophysics”, The University of Alberta Press, 1975, pp. 109-110. 3 Wikipedia, “Window function”, https://en.wikipedia.org/wiki/Window_function 4 W.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, “Numerical Recipes”, Cambridge University Press, 1986, page 425. Examples >>> np.hamming(12) array([ 0.08 , 0.15302337, 0.34890909, 0.60546483, 0.84123594, # may vary 0.98136677, 0.98136677, 0.84123594, 0.60546483, 0.34890909, 0.15302337, 0.08 ]) Plot the window and the frequency response: >>> import matplotlib.pyplot as plt >>> from numpy.fft import fft, fftshift >>> window = np.hamming(51) >>> plt.plot(window) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title(\"Hamming window\") Text(0.5, 1.0, 'Hamming window') >>> plt.ylabel(\"Amplitude\") Text(0, 0.5, 'Amplitude') >>> plt.xlabel(\"Sample\") Text(0.5, 0, 'Sample') >>> plt.show() >>> plt.figure() <Figure size 640x480 with 0 Axes> >>> A = fft(window, 2048) / 25.5 >>> mag = np.abs(fftshift(A)) >>> freq = np.linspace(-0.5, 0.5, len(A)) >>> response = 20 * np.log10(mag) >>> response = np.clip(response, -100, 100) >>> plt.plot(freq, response) [<matplotlib.lines.Line2D object at 0x...>] >>> plt.title(\"Frequency response of Hamming window\") Text(0.5, 1.0, 'Frequency response of Hamming window') >>> plt.ylabel(\"Magnitude [dB]\") Text(0, 0.5, 'Magnitude [dB]') >>> plt.xlabel(\"Normalized frequency [cycles per sample]\") Text(0.5, 0, 'Normalized frequency [cycles per sample]') >>> plt.axis('tight') ... >>> plt.show()", "score": "0.68338376"}, {"id": "21290", "text": "Function: python.library.itertools\nSnippet: iterables are exhausted. Used for treating consecutive sequences as a single sequence. Roughly equivalent to: def chain(*iterables): # chain('ABC', 'DEF') --> A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily. Roughly equivalent to: def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n", "score": "0.6817728"}, {"id": "19648", "text": "Function: python.library.difflib#difflib.SequenceMatcher.get_matching_blocks\nSnippet: get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]", "score": "0.67722785"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.67677563"}]}
{"task_id": 548, "text": "Write a function to find the length of the longest increasing subsequence of the given sequence.", "code": "def longest_increasing_subsequence(arr): \r\n\tn = len(arr) \r\n\tlongest_increasing_subsequence = [1]*n \r\n\tfor i in range (1 , n): \r\n\t\tfor j in range(0 , i): \r\n\t\t\tif arr[i] > arr[j] and longest_increasing_subsequence[i]< longest_increasing_subsequence[j] + 1 : \r\n\t\t\t\tlongest_increasing_subsequence[i] = longest_increasing_subsequence[j]+1\r\n\tmaximum = 0\r\n\tfor i in range(n): \r\n\t\tmaximum = max(maximum , longest_increasing_subsequence[i]) \r\n\treturn maximum", "test_list": ["assert longest_increasing_subsequence([10, 22, 9, 33, 21, 50, 41, 60]) == 5", "assert longest_increasing_subsequence([3, 10, 2, 1, 20]) == 3", "assert longest_increasing_subsequence([50, 3, 10, 7, 40, 80]) == 4 "], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19646", "text": "Function: python.library.difflib#difflib.SequenceMatcher.find_longest_match\nSnippet: find_longest_match(alo=0, ahi=None, blo=0, bhi=None) Find longest matching block in a[alo:ahi] and b[blo:bhi]. If isjunk was omitted or None, find_longest_match() returns (i, j, k) such that a[i:i+k] is equal to b[j:j+k], where alo <= i <= i+k <= ahi and blo <= j <= j+k <= bhi. For all (i', j', k') meeting those conditions, the additional conditions k >= k', i <= i', and if i == i', j <= j' are also met. In other words, of all maximal matching blocks, return one that starts earliest in a, and of all those maximal matching blocks that start earliest in a, return the one that starts earliest in b. >>> s = SequenceMatcher(None, \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=0, b=4, size=5) If isjunk was provided, first the longest matching block is determined as above, but with the additional restriction that no junk element appears in the block. Then that block is extended as far as possible by matching (only) junk elements on both sides. So the resulting block never matches on junk except as identical junk happens to be adjacent to an interesting match. Here’s the same example as before, but considering blanks to be junk. That prevents ' abcd' from matching the ' abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence: >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=1, b=0, size=4) If no blocks match, this returns (alo, blo, 0). This method returns a named tuple Match(a, b, size). Changed in version 3.9: Added default arguments.", "score": "0.689012"}, {"id": "19644", "text": "Function: python.library.difflib#difflib.SequenceMatcher\nSnippet: abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence: >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=1, b=0, size=4) If no blocks match, this returns (alo, blo, 0). This method returns a named tuple Match(a, b, size). Changed in version 3.9: Added default arguments. get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution:", "score": "0.6875057"}, {"id": "18285", "text": "Function: python.library.stdtypes#bytearray.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.6785543"}, {"id": "18329", "text": "Function: python.library.stdtypes#bytes.rfind\nSnippet: bytes.rfind(sub[, start[, end]]) bytearray.rfind(sub[, start[, end]]) Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on failure. The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255. Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.", "score": "0.6785413"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.6693232"}]}
{"task_id": 549, "text": "Write a python function to find the sum of fifth power of first n odd natural numbers.", "code": "def odd_Num_Sum(n) : \r\n    j = 0\r\n    sm = 0\r\n    for i in range(1,n+1) : \r\n        j = (2*i-1) \r\n        sm = sm + (j*j*j*j*j)     \r\n    return sm ", "test_list": ["assert odd_Num_Sum(1) == 1", "assert odd_Num_Sum(2) == 244", "assert odd_Num_Sum(3) == 3369"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.66503286"}, {"id": "43141", "text": "Function: numpy.reference.generated.numpy.ravel\nSnippet: 3, 4, 5, 6, 7, 8, 9, 10, 11])", "score": "0.661642"}, {"id": "21297", "text": "Function: python.library.itertools\nSnippet: * (n - k + i) // i if index < 0: index += c if index < 0 or index >= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index >= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)", "score": "0.6591576"}, {"id": "25734", "text": "Function: python.library.stdtypes\nSnippet: in detail: If x = m / n is a nonnegative rational number and n is not divisible by P, define hash(x) as m * invmod(n, P) % P, where invmod(n, P) gives the inverse of n modulo P. If x = m / n is a nonnegative rational number and n is divisible by P (but m is not) then n has no inverse modulo P and the rule above doesn’t apply; in this case define hash(x) to be the constant value sys.hash_info.inf. If x = m / n is a negative rational number define hash(x) as -hash(-x). If the resulting hash is -1, replace it with -2. The particular values sys.hash_info.inf, -sys.hash_info.inf and sys.hash_info.nan are used as hash values for positive infinity, negative infinity, or nans (respectively). (All hashable nans have the same hash value.) For a complex number z, the hash values of the real and imaginary parts are combined by computing hash(z.real) + sys.hash_info.imag * hash(z.imag), reduced modulo 2**sys.hash_info.width so that it lies in range(-2**(sys.hash_info.width - 1), 2**(sys.hash_info.width - 1)). Again, if the result is -1, it’s replaced with -2. To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash of a rational number, float, or complex: import sys, math def hash_fraction(m, n): \"\"\"Compute the hash of a rational number m / n. Assumes m and n are integers, with n positive. Equivalent to hash(fractions.Fraction(m, n)). \"\"\" P = sys.hash_info.modulus # Remove common factors of P. (Unnecessary if m and n already coprime.) while m % P == n % P == 0: m, n = m // P, n // P if n % P == 0: hash_value = sys.hash_info.inf else: # Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P. hash_value = (abs(m) % P) * pow(n, P - 2, P) % P if m < 0: hash_value = -hash_value if hash_value == -1: hash_value = -2 return hash_value def hash_float(x): \"\"\"Compute the hash of a float x.\"\"\" if math.isnan(x): return sys.hash_info.nan elif math.isinf(x): return sys.hash_info.inf if x > 0 else -sys.hash_info.inf else: return hash_fraction(*x.as_integer_ratio()) def hash_complex(z): \"\"\"Compute the hash of a complex number z.\"\"\" hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag) # do a signed reduction modulo 2**sys.hash_info.width M = 2**(sys.hash_info.width - 1) hash_value = (hash_value & (M - 1)) - (hash_value & M) if hash_value == -1: hash_value = -2 return hash_value Iterator Types Python supports a concept of iteration over containers. This is implemented using two distinct methods; these are used to allow user-defined classes to support iteration. Sequences, described below in more detail, always support the iteration methods. One method needs to be defined for container objects to provide iteration support: container.__iter__() Return an iterator object. The object is required to support the iterator protocol described below. If a container supports different types of iteration, additional methods can be provided to specifically request iterators for those iteration types. (An example", "score": "0.64899045"}, {"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.6473809"}]}
{"task_id": 550, "text": "Write a python function to find the maximum element in a sorted and rotated array.", "code": "def find_Max(arr,low,high): \r\n    if (high < low): \r\n        return arr[0] \r\n    if (high == low): \r\n        return arr[low] \r\n    mid = low + (high - low) // 2 \r\n    if (mid < high and arr[mid + 1] < arr[mid]): \r\n        return arr[mid] \r\n    if (mid > low and arr[mid] < arr[mid - 1]): \r\n        return arr[mid - 1]  \r\n    if (arr[low] > arr[mid]): \r\n        return find_Max(arr,low,mid - 1) \r\n    else: \r\n        return find_Max(arr,mid + 1,high) ", "test_list": ["assert find_Max([2,3,5,6,9],0,4) == 9", "assert find_Max([3,4,5,2,1],0,4) == 5", "assert find_Max([1,2,3],0,2) == 3"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21837", "text": "Function: python.library.functions#max\nSnippet: max(iterable, *[, key, default]) max(arg1, arg2, *args[, key]) Return the largest item in an iterable or the largest of two or more arguments. If one positional argument is provided, it should be an iterable. The largest item in the iterable is returned. If two or more positional arguments are provided, the largest of the positional arguments is returned. There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function like that used for list.sort(). The default argument specifies an object to return if the provided iterable is empty. If the iterable is empty and default is not provided, a ValueError is raised. If multiple items are maximal, the function returns the first one encountered. This is consistent with other sort-stability preserving tools such as sorted(iterable, key=keyfunc, reverse=True)[0] and heapq.nlargest(1, iterable, key=keyfunc). New in version 3.4: The default keyword-only argument. Changed in version 3.8: The key can be None.", "score": "0.70372206"}, {"id": "43012", "text": "Function: numpy.reference.generated.numpy.maximum\nSnippet: numpy.maximum numpy.maximum(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'maximum'> Element-wise maximum of array elements. Compare two arrays and returns a new array containing the element-wise maxima. If one of the elements being compared is a NaN, then that element is returned. If both elements are NaNs then the first is returned. The latter distinction is important for complex NaNs, which are defined as at least one of the real or imaginary parts being a NaN. The net effect is that NaNs are propagated. Parameters x1, x2array_like The arrays holding the elements to be compared. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray or scalar The maximum of x1 and x2, element-wise. This is a scalar if both x1 and x2 are scalars. See also minimum Element-wise minimum of two arrays, propagates NaNs. fmax Element-wise maximum of two arrays, ignores NaNs. amax The maximum value of an array along a given axis, propagates NaNs. nanmax The maximum value of an array along a given axis, ignores NaNs. fmin, amin, nanmin Notes The maximum is equivalent to np.where(x1 >= x2, x1, x2) when neither x1 nor x2 are nans, but it is faster and does proper broadcasting. Examples >>> np.maximum([2, 3, 4], [1, 5, 2]) array([2, 5, 4]) >>> np.maximum(np.eye(2), [0.5, 2]) # broadcasting array([[ 1. , 2. ], [ 0.5, 2. ]]) >>> np.maximum([np.nan, 0, np.nan], [0, np.nan, np.nan]) array([nan, nan, nan]) >>> np.maximum(np.Inf, 1) inf", "score": "0.7015634"}, {"id": "43857", "text": "Function: numpy.reference.generated.numpy.recarray.max\nSnippet: numpy.recarray.max method recarray.max(axis=None, out=None, keepdims=False, initial=<no value>, where=True) Return the maximum along a given axis. Refer to numpy.amax for full documentation. See also numpy.amax equivalent function", "score": "0.6989225"}, {"id": "43053", "text": "Function: numpy.reference.generated.numpy.ndarray\nSnippet: the given axis. argpartition(kth[, axis, kind, order]) Returns the indices that would partition this array. argsort([axis, kind, order]) Returns the indices that would sort this array. astype(dtype[, order, casting, subok, copy]) Copy of the array, cast to a specified type. byteswap([inplace]) Swap the bytes of the array elements choose(choices[, out, mode]) Use an index array to construct a new array from a set of choices. clip([min, max, out]) Return an array whose values are limited to [min, max]. compress(condition[, axis, out]) Return selected slices of this array along given axis. conj() Complex-conjugate all elements. conjugate() Return the complex conjugate, element-wise. copy([order]) Return a copy of the array. cumprod([axis, dtype, out]) Return the cumulative product of the elements along the given axis. cumsum([axis, dtype, out]) Return the cumulative sum of the elements along the given axis. diagonal([offset, axis1, axis2]) Return specified diagonals. dump(file) Dump a pickle of the array to the specified file. dumps() Returns the pickle of the array as a string. fill(value) Fill the array with a scalar value. flatten([order]) Return a copy of the array collapsed into one dimension. getfield(dtype[, offset]) Returns a field of the given array as a certain type. item(*args) Copy an element of an array to a standard Python scalar and return it. itemset(*args) Insert scalar into an array (scalar is cast to array's dtype, if possible) max([axis, out, keepdims, initial, where]) Return the maximum along a given axis. mean([axis, dtype, out, keepdims, where]) Returns the average of the array elements along given axis. min([axis, out, keepdims, initial, where]) Return the minimum along a given axis. newbyteorder([new_order]) Return the array with the same data viewed with a different byte order. nonzero() Return the indices of the elements that are non-zero. partition(kth[, axis, kind, order]) Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. prod([axis, dtype, out, keepdims, initial, ...]) Return the product of the array elements over the given axis ptp([axis, out, keepdims]) Peak to peak (maximum - minimum) value along a given axis. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. reshape(shape[, order]) Returns an array containing the same data with a new shape. resize(new_shape[, refcheck]) Change shape and size of array in-place. round([decimals, out]) Return a with each element rounded to the given number of decimals. searchsorted(v[, side, sorter]) Find indices where elements of v should be inserted in a to maintain order. setfield(val, dtype[, offset]) Put a value into a specified place in a field defined by a data-type. setflags([write, align, uic]) Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY), respectively. sort([axis, kind, order]) Sort an array in-place. squeeze([axis]) Remove axes of length one from a. std([axis, dtype, out, ddof, keepdims, where]) Returns the standard deviation of the array elements along given axis. sum([axis, dtype, out, keepdims, initial, where]) Return the sum of the", "score": "0.68608403"}, {"id": "43147", "text": "Function: numpy.reference.generated.numpy.recarray\nSnippet: Peak to peak (maximum - minimum) value along a given axis. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. reshape(shape[, order]) Returns an array containing the same data with a new shape. resize(new_shape[, refcheck]) Change shape and size of array in-place. round([decimals, out]) Return a with each element rounded to the given number of decimals. searchsorted(v[, side, sorter]) Find indices where elements of v should be inserted in a to maintain order. setfield(val, dtype[, offset]) Put a value into a specified place in a field defined by a data-type. setflags([write, align, uic]) Set array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY), respectively. sort([axis, kind, order]) Sort an array in-place. squeeze([axis]) Remove axes of length one from a. std([axis, dtype, out, ddof, keepdims, where]) Returns the standard deviation of the array elements along given axis. sum([axis, dtype, out, keepdims, initial, where]) Return the sum of the array elements over the given axis. swapaxes(axis1, axis2) Return a view of the array with axis1 and axis2 interchanged. take(indices[, axis, out, mode]) Return an array formed from the elements of a at the given indices. tobytes([order]) Construct Python bytes containing the raw data bytes in the array. tofile(fid[, sep, format]) Write array to a file as text or binary (default). tolist() Return the array as an a.ndim-levels deep nested list of Python scalars. tostring([order]) A compatibility alias for tobytes, with exactly the same behavior. trace([offset, axis1, axis2, dtype, out]) Return the sum along diagonals of the array. transpose(*axes) Returns a view of the array with axes transposed. var([axis, dtype, out, ddof, keepdims, where]) Returns the variance of the array elements, along given axis. view([dtype][, type]) New view of array with the same data. dot field", "score": "0.6851023"}]}
{"task_id": 551, "text": "Write a function to extract a specified column from a given nested list.", "code": "def extract_column(list1, n):\r\n   result = [i.pop(n) for i in list1]\r\n   return result ", "test_list": ["assert extract_column([[1, 2, 3], [2, 4, 5], [1, 1, 1]],0)==[1, 2, 1]", "assert extract_column([[1, 2, 3], [-2, 4, -5], [1, -1, 1]],2)==[3, -5, 1]", "assert extract_column([[1, 3], [5, 7], [1, 3], [13, 15, 17], [5, 7], [9, 11]],0)==[1, 5, 1, 13, 5, 9]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "15030", "text": "Function: pandas.reference.api.pandas.read_table\nSnippet: Return a subset of the columns. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in names or inferred from the document header row(s). If names are given, the document header row(s) are not taken into account. For example, a valid list-like usecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz']. Element order is ignored, so usecols=[0, 1] is the same as [1, 0]. To instantiate a DataFrame from data with element order preserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']] for columns in ['foo', 'bar'] order or pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']] for ['bar', 'foo'] order. If callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True. An example of a valid callable argument would be lambda x: x.upper() in ['AAA', 'BBB', 'DDD']. Using this parameter results in much faster parsing time and lower memory usage. squeeze:bool, default False If the parsed data only contains one column then return a Series. Deprecated since version 1.4.0: Append .squeeze(\"columns\") to the call to read_table to squeeze the data. prefix:str, optional Prefix to add to column numbers when no header, e.g. ‘X’ for X0, X1, … Deprecated since version 1.4.0: Use a list comprehension on the DataFrame’s columns after calling read_csv. mangle_dupe_cols:bool, default True Duplicate columns will be specified as ‘X’, ‘X.1’, …’X.N’, rather than ‘X’…’X’. Passing in False will cause data to be overwritten if there are duplicate names in the columns. dtype:Type name or dict of column -> type, optional Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’} Use str or object together with suitable na_values settings to preserve and not interpret dtype. If converters are specified, they will be applied INSTEAD of dtype conversion. engine:{‘c’, ‘python’, ‘pyarrow’}, optional Parser engine to use. The C and pyarrow engines are faster, while the python engine is currently more feature-complete. Multithreading is currently only supported by the pyarrow engine. New in version 1.4.0: The “pyarrow” engine was added as an experimental engine, and some features are unsupported, or may not work correctly, with this engine. converters:dict, optional Dict of functions for converting values in certain columns. Keys can either be integers or column labels. true_values:list, optional Values to consider as True. false_values:list, optional Values to consider as False. skipinitialspace:bool, default False Skip spaces after delimiter. skiprows:list-like, int or callable, optional Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file. If callable, the callable function will be evaluated against the row indices, returning True if the row should be skipped and False otherwise. An example of a valid callable argument would be lambda x: x in [0, 2]. skipfooter:int, default 0 Number of lines at bottom of file to skip (Unsupported with engine=’c’). nrows:int, optional Number of rows of file to read. Useful for reading pieces of large files. na_values:scalar, str, list-like,", "score": "0.69557726"}, {"id": "14999", "text": "Function: pandas.reference.api.pandas.read_csv\nSnippet: optional Return a subset of the columns. If list-like, all elements must either be positional (i.e. integer indices into the document columns) or strings that correspond to column names provided either by the user in names or inferred from the document header row(s). If names are given, the document header row(s) are not taken into account. For example, a valid list-like usecols parameter would be [0, 1, 2] or ['foo', 'bar', 'baz']. Element order is ignored, so usecols=[0, 1] is the same as [1, 0]. To instantiate a DataFrame from data with element order preserved use pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']] for columns in ['foo', 'bar'] order or pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']] for ['bar', 'foo'] order. If callable, the callable function will be evaluated against the column names, returning names where the callable function evaluates to True. An example of a valid callable argument would be lambda x: x.upper() in ['AAA', 'BBB', 'DDD']. Using this parameter results in much faster parsing time and lower memory usage. squeeze:bool, default False If the parsed data only contains one column then return a Series. Deprecated since version 1.4.0: Append .squeeze(\"columns\") to the call to read_csv to squeeze the data. prefix:str, optional Prefix to add to column numbers when no header, e.g. ‘X’ for X0, X1, … Deprecated since version 1.4.0: Use a list comprehension on the DataFrame’s columns after calling read_csv. mangle_dupe_cols:bool, default True Duplicate columns will be specified as ‘X’, ‘X.1’, …’X.N’, rather than ‘X’…’X’. Passing in False will cause data to be overwritten if there are duplicate names in the columns. dtype:Type name or dict of column -> type, optional Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’} Use str or object together with suitable na_values settings to preserve and not interpret dtype. If converters are specified, they will be applied INSTEAD of dtype conversion. engine:{‘c’, ‘python’, ‘pyarrow’}, optional Parser engine to use. The C and pyarrow engines are faster, while the python engine is currently more feature-complete. Multithreading is currently only supported by the pyarrow engine. New in version 1.4.0: The “pyarrow” engine was added as an experimental engine, and some features are unsupported, or may not work correctly, with this engine. converters:dict, optional Dict of functions for converting values in certain columns. Keys can either be integers or column labels. true_values:list, optional Values to consider as True. false_values:list, optional Values to consider as False. skipinitialspace:bool, default False Skip spaces after delimiter. skiprows:list-like, int or callable, optional Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file. If callable, the callable function will be evaluated against the row indices, returning True if the row should be skipped and False otherwise. An example of a valid callable argument would be lambda x: x in [0, 2]. skipfooter:int, default 0 Number of lines at bottom of file to skip (Unsupported with engine=’c’). nrows:int, optional Number of rows of file to read. Useful for reading pieces of large files. na_values:scalar, str,", "score": "0.6867951"}, {"id": "15327", "text": "Function: pandas.reference.api.pandas.series.str.extract\nSnippet: pandas.Series.str.extract Series.str.extract(pat, flags=0, expand=True)[source] Extract capture groups in the regex pat as columns in a DataFrame. For each subject string in the Series, extract groups from the first match of regular expression pat. Parameters pat:str Regular expression pattern with capturing groups. flags:int, default 0 (no flags) Flags from the re module, e.g. re.IGNORECASE, that modify regular expression matching for things like case, spaces, etc. For more details, see re. expand:bool, default True If True, return DataFrame with one column per capture group. If False, return a Series/Index if there is one capture group or DataFrame if there are multiple capture groups. Returns DataFrame or Series or Index A DataFrame with one row for each subject string, and one column for each group. Any capture group names in regular expression pat will be used for column names; otherwise capture group numbers will be used. The dtype of each result column is always object, even when no match is found. If expand=False and pat has only one capture group, then return a Series (if subject is a Series) or Index (if subject is an Index). See also extractall Returns all matches (not just the first match). Examples A pattern with two groups will return a DataFrame with two columns. Non-matches will be NaN. >>> s = pd.Series(['a1', 'b2', 'c3']) >>> s.str.extract(r'([ab])(\\d)') 0 1 0 a 1 1 b 2 2 NaN NaN A pattern may contain optional groups. >>> s.str.extract(r'([ab])?(\\d)') 0 1 0 a 1 1 b 2 2 NaN 3 Named groups will become column names in the result. >>> s.str.extract(r'(?P<letter>[ab])(?P<digit>\\d)') letter digit 0 a 1 1 b 2 2 NaN NaN A pattern with one group will return a DataFrame with one column if expand=True. >>> s.str.extract(r'[ab](\\d)', expand=True) 0 0 1 1 2 2 NaN A pattern with one group will return a Series if expand=False. >>> s.str.extract(r'[ab](\\d)', expand=False) 0 1 1 2 2 NaN dtype: object", "score": "0.68598986"}, {"id": "15328", "text": "Function: pandas.reference.api.pandas.series.str.extractall\nSnippet: pandas.Series.str.extractall Series.str.extractall(pat, flags=0)[source] Extract capture groups in the regex pat as columns in DataFrame. For each subject string in the Series, extract groups from all matches of regular expression pat. When each subject string in the Series has exactly one match, extractall(pat).xs(0, level=’match’) is the same as extract(pat). Parameters pat:str Regular expression pattern with capturing groups. flags:int, default 0 (no flags) A re module flag, for example re.IGNORECASE. These allow to modify regular expression matching for things like case, spaces, etc. Multiple flags can be combined with the bitwise OR operator, for example re.IGNORECASE | re.MULTILINE. Returns DataFrame A DataFrame with one row for each match, and one column for each group. Its rows have a MultiIndex with first levels that come from the subject Series. The last level is named ‘match’ and indexes the matches in each item of the Series. Any capture group names in regular expression pat will be used for column names; otherwise capture group numbers will be used. See also extract Returns first match only (not all matches). Examples A pattern with one group will return a DataFrame with one column. Indices with no matches will not appear in the result. >>> s = pd.Series([\"a1a2\", \"b1\", \"c1\"], index=[\"A\", \"B\", \"C\"]) >>> s.str.extractall(r\"[ab](\\d)\") 0 match A 0 1 1 2 B 0 1 Capture group names are used for column names of the result. >>> s.str.extractall(r\"[ab](?P<digit>\\d)\") digit match A 0 1 1 2 B 0 1 A pattern with two groups will return a DataFrame with two columns. >>> s.str.extractall(r\"(?P<letter>[ab])(?P<digit>\\d)\") letter digit match A 0 a 1 1 a 2 B 0 b 1 Optional groups that do not match are NaN in the result. >>> s.str.extractall(r\"(?P<letter>[ab])?(?P<digit>\\d)\") letter digit match A 0 a 1 1 a 2 B 0 b 1 C 0 NaN 1", "score": "0.6813302"}, {"id": "35644", "text": "Function: django.ref.models.expressions#django.db.models.Expression.get_group_by_cols\nSnippet: get_group_by_cols(alias=None) Responsible for returning the list of columns references by this expression. get_group_by_cols() should be called on any nested expressions. F() objects, in particular, hold a reference to a column. The alias parameter will be None unless the expression has been annotated and is used for grouping.", "score": "0.67473423"}]}
{"task_id": 552, "text": "Write a python function to check whether a given sequence is linear or not.", "code": "def Seq_Linear(seq_nums):\r\n  seq_nums = [seq_nums[x] - seq_nums[x-1] for x in range(1, len(seq_nums))]\r\n  if len(set(seq_nums)) == 1: \r\n    return \"Linear Sequence\"\r\n  else:\r\n    return \"Non Linear Sequence\"", "test_list": ["assert Seq_Linear([0,2,4,6,8,10]) == \"Linear Sequence\"", "assert Seq_Linear([1,2,3]) == \"Linear Sequence\"", "assert Seq_Linear([1,5,2]) == \"Non Linear Sequence\""], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42785", "text": "Function: numpy.reference.distutils.misc_util#numpy.distutils.misc_util.is_sequence\nSnippet: numpy.distutils.misc_util.is_sequence(seq)[source]", "score": "0.74146724"}, {"id": "34083", "text": "Function: matplotlib.transformations#matplotlib.transforms.AffineBase.is_affine\nSnippet: is_affine=True", "score": "0.6808169"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.67887586"}, {"id": "36672", "text": "Function: django.ref.contrib.gis.geos#django.contrib.gis.geos.LinearRing.is_counterclockwise\nSnippet: is_counterclockwise Returns whether this LinearRing is counterclockwise.", "score": "0.6765549"}, {"id": "36656", "text": "Function: django.ref.contrib.gis.geos#django.contrib.gis.geos.GEOSGeometry.ring\nSnippet: GEOSGeometry.ring Returns a boolean indicating whether the geometry is a LinearRing.", "score": "0.669764"}]}
{"task_id": 553, "text": "Write a function to convert the given tuple to a floating-point number.", "code": "def tuple_to_float(test_tup):\r\n  res = float('.'.join(str(ele) for ele in test_tup))\r\n  return (res) ", "test_list": ["assert tuple_to_float((4, 56)) == 4.56", "assert tuple_to_float((7, 256)) == 7.256", "assert tuple_to_float((8, 123)) == 8.123"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19524", "text": "Function: python.library.decimal#decimal.Decimal.as_tuple\nSnippet: as_tuple() Return a named tuple representation of the number: DecimalTuple(sign, digits, exponent).", "score": "0.71956986"}, {"id": "42836", "text": "Function: numpy.reference.arrays.scalars#numpy.float64\nSnippet: numpy.float64[source] alias of numpy.double", "score": "0.7062062"}, {"id": "19442", "text": "Function: python.library.decimal\nSnippet: In developing fixed-point applications, it is convenient to define functions to handle the quantize() step: >>> def mul(x, y, fp=TWOPLACES): ... return (x * y).quantize(fp) >>> def div(x, y, fp=TWOPLACES): ... return (x / y).quantize(fp) >>> mul(a, b) # Automatically preserve fixed-point Decimal('325.62') >>> div(b, a) Decimal('0.03') Q. There are many ways to express the same value. The numbers 200, 200.000, 2E2, and 02E+4 all have the same value at various precisions. Is there a way to transform them to a single recognizable canonical value? A. The normalize() method maps all equivalent values to a single representative: >>> values = map(Decimal, '200 200.000 2E2 .02E+4'.split()) >>> [v.normalize() for v in values] [Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')] Q. Some decimal values always print with exponential notation. Is there a way to get a non-exponential representation? A. For some values, exponential notation is the only way to express the number of significant places in the coefficient. For example, expressing 5.0E+3 as 5000 keeps the value constant but cannot show the original’s two-place significance. If an application does not care about tracking significance, it is easy to remove the exponent and trailing zeroes, losing significance, but keeping the value unchanged: >>> def remove_exponent(d): ... return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize() >>> remove_exponent(Decimal('5E+3')) Decimal('5000') Q. Is there a way to convert a regular float to a Decimal? A. Yes, any binary floating point number can be exactly expressed as a Decimal though an exact conversion may take more precision than intuition would suggest: >>> Decimal(math.pi) Decimal('3.141592653589793115997963468544185161590576171875') Q. Within a complex calculation, how can I make sure that I haven’t gotten a spurious result because of insufficient precision or rounding anomalies. A. The decimal module makes it easy to test results. A best practice is to re-run calculations using greater precision and with various rounding modes. Widely differing results indicate insufficient precision, rounding mode issues, ill-conditioned inputs, or a numerically unstable algorithm. Q. I noticed that context precision is applied to the results of operations but not to the inputs. Is there anything to watch out for when mixing values of different precisions? A. Yes. The principle is that all values are considered to be exact and so is the arithmetic on those values. Only the results are rounded. The advantage for inputs is that “what you type is what you get”. A disadvantage is that the results can look odd if you forget that the inputs haven’t been rounded: >>> getcontext().prec = 3 >>> Decimal('3.104') + Decimal('2.104') Decimal('5.21') >>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104') Decimal('5.20') The solution is either to increase precision or to force rounding of inputs using the unary plus operation: >>> getcontext().prec = 3 >>> +Decimal('1.23456789') # unary plus triggers rounding Decimal('1.23') Alternatively, inputs can be rounded upon creation using the Context.create_decimal() method: >>> Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678') Decimal('1.2345') Q. Is the CPython implementation fast for large numbers? A. Yes. In the CPython and PyPy3 implementations, the C/CFFI versions of the decimal module integrate the high speed libmpdec library for arbitrary precision", "score": "0.70593166"}, {"id": "19516", "text": "Function: python.library.decimal#decimal.Decimal\nSnippet: class decimal.Decimal(value=\"0\", context=None) Construct a new Decimal object based from value. value can be an integer, string, tuple, float, or another Decimal object. If no value is given, returns Decimal('0'). If value is a string, it should conform to the decimal numeric string syntax after leading and trailing whitespace characters, as well as underscores throughout, are removed: sign ::= '+' | '-' digit ::= '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' indicator ::= 'e' | 'E' digits ::= digit [digit]... decimal-part ::= digits '.' [digits] | ['.'] digits exponent-part ::= indicator [sign] digits infinity ::= 'Infinity' | 'Inf' nan ::= 'NaN' [digits] | 'sNaN' [digits] numeric-value ::= decimal-part [exponent-part] | infinity numeric-string ::= [sign] numeric-value | [sign] nan Other Unicode decimal digits are also permitted where digit appears above. These include decimal digits from various other alphabets (for example, Arabic-Indic and Devanāgarī digits) along with the fullwidth digits '\\uff10' through '\\uff19'. If value is a tuple, it should have three components, a sign (0 for positive or 1 for negative), a tuple of digits, and an integer exponent. For example, Decimal((0, (1, 4, 1, 4), -3)) returns Decimal('1.414'). If value is a float, the binary floating point value is losslessly converted to its exact decimal equivalent. This conversion can often require 53 or more digits of precision. For example, Decimal(float('1.1')) converts to Decimal('1.100000000000000088817841970012523233890533447265625'). The context precision does not affect how many digits are stored. That is determined exclusively by the number of digits in value. For example, Decimal('3.00000') records all five zeros even if the context precision is only three. The purpose of the context argument is determining what to do if value is a malformed string. If the context traps InvalidOperation, an exception is raised; otherwise, the constructor returns a new Decimal with the value of NaN. Once constructed, Decimal objects are immutable. Changed in version 3.2: The argument to the constructor is now permitted to be a float instance. Changed in version 3.3: float arguments raise an exception if the FloatOperation trap is set. By default the trap is off. Changed in version 3.6: Underscores are allowed for grouping, as with integral and floating-point literals in code. Decimal floating point objects share many properties with the other built-in numeric types such as float and int. All of the usual math operations and special methods apply. Likewise, decimal objects can be copied, pickled, printed, used as dictionary keys, used as set elements, compared, sorted, and coerced to another type (such as float or int). There are some small differences between arithmetic on Decimal objects and arithmetic on integers and floats. When the remainder operator % is applied to Decimal objects, the sign of the result is the sign of the dividend rather than the sign of the divisor: >>> (-7) % 4 1 >>> Decimal(-7) % Decimal(4) Decimal('-3') The integer division operator // behaves analogously, returning the integer part of the true quotient (truncating towards zero) rather", "score": "0.7038083"}, {"id": "42835", "text": "Function: numpy.reference.arrays.scalars#numpy.float32\nSnippet: numpy.float32[source] alias of numpy.single", "score": "0.70331013"}]}
{"task_id": 554, "text": "Write a python function to find odd numbers from a mixed list.", "code": "def Split(list): \r\n    od_li = [] \r\n    for i in list: \r\n        if (i % 2 != 0): \r\n            od_li.append(i)  \r\n    return od_li", "test_list": ["assert Split([1,2,3,4,5,6]) == [1,3,5]", "assert Split([10,11,12,13]) == [11,13]", "assert Split([7,8,9,1]) == [7,9,1]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21297", "text": "Function: python.library.itertools\nSnippet: * (n - k + i) // i if index < 0: index += c if index < 0 or index >= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index >= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)", "score": "0.6592969"}, {"id": "21310", "text": "Function: python.library.itertools#itertools.permutations\nSnippet: itertools.permutations(iterable, r=None) Return successive r length permutations of elements in the iterable. If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.65098333"}, {"id": "43141", "text": "Function: numpy.reference.generated.numpy.ravel\nSnippet: 3, 4, 5, 6, 7, 8, 9, 10, 11])", "score": "0.649381"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.6460302"}, {"id": "23288", "text": "Function: python.library.random#random.shuffle\nSnippet: random.shuffle(x[, random]) Shuffle the sequence x in place. The optional argument random is a 0-argument function returning a random float in [0.0, 1.0); by default, this is the function random(). To shuffle an immutable sequence and return a new shuffled list, use sample(x, k=len(x)) instead. Note that even for small len(x), the total number of permutations of x can quickly grow larger than the period of most random number generators. This implies that most permutations of a long sequence can never be generated. For example, a sequence of length 2080 is the largest that can fit within the period of the Mersenne Twister random number generator. Deprecated since version 3.9, will be removed in version 3.11: The optional parameter random.", "score": "0.64427924"}]}
{"task_id": 555, "text": "Write a python function to find the difference between sum of cubes of first n natural numbers and the sum of first n natural numbers.", "code": "def difference(n) :  \r\n    S = (n*(n + 1))//2;  \r\n    res = S*(S-1);  \r\n    return res;  ", "test_list": ["assert difference(3) == 30", "assert difference(5) == 210", "assert difference(2) == 6"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42126", "text": "Function: numpy.reference.generated.numpy.ma.diff\nSnippet: numpy.ma.diff ma.diff(*args, **kwargs) = <numpy.ma.core._convert2ma object> Calculate the n-th discrete difference along the given axis. The first difference is given by out[i] = a[i+1] - a[i] along the given axis, higher differences are calculated by using diff recursively. Parameters aarray_like Input array nint, optional The number of times values are differenced. If zero, the input is returned as-is. axisint, optional The axis along which the difference is taken, default is the last axis. prepend, appendarray_like, optional Values to prepend or append to a along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match a except along axis. New in version 1.16.0. Returns diffMaskedArray The n-th differences. The shape of the output is the same as a except along axis where the dimension is smaller by n. The type of the output is the same as the type of the difference between any two elements of a. This is the same as the type of a in most cases. A notable exception is datetime64, which results in a timedelta64 output array. See also gradient, ediff1d, cumsum Notes Type is preserved for boolean arrays, so the result will contain False when consecutive elements are the same and True when they differ. For unsigned integer arrays, the results will also be unsigned. This should not be surprising, as the result is consistent with calculating the difference directly: >>> u8_arr = np.array([1, 0], dtype=np.uint8) >>> np.diff(u8_arr) array([255], dtype=uint8) >>> u8_arr[1,...] - u8_arr[0,...] 255 If this is not desirable, then the array should be cast to a larger integer type first: >>> i16_arr = u8_arr.astype(np.int16) >>> np.diff(i16_arr) array([-1], dtype=int16) Examples >>> x = np.array([1, 2, 4, 7, 0]) >>> np.diff(x) array([ 1, 2, 3, -7]) >>> np.diff(x, n=2) array([ 1, 1, -10]) >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]]) >>> np.diff(x) array([[2, 3, 4], [5, 1, 2]]) >>> np.diff(x, axis=0) array([[-1, 2, 0, -2]]) >>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64) >>> np.diff(x) array([1, 1], dtype='timedelta64[D]')", "score": "0.67066664"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.66818285"}, {"id": "21823", "text": "Function: python.library.math#math.perm\nSnippet: math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8.", "score": "0.66800344"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6677118"}, {"id": "42745", "text": "Function: numpy.reference.generated.numpy.diff\nSnippet: numpy.diff numpy.diff(a, n=1, axis=-1, prepend=<no value>, append=<no value>)[source] Calculate the n-th discrete difference along the given axis. The first difference is given by out[i] = a[i+1] - a[i] along the given axis, higher differences are calculated by using diff recursively. Parameters aarray_like Input array nint, optional The number of times values are differenced. If zero, the input is returned as-is. axisint, optional The axis along which the difference is taken, default is the last axis. prepend, appendarray_like, optional Values to prepend or append to a along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match a except along axis. New in version 1.16.0. Returns diffndarray The n-th differences. The shape of the output is the same as a except along axis where the dimension is smaller by n. The type of the output is the same as the type of the difference between any two elements of a. This is the same as the type of a in most cases. A notable exception is datetime64, which results in a timedelta64 output array. See also gradient, ediff1d, cumsum Notes Type is preserved for boolean arrays, so the result will contain False when consecutive elements are the same and True when they differ. For unsigned integer arrays, the results will also be unsigned. This should not be surprising, as the result is consistent with calculating the difference directly: >>> u8_arr = np.array([1, 0], dtype=np.uint8) >>> np.diff(u8_arr) array([255], dtype=uint8) >>> u8_arr[1,...] - u8_arr[0,...] 255 If this is not desirable, then the array should be cast to a larger integer type first: >>> i16_arr = u8_arr.astype(np.int16) >>> np.diff(i16_arr) array([-1], dtype=int16) Examples >>> x = np.array([1, 2, 4, 7, 0]) >>> np.diff(x) array([ 1, 2, 3, -7]) >>> np.diff(x, n=2) array([ 1, 1, -10]) >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]]) >>> np.diff(x) array([[2, 3, 4], [5, 1, 2]]) >>> np.diff(x, axis=0) array([[-1, 2, 0, -2]]) >>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64) >>> np.diff(x) array([1, 1], dtype='timedelta64[D]')", "score": "0.6658265"}]}
{"task_id": 556, "text": "Write a python function to count the pairs with xor as an odd number.", "code": "def find_Odd_Pair(A,N) : \r\n    oddPair = 0\r\n    for i in range(0,N) :  \r\n        for j in range(i+1,N) :  \r\n            if ((A[i] ^ A[j]) % 2 != 0):  \r\n                oddPair+=1  \r\n    return oddPair  ", "test_list": ["assert find_Odd_Pair([5,4,7,2,1],5) == 6", "assert find_Odd_Pair([7,2,8,1,0,5,11],7) == 12", "assert find_Odd_Pair([1,2,3],3) == 2"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "22353", "text": "Function: python.library.operator#operator.xor\nSnippet: operator.xor(a, b) operator.__xor__(a, b) Return the bitwise exclusive or of a and b.", "score": "0.7138398"}, {"id": "22398", "text": "Function: python.library.operator#operator.__xor__\nSnippet: operator.xor(a, b) operator.__xor__(a, b) Return the bitwise exclusive or of a and b.", "score": "0.7042614"}, {"id": "22297", "text": "Function: python.library.operator\nSnippet: known as “true” division. operator.xor(a, b) operator.__xor__(a, b) Return the bitwise exclusive or of a and b. Operations which work with sequences (some of them with mappings too) include: operator.concat(a, b) operator.__concat__(a, b) Return a + b for a and b sequences. operator.contains(a, b) operator.__contains__(a, b) Return the outcome of the test b in a. Note the reversed operands. operator.countOf(a, b) Return the number of occurrences of b in a. operator.delitem(a, b) operator.__delitem__(a, b) Remove the value of a at index b. operator.getitem(a, b) operator.__getitem__(a, b) Return the value of a at index b. operator.indexOf(a, b) Return the index of the first of occurrence of b in a. operator.setitem(a, b, c) operator.__setitem__(a, b, c) Set the value of a at index b to c. operator.length_hint(obj, default=0) Return an estimated length for the object o. First try to return its actual length, then an estimate using object.__length_hint__(), and finally return the default value. New in version 3.4. The operator module also defines tools for generalized attribute and item lookups. These are useful for making fast field extractors as arguments for map(), sorted(), itertools.groupby(), or other functions that expect a function argument. operator.attrgetter(attr) operator.attrgetter(*attrs) Return a callable object that fetches attr from its operand. If more than one attribute is requested, returns a tuple of attributes. The attribute names can also contain dots. For example: After f = attrgetter('name'), the call f(b) returns b.name. After f = attrgetter('name', 'date'), the call f(b) returns (b.name, b.date). After f = attrgetter('name.first', 'name.last'), the call f(b) returns (b.name.first, b.name.last). Equivalent to: def attrgetter(*items): if any(not isinstance(item, str) for item in items): raise TypeError('attribute name must be a string') if len(items) == 1: attr = items[0] def g(obj): return resolve_attr(obj, attr) else: def g(obj): return tuple(resolve_attr(obj, attr) for attr in items) return g def resolve_attr(obj, attr): for name in attr.split(\".\"): obj = getattr(obj, name) return obj operator.itemgetter(item) operator.itemgetter(*items) Return a callable object that fetches item from its operand using the operand’s __getitem__() method. If multiple items are specified, returns a tuple of lookup values. For example: After f = itemgetter(2), the call f(r) returns r[2]. After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3]). Equivalent to: def itemgetter(*items): if len(items) == 1: item = items[0] def g(obj): return obj[item] else: def g(obj): return tuple(obj[item] for item in items) return g The items can be any type accepted by the operand’s __getitem__() method. Dictionaries accept any hashable value. Lists, tuples, and strings accept an index or a slice: >>> itemgetter(1)('ABCDEFG') 'B' >>> itemgetter(1, 3, 5)('ABCDEFG') ('B', 'D', 'F') >>> itemgetter(slice(2, None))('ABCDEFG') 'CDEFG' >>> soldier = dict(rank='captain', name='dotterbart') >>> itemgetter('rank')(soldier) 'captain' Example of using itemgetter() to retrieve specific fields from a tuple record: >>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)] >>> getcount = itemgetter(1) >>> list(map(getcount, inventory)) [3, 2, 5, 1] >>> sorted(inventory, key=getcount) [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)] operator.methodcaller(name, /, *args, **kwargs) Return a callable object that calls the method name on its operand. If additional", "score": "0.6820365"}, {"id": "7760", "text": "Function: torch.tensors#torch.Tensor.bitwise_xor_\nSnippet: bitwise_xor_() → Tensor In-place version of bitwise_xor()", "score": "0.6805793"}, {"id": "22306", "text": "Function: python.library.operator#operator.countOf\nSnippet: operator.countOf(a, b) Return the number of occurrences of b in a.", "score": "0.678977"}]}
{"task_id": 557, "text": "Write a function to toggle characters case in a string.", "code": "def toggle_string(string):\r\n string1 = string.swapcase()\r\n return string1", "test_list": ["assert toggle_string(\"Python\")==(\"pYTHON\")", "assert toggle_string(\"Pangram\")==(\"pANGRAM\")", "assert toggle_string(\"LIttLE\")==(\"liTTle\")"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "25745", "text": "Function: python.library.stdtypes\nSnippet: cased character, False otherwise. >>> 'BANANA'.isupper() True >>> 'banana'.isupper() False >>> 'baNana'.isupper() False >>> ' '.isupper() False str.join(iterable) Return a string which is the concatenation of the strings in iterable. A TypeError will be raised if there are any non-string values in iterable, including bytes objects. The separator between elements is the string providing this method. str.ljust(width[, fillchar]) Return the string left justified in a string of length width. Padding is done using the specified fillchar (default is an ASCII space). The original string is returned if width is less than or equal to len(s). str.lower() Return a copy of the string with all the cased characters 4 converted to lowercase. The lowercasing algorithm used is described in section 3.13 of the Unicode Standard. str.lstrip([chars]) Return a copy of the string with leading characters removed. The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a prefix; rather, all combinations of its values are stripped: >>> ' spacious '.lstrip() 'spacious ' >>> 'www.example.com'.lstrip('cmowz.') 'example.com' See str.removeprefix() for a method that will remove a single prefix string rather than all of a set of characters. For example: >>> 'Arthur: three!'.lstrip('Arthur: ') 'ee!' >>> 'Arthur: three!'.removeprefix('Arthur: ') 'three!' static str.maketrans(x[, y[, z]]) This static method returns a translation table usable for str.translate(). If there is only one argument, it must be a dictionary mapping Unicode ordinals (integers) or characters (strings of length 1) to Unicode ordinals, strings (of arbitrary lengths) or None. Character keys will then be converted to ordinals. If there are two arguments, they must be strings of equal length, and in the resulting dictionary, each character in x will be mapped to the character at the same position in y. If there is a third argument, it must be a string, whose characters will be mapped to None in the result. str.partition(sep) Split the string at the first occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing the string itself, followed by two empty strings. str.removeprefix(prefix, /) If the string starts with the prefix string, return string[len(prefix):]. Otherwise, return a copy of the original string: >>> 'TestHook'.removeprefix('Test') 'Hook' >>> 'BaseTestCase'.removeprefix('Test') 'BaseTestCase' New in version 3.9. str.removesuffix(suffix, /) If the string ends with the suffix string and that suffix is not empty, return string[:-len(suffix)]. Otherwise, return a copy of the original string: >>> 'MiscTests'.removesuffix('Tests') 'Misc' >>> 'TmpDirMixin'.removesuffix('Tests') 'TmpDirMixin' New in version 3.9. str.replace(old, new[, count]) Return a copy of the string with all occurrences of substring old replaced by new. If the optional argument count is given, only the first count occurrences are replaced. str.rfind(sub[, start[, end]]) Return the highest index in the string where substring sub is found, such that sub is contained within s[start:end]. Optional arguments start and end are interpreted as in slice notation.", "score": "0.73933923"}, {"id": "24381", "text": "Function: python.library.stdtypes#str.swapcase\nSnippet: str.swapcase() Return a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is not necessarily true that s.swapcase().swapcase() == s.", "score": "0.73073137"}, {"id": "41825", "text": "Function: numpy.reference.generated.numpy.chararray.swapcase\nSnippet: numpy.chararray.swapcase method chararray.swapcase()[source] For each element in self, return a copy of the string with uppercase characters converted to lowercase and vice versa. See also char.swapcase", "score": "0.72249925"}, {"id": "41704", "text": "Function: numpy.reference.generated.numpy.char.chararray.swapcase\nSnippet: numpy.char.chararray.swapcase method char.chararray.swapcase()[source] For each element in self, return a copy of the string with uppercase characters converted to lowercase and vice versa. See also char.swapcase", "score": "0.7209085"}, {"id": "24361", "text": "Function: python.library.stdtypes#str.isupper\nSnippet: str.isupper() Return True if all cased characters 4 in the string are uppercase and there is at least one cased character, False otherwise. >>> 'BANANA'.isupper() True >>> 'banana'.isupper() False >>> 'baNana'.isupper() False >>> ' '.isupper() False", "score": "0.71205884"}]}
{"task_id": 558, "text": "Write a python function to find the digit distance between two integers.", "code": "def digit_distance_nums(n1, n2):\r\n         return sum(map(int,str(abs(n1-n2))))", "test_list": ["assert digit_distance_nums(1,2) == 1", "assert digit_distance_nums(23,56) == 6", "assert digit_distance_nums(123,256) == 7"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21792", "text": "Function: python.library.math#math.dist\nSnippet: math.dist(p, q) Return the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Roughly equivalent to: sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q))) New in version 3.8.", "score": "0.7115909"}, {"id": "24403", "text": "Function: python.library.string#string.digits\nSnippet: string.digits The string '0123456789'.", "score": "0.6876713"}, {"id": "25625", "text": "Function: python.library.turtle#turtle.distance\nSnippet: turtle.distance(x, y=None) Parameters x – a number or a pair/vector of numbers or a turtle instance y – a number if x is a number, else None Return the distance from the turtle to (x,y), the given vector, or the given other turtle, in turtle step units. >>> turtle.home() >>> turtle.distance(30,40) 50.0 >>> turtle.distance((30,40)) 50.0 >>> joe = Turtle() >>> joe.forward(77) >>> turtle.distance(joe) 77.0", "score": "0.68463707"}, {"id": "6998", "text": "Function: torch.nn.functional#torch.nn.functional.pairwise_distance\nSnippet: torch.nn.functional.pairwise_distance(x1, x2, p=2.0, eps=1e-06, keepdim=False) [source] See torch.nn.PairwiseDistance for details", "score": "0.68022"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.679713"}]}
{"task_id": 559, "text": "Write a function to find the largest sum of contiguous subarray in the given array.", "code": "def max_sub_array_sum(a, size):\r\n  max_so_far = 0\r\n  max_ending_here = 0\r\n  for i in range(0, size):\r\n    max_ending_here = max_ending_here + a[i]\r\n    if max_ending_here < 0:\r\n      max_ending_here = 0\r\n    elif (max_so_far < max_ending_here):\r\n      max_so_far = max_ending_here\r\n  return max_so_far", "test_list": ["assert max_sub_array_sum([-2, -3, 4, -1, -2, 1, 5, -3], 8) == 7", "assert max_sub_array_sum([-3, -4, 5, -2, -3, 2, 6, -4], 8) == 8", "assert max_sub_array_sum([-4, -5, 6, -3, -4, 3, 7, -5], 8) == 10"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43012", "text": "Function: numpy.reference.generated.numpy.maximum\nSnippet: numpy.maximum numpy.maximum(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'maximum'> Element-wise maximum of array elements. Compare two arrays and returns a new array containing the element-wise maxima. If one of the elements being compared is a NaN, then that element is returned. If both elements are NaNs then the first is returned. The latter distinction is important for complex NaNs, which are defined as at least one of the real or imaginary parts being a NaN. The net effect is that NaNs are propagated. Parameters x1, x2array_like The arrays holding the elements to be compared. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray or scalar The maximum of x1 and x2, element-wise. This is a scalar if both x1 and x2 are scalars. See also minimum Element-wise minimum of two arrays, propagates NaNs. fmax Element-wise maximum of two arrays, ignores NaNs. amax The maximum value of an array along a given axis, propagates NaNs. nanmax The maximum value of an array along a given axis, ignores NaNs. fmin, amin, nanmin Notes The maximum is equivalent to np.where(x1 >= x2, x1, x2) when neither x1 nor x2 are nans, but it is faster and does proper broadcasting. Examples >>> np.maximum([2, 3, 4], [1, 5, 2]) array([2, 5, 4]) >>> np.maximum(np.eye(2), [0.5, 2]) # broadcasting array([[ 1. , 2. ], [ 0.5, 2. ]]) >>> np.maximum([np.nan, 0, np.nan], [0, np.nan, np.nan]) array([nan, nan, nan]) >>> np.maximum(np.Inf, 1) inf", "score": "0.6728927"}, {"id": "42839", "text": "Function: numpy.reference.generated.numpy.floor\nSnippet: numpy.floor numpy.floor(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'floor'> Return the floor of the input, element-wise. The floor of the scalar x is the largest integer i, such that i <= x. It is often denoted as \\(\\lfloor x \\rfloor\\). Parameters xarray_like Input data. outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray or scalar The floor of each element in x. This is a scalar if x is a scalar. See also ceil, trunc, rint, fix Notes Some spreadsheet programs calculate the “floor-towards-zero”, where floor(-2.5) == -2. NumPy instead uses the definition of floor where floor(-2.5) == -3. The “floor-towards-zero” function is called fix in NumPy. Examples >>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) >>> np.floor(a) array([-2., -2., -1., 0., 1., 1., 2.])", "score": "0.65647423"}, {"id": "42123", "text": "Function: numpy.reference.generated.numpy.ma.cumsum\nSnippet: numpy.ma.cumsum ma.cumsum(self, axis=None, dtype=None, out=None) = <numpy.ma.core._frommethod object> Return the cumulative sum of the array elements over the given axis. Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations. Refer to numpy.cumsum for full documentation. See also numpy.ndarray.cumsum corresponding function for ndarrays numpy.cumsum equivalent function Notes The mask is lost if out is not a valid ma.MaskedArray ! Arithmetic is modular when using integer types, and no error is raised on overflow. Examples >>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0]) >>> marr.cumsum() masked_array(data=[0, 1, 3, --, --, --, 9, 16, 24, 33], mask=[False, False, False, True, True, True, False, False, False, False], fill_value=999999)", "score": "0.65476966"}, {"id": "42840", "text": "Function: numpy.reference.generated.numpy.floor_divide\nSnippet: numpy.floor_divide numpy.floor_divide(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'floor_divide'> Return the largest integer smaller or equal to the division of the inputs. It is equivalent to the Python // operator and pairs with the Python % (remainder), function so that a = a % b + b * (a // b) up to roundoff. Parameters x1array_like Numerator. x2array_like Denominator. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray y = floor(x1/x2) This is a scalar if both x1 and x2 are scalars. See also remainder Remainder complementary to floor_divide. divmod Simultaneous floor division and remainder. divide Standard division. floor Round a number to the nearest integer toward minus infinity. ceil Round a number to the nearest integer toward infinity. Examples >>> np.floor_divide(7,3) 2 >>> np.floor_divide([1., 2., 3., 4.], 2.5) array([ 0., 0., 1., 1.]) The // operator can be used as a shorthand for np.floor_divide on ndarrays. >>> x1 = np.array([1., 2., 3., 4.]) >>> x1 // 2.5 array([0., 0., 1., 1.])", "score": "0.6540172"}, {"id": "42260", "text": "Function: numpy.reference.generated.numpy.ma.maskedarray.cumsum\nSnippet: numpy.ma.MaskedArray.cumsum method ma.MaskedArray.cumsum(axis=None, dtype=None, out=None)[source] Return the cumulative sum of the array elements over the given axis. Masked values are set to 0 internally during the computation. However, their position is saved, and the result will be masked at the same locations. Refer to numpy.cumsum for full documentation. See also numpy.ndarray.cumsum corresponding function for ndarrays numpy.cumsum equivalent function Notes The mask is lost if out is not a valid ma.MaskedArray ! Arithmetic is modular when using integer types, and no error is raised on overflow. Examples >>> marr = np.ma.array(np.arange(10), mask=[0,0,0,1,1,1,0,0,0,0]) >>> marr.cumsum() masked_array(data=[0, 1, 3, --, --, --, 9, 16, 24, 33], mask=[False, False, False, True, True, True, False, False, False, False], fill_value=999999)", "score": "0.65279496"}]}
{"task_id": 560, "text": "Write a function to find the union of elements of the given tuples.", "code": "def union_elements(test_tup1, test_tup2):\r\n  res = tuple(set(test_tup1 + test_tup2))\r\n  return (res) ", "test_list": ["assert union_elements((3, 4, 5, 6),(5, 7, 4, 10) ) == (3, 4, 5, 6, 7, 10)", "assert union_elements((1, 2, 3, 4),(3, 4, 5, 6) ) == (1, 2, 3, 4, 5, 6)", "assert union_elements((11, 12, 13, 14),(13, 15, 16, 17) ) == (11, 12, 13, 14, 15, 16, 17)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "43258", "text": "Function: numpy.reference.generated.numpy.union1d\nSnippet: numpy.union1d numpy.union1d(ar1, ar2)[source] Find the union of two arrays. Return the unique, sorted array of values that are in either of the two input arrays. Parameters ar1, ar2array_like Input arrays. They are flattened if they are not already 1D. Returns union1dndarray Unique, sorted union of the input arrays. See also numpy.lib.arraysetops Module with a number of other functions for performing set operations on arrays. Examples >>> np.union1d([-1, 0, 1], [-2, 0, 2]) array([-2, -1, 0, 1, 2]) To find the union of more than two arrays, use functools.reduce: >>> from functools import reduce >>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2])) array([1, 2, 3, 4, 6])", "score": "0.7218908"}, {"id": "20231", "text": "Function: python.library.stdtypes#frozenset.union\nSnippet: union(*others) set | other | ... Return a new set with elements from the set and all others.", "score": "0.7143054"}, {"id": "36365", "text": "Function: django.ref.contrib.gis.functions#django.contrib.gis.db.models.functions.Union\nSnippet: class Union(expr1, expr2, **extra)", "score": "0.69489974"}, {"id": "5214", "text": "Function: tensorflow.sets.union\nSnippet: tf.sets.union View source on GitHub Compute set union of elements in last dimension of a and b. View aliases Compat aliases for migration See Migration guide for more details. tf.compat.v1.sets.set_union, tf.compat.v1.sets.union tf.sets.union( a, b, validate_indices=True ) All but the last dimension of a and b must match. Example: import tensorflow as tf import collections # [[{1, 2}, {3}], [{4}, {5, 6}]] a = collections.OrderedDict([ ((0, 0, 0), 1), ((0, 0, 1), 2), ((0, 1, 0), 3), ((1, 0, 0), 4), ((1, 1, 0), 5), ((1, 1, 1), 6), ]) a = tf.sparse.SparseTensor(list(a.keys()), list(a.values()), dense_shape=[2, 2, 2]) # [[{1, 3}, {2}], [{4, 5}, {5, 6, 7, 8}]] b = collections.OrderedDict([ ((0, 0, 0), 1), ((0, 0, 1), 3), ((0, 1, 0), 2), ((1, 0, 0), 4), ((1, 0, 1), 5), ((1, 1, 0), 5), ((1, 1, 1), 6), ((1, 1, 2), 7), ((1, 1, 3), 8), ]) b = tf.sparse.SparseTensor(list(b.keys()), list(b.values()), dense_shape=[2, 2, 4]) # `set_union` is applied to each aligned pair of sets. tf.sets.union(a, b) # The result will be a equivalent to either of: # # np.array([[{1, 2, 3}, {2, 3}], [{4, 5}, {5, 6, 7, 8}]]) # # collections.OrderedDict([ # ((0, 0, 0), 1), # ((0, 0, 1), 2), # ((0, 0, 2), 3), # ((0, 1, 0), 2), # ((0, 1, 1), 3), # ((1, 0, 0), 4), # ((1, 0, 1), 5), # ((1, 1, 0), 5), # ((1, 1, 1), 6), # ((1, 1, 2), 7), # ((1, 1, 3), 8), # ]) Args a Tensor or SparseTensor of the same type as b. If sparse, indices must be sorted in row-major order. b Tensor or SparseTensor of the same type as a. If sparse, indices must be sorted in row-major order. validate_indices Whether to validate the order and range of sparse indices in a and b. Returns A SparseTensor whose shape is the same rank as a and b, and all but the last dimension the same. Elements along the last dimension contain the unions.", "score": "0.69150484"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.6913512"}]}
{"task_id": 561, "text": "Write a function to assign with each element, its pair elements from other similar pairs in the given tuple.", "code": "def assign_elements(test_list):\r\n  res = dict()\r\n  for key, val in test_list:\r\n    res.setdefault(val, [])\r\n    res.setdefault(key, []).append(val)\r\n  return (res) ", "test_list": ["assert assign_elements([(5, 3), (7, 5), (2, 7), (3, 8), (8, 4)] ) == {3: [8], 5: [3], 7: [5], 2: [7], 8: [4], 4: []}", "assert assign_elements([(6, 4), (9, 4), (3, 8), (4, 9), (9, 5)] ) == {4: [9], 6: [4], 9: [4, 5], 8: [], 3: [8], 5: []}", "assert assign_elements([(6, 2), (6, 8), (4, 9), (4, 9), (3, 7)] ) == {2: [], 6: [2, 8], 8: [], 9: [], 4: [9, 9], 7: [], 3: [7]}"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21302", "text": "Function: python.library.itertools#itertools.combinations_with_replacement\nSnippet: itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n = len(pool) for indices in product(range(n), repeat=r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is (n+r-1)! / r! / (n-1)! when n > 0. New in version 3.1.", "score": "0.6679058"}, {"id": "25766", "text": "Function: python.library.stdtypes\nSnippet: is less than another set if and only if the first set is a proper subset of the second set (is a subset, but is not equal). A set is greater than another set if and only if the first set is a proper superset of the second set (is a superset, but is not equal). Instances of set are compared to instances of frozenset based on their members. For example, set('abc') == frozenset('abc') returns True and so does set('abc') in set([frozenset('abc')]). The subset and equality comparisons do not generalize to a total ordering function. For example, any two nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return False: a<b, a==b, or a>b. Since sets only define partial ordering (subset relationships), the output of the list.sort() method is undefined for lists of sets. Set elements, like dictionary keys, must be hashable. Binary operations that mix set instances with frozenset return the type of the first operand. For example: frozenset('ab') | set('bc') returns an instance of frozenset. The following table lists operations available for set that do not apply to immutable instances of frozenset: update(*others) set |= other | ... Update the set, adding elements from all others. intersection_update(*others) set &= other & ... Update the set, keeping only elements found in it and all others. difference_update(*others) set -= other | ... Update the set, removing elements found in others. symmetric_difference_update(other) set ^= other Update the set, keeping only elements found in either set, but not in both. add(elem) Add element elem to the set. remove(elem) Remove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem) Remove element elem from the set if it is present. pop() Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear() Remove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(), and symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To support searching for an equivalent frozenset, a temporary one is created from elem. Mapping Types — dict A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and the collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictionaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (such as 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. (Note however, that since computers store floating-point numbers as approximations it is usually unwise to use them as dictionary keys.) Dictionaries can", "score": "0.6594232"}, {"id": "19651", "text": "Function: python.library.difflib#difflib.SequenceMatcher.ratio\nSnippet: ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5", "score": "0.6574856"}, {"id": "21290", "text": "Function: python.library.itertools\nSnippet: iterables are exhausted. Used for treating consecutive sequences as a single sequence. Roughly equivalent to: def chain(*iterables): # chain('ABC', 'DEF') --> A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily. Roughly equivalent to: def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n", "score": "0.65404737"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.6521946"}]}
{"task_id": 562, "text": "Write a python function to find the maximum length of sublist.", "code": "def Find_Max_Length(lst):  \r\n    maxLength = max(len(x) for x in lst )\r\n    return maxLength ", "test_list": ["assert Find_Max_Length([[1],[1,4],[5,6,7,8]]) == 4", "assert Find_Max_Length([[0,1],[2,2,],[3,2,1]]) == 3", "assert Find_Max_Length([[7],[22,23],[13,14,15],[10,20,30,40,50]]) == 5"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18944", "text": "Function: python.library.ctypes#ctypes.Array._length_\nSnippet: _length_ A positive integer specifying the number of elements in the array. Out-of-range subscripts result in an IndexError. Will be returned by len().", "score": "0.7183503"}, {"id": "18671", "text": "Function: python.library.collections#collections.deque.maxlen\nSnippet: maxlen Maximum size of a deque or None if unbounded. New in version 3.1.", "score": "0.7049932"}, {"id": "20457", "text": "Function: python.library.hashlib#hashlib.blake2b.MAX_KEY_SIZE\nSnippet: blake2b.MAX_KEY_SIZE", "score": "0.69849616"}, {"id": "20462", "text": "Function: python.library.hashlib#hashlib.blake2s.MAX_KEY_SIZE\nSnippet: blake2s.MAX_KEY_SIZE", "score": "0.6931541"}, {"id": "21316", "text": "Function: python.library.itertools#itertools.zip_longest\nSnippet: itertools.zip_longest(*iterables, fillvalue=None) Make an iterator that aggregates elements from each of the iterables. If the iterables are of uneven length, missing values are filled-in with fillvalue. Iteration continues until the longest iterable is exhausted. Roughly equivalent to: def zip_longest(*args, fillvalue=None): # zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D- iterators = [iter(it) for it in args] num_active = len(iterators) if not num_active: return while True: values = [] for i, it in enumerate(iterators): try: value = next(it) except StopIteration: num_active -= 1 if not num_active: return iterators[i] = repeat(fillvalue) value = fillvalue values.append(value) yield tuple(values) If one of the iterables is potentially infinite, then the zip_longest() function should be wrapped with something that limits the number of calls (for example islice() or takewhile()). If not specified, fillvalue defaults to None.", "score": "0.68890405"}]}
{"task_id": 563, "text": "Write a function to extract values between quotation marks of a string.", "code": "import re\r\ndef extract_values(text):\r\n return (re.findall(r'\"(.*?)\"', text))", "test_list": ["assert extract_values('\"Python\", \"PHP\", \"Java\"')==['Python', 'PHP', 'Java']", "assert extract_values('\"python\",\"program\",\"language\"')==['python','program','language']", "assert extract_values('\"red\",\"blue\",\"green\",\"yellow\"')==['red','blue','green','yellow']"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23308", "text": "Function: python.library.re\nSnippet: the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string. re.findall(pattern, string, flags=0) Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.finditer(pattern, string, flags=0) Return an iterator yielding match objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.sub(pattern, repl, string, count=0, flags=0) Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. For example: >>> re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', ... r'static PyObject*\\npy_\\1(void)\\n{', ... 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. For example: >>> def dashrepl(matchobj): ... if matchobj.group(0) == '-': return ' ' ... else: return '-' >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' >>> re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' The pattern may be a string or a pattern object. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern", "score": "0.6744547"}, {"id": "16533", "text": "Function: pandas.reference.series\nSnippet: of strings in the Series/Index. Series.str.rpartition([sep, expand]) Split the string at the last occurrence of sep. Series.str.rstrip([to_strip]) Remove trailing characters. Series.str.slice([start, stop, step]) Slice substrings from each element in the Series or Index. Series.str.slice_replace([start, stop, repl]) Replace a positional slice of a string with another value. Series.str.split([pat, n, expand, regex]) Split strings around given separator/delimiter. Series.str.rsplit([pat, n, expand]) Split strings around given separator/delimiter. Series.str.startswith(pat[, na]) Test if the start of each string element matches a pattern. Series.str.strip([to_strip]) Remove leading and trailing characters. Series.str.swapcase() Convert strings in the Series/Index to be swapcased. Series.str.title() Convert strings in the Series/Index to titlecase. Series.str.translate(table) Map all characters in the string through the given mapping table. Series.str.upper() Convert strings in the Series/Index to uppercase. Series.str.wrap(width, **kwargs) Wrap strings in Series/Index at specified line width. Series.str.zfill(width) Pad strings in the Series/Index by prepending '0' characters. Series.str.isalnum() Check whether all characters in each string are alphanumeric. Series.str.isalpha() Check whether all characters in each string are alphabetic. Series.str.isdigit() Check whether all characters in each string are digits. Series.str.isspace() Check whether all characters in each string are whitespace. Series.str.islower() Check whether all characters in each string are lowercase. Series.str.isupper() Check whether all characters in each string are uppercase. Series.str.istitle() Check whether all characters in each string are titlecase. Series.str.isnumeric() Check whether all characters in each string are numeric. Series.str.isdecimal() Check whether all characters in each string are decimal. Series.str.get_dummies([sep]) Return DataFrame of dummy/indicator variables for Series. Categorical accessor Categorical-dtype specific methods and attributes are available under the Series.cat accessor. Series.cat.categories The categories of this categorical. Series.cat.ordered Whether the categories have an ordered relationship. Series.cat.codes Return Series of codes as well as the index. Series.cat.rename_categories(*args, **kwargs) Rename categories. Series.cat.reorder_categories(*args, **kwargs) Reorder categories as specified in new_categories. Series.cat.add_categories(*args, **kwargs) Add new categories. Series.cat.remove_categories(*args, **kwargs) Remove the specified categories. Series.cat.remove_unused_categories(*args, ...) Remove categories which are not used. Series.cat.set_categories(*args, **kwargs) Set the categories to the specified new_categories. Series.cat.as_ordered(*args, **kwargs) Set the Categorical to be ordered. Series.cat.as_unordered(*args, **kwargs) Set the Categorical to be unordered. Sparse accessor Sparse-dtype specific methods and attributes are provided under the Series.sparse accessor. Series.sparse.npoints The number of non- fill_value points. Series.sparse.density The percent of non- fill_value points, as decimal. Series.sparse.fill_value Elements in data that are fill_value are not stored. Series.sparse.sp_values An ndarray containing the non- fill_value values. Series.sparse.from_coo(A[, dense_index]) Create a Series with sparse values from a scipy.sparse.coo_matrix. Series.sparse.to_coo([row_levels, ...]) Create a scipy.sparse.coo_matrix from a Series with MultiIndex. Flags Flags refer to attributes of the pandas object. Properties of the dataset (like the date is was recorded, the URL it was accessed from, etc.) should be stored in Series.attrs. Flags(obj, *, allows_duplicate_labels) Flags that apply to pandas objects. Metadata Series.attrs is a dictionary for storing global metadata for this Series. Warning Series.attrs is considered experimental and may change without warning. Series.attrs Dictionary of global attributes of this dataset. Plotting Series.plot is both a callable method and a namespace attribute for specific plotting methods of the form Series.plot.<kind>. Series.plot([kind, ax, figsize, ....]) Series plotting accessor and method Series.plot.area([x, y]) Draw a", "score": "0.67235106"}, {"id": "23368", "text": "Function: python.library.re#re.split\nSnippet: re.split(pattern, string, maxsplit=0, flags=0) Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. >>> re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] >>> re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] >>> re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.", "score": "0.6718864"}, {"id": "25413", "text": "Function: python.library.token#token.COMMA\nSnippet: token.COMMA Token value for \",\".", "score": "0.6695237"}, {"id": "15363", "text": "Function: pandas.reference.api.pandas.series.str.rsplit\nSnippet: s.str.split(expand=True) 0 1 2 3 4 0 this is a regular sentence 1 https://docs.python.org/3/tutorial/index.html None None None None 2 NaN NaN NaN NaN NaN For slightly more complex use cases like splitting the html document name from a url, a combination of parameter settings can be used. >>> s.str.rsplit(\"/\", n=1, expand=True) 0 1 0 this is a regular sentence None 1 https://docs.python.org/3/tutorial index.html 2 NaN NaN Remember to escape special characters when explicitly using regular expressions. >>> s = pd.Series([\"foo and bar plus baz\"]) >>> s.str.split(r\"and|plus\", expand=True) 0 1 2 0 foo bar baz Regular expressions can be used to handle urls or file names. When pat is a string and regex=None (the default), the given pat is compiled as a regex only if len(pat) != 1. >>> s = pd.Series(['foojpgbar.jpg']) >>> s.str.split(r\".\", expand=True) 0 1 0 foojpgbar jpg >>> s.str.split(r\"\\.jpg\", expand=True) 0 1 0 foojpgbar When regex=True, pat is interpreted as a regex >>> s.str.split(r\"\\.jpg\", regex=True, expand=True) 0 1 0 foojpgbar A compiled regex can be passed as pat >>> import re >>> s.str.split(re.compile(r\"\\.jpg\"), expand=True) 0 1 0 foojpgbar When regex=False, pat is interpreted as the string itself >>> s.str.split(r\"\\.jpg\", regex=False, expand=True) 0 0 foojpgbar.jpg", "score": "0.66558844"}]}
{"task_id": 564, "text": "Write a python function to count unequal element pairs from the given array.", "code": "def count_Pairs(arr,n): \r\n    cnt = 0; \r\n    for i in range(n): \r\n        for j in range(i + 1,n): \r\n            if (arr[i] != arr[j]): \r\n                cnt += 1; \r\n    return cnt; ", "test_list": ["assert count_Pairs([1,2,1],3) == 2", "assert count_Pairs([1,1,1,1],4) == 0", "assert count_Pairs([1,2,3,4,5],5) == 10"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "17632", "text": "Function: python.library.array#array.array.count\nSnippet: array.count(x) Return the number of occurrences of x in the array.", "score": "0.71388143"}, {"id": "25736", "text": "Function: python.library.stdtypes\nSnippet: s.index(x[, i[, j]]) index of the first occurrence of x in s (at or after index i and before index j) (8) s.count(x) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Notes: While the in and not in operations are used only for simple containment testing in the general case, some specialised sequences (such as str, bytes and bytearray) also use them for subsequence testing: >>> \"gg\" in \"eggs\" True Values of n less than 0 are treated as 0 (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: >>> lists = [[]] * 3 >>> lists [[], [], []] >>> lists[0].append(3) >>> lists [[3], [3], [3]] What has happened is that [[]] is a one-element list containing an empty list, so all three elements of [[]] * 3 are references to this single empty list. Modifying any of the elements of lists modifies this single list. You can create a list of different lists this way: >>> lists = [[] for i in range(3)] >>> lists[0].append(3) >>> lists[1].append(5) >>> lists[2].append(7) >>> lists [[3], [5], [7]] Further explanation is available in the FAQ entry How do I create a multidimensional list?. If i or j is negative, the index is relative to the end of sequence s: len(s) + i or len(s) + j is substituted. But note that -0 is still 0. The slice of s from i to j is defined as the sequence of items with index k such that i <= k < j. If i or j is greater than len(s), use len(s). If i is omitted or None, use 0. If j is omitted or None, use len(s). If i is greater than or equal to j, the slice is empty. The slice of s from i to j with step k is defined as the sequence of items with index x = i + n*k such that 0 <= n < (j-i)/k. In other words, the indices are i, i+k, i+2*k, i+3*k and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to len(s) if they are greater. When k is negative, i and j are reduced to len(s) - 1 if they are greater. If i or j are omitted or None, they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is None, it is treated like 1. Concatenating immutable sequences always results in a new object. This means that building up", "score": "0.6910572"}, {"id": "26075", "text": "Function: python.library.unittest#unittest.TestCase.assertCountEqual\nSnippet: assertCountEqual(first, second, msg=None) Test that sequence first contains the same elements as second, regardless of their order. When they don’t, an error message listing the differences between the sequences will be generated. Duplicate elements are not ignored when comparing first and second. It verifies whether each element has the same count in both sequences. Equivalent to: assertEqual(Counter(list(first)), Counter(list(second))) but works with sequences of unhashable objects as well. New in version 3.2.", "score": "0.6886631"}, {"id": "43067", "text": "Function: numpy.reference.generated.numpy.not_equal\nSnippet: numpy.not_equal numpy.not_equal(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'not_equal'> Return (x1 != x2) element-wise. Parameters x1, x2array_like Input arrays. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns outndarray or scalar Output array, element-wise comparison of x1 and x2. Typically of type bool, unless dtype=object is passed. This is a scalar if both x1 and x2 are scalars. See also equal, greater, greater_equal, less, less_equal Examples >>> np.not_equal([1.,2.], [1., 3.]) array([False, True]) >>> np.not_equal([1, 2], [[1, 3],[1, 4]]) array([[False, True], [False, True]]) The != operator can be used as a shorthand for np.not_equal on ndarrays. >>> a = np.array([1., 2.]) >>> b = np.array([1., 3.]) >>> a != b array([False, True])", "score": "0.68550086"}, {"id": "42690", "text": "Function: numpy.reference.generated.numpy.chararray\nSnippet: sort this array. copy([order]) Return a copy of the array. count(sub[, start, end]) Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end]. decode([encoding, errors]) Calls str.decode element-wise. dump(file) Dump a pickle of the array to the specified file. dumps() Returns the pickle of the array as a string. encode([encoding, errors]) Calls str.encode element-wise. endswith(suffix[, start, end]) Returns a boolean array which is True where the string element in self ends with suffix, otherwise False. expandtabs([tabsize]) Return a copy of each string element where all tab characters are replaced by one or more spaces. fill(value) Fill the array with a scalar value. find(sub[, start, end]) For each element, return the lowest index in the string where substring sub is found. flatten([order]) Return a copy of the array collapsed into one dimension. getfield(dtype[, offset]) Returns a field of the given array as a certain type. index(sub[, start, end]) Like find, but raises ValueError when the substring is not found. isalnum() Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise. isalpha() Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise. isdecimal() For each element in self, return True if there are only decimal characters in the element. isdigit() Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise. islower() Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise. isnumeric() For each element in self, return True if there are only numeric characters in the element. isspace() Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise. istitle() Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise. isupper() Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise. item(*args) Copy an element of an array to a standard Python scalar and return it. join(seq) Return a string which is the concatenation of the strings in the sequence seq. ljust(width[, fillchar]) Return an array with the elements of self left-justified in a string of length width. lower() Return an array with the elements of self converted to lowercase. lstrip([chars]) For each element in self, return a copy with the leading characters removed. nonzero() Return the indices of the elements that are non-zero. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. replace(old, new[, count]) For each element in self, return a copy of the string with all occurrences of substring old replaced by new. reshape(shape[, order]) Returns an array containing the", "score": "0.6845266"}]}
{"task_id": 565, "text": "Write a python function to split a string into characters.", "code": "def split(word): \r\n    return [char for char in word] ", "test_list": ["assert split('python') == ['p','y','t','h','o','n']", "assert split('Name') == ['N','a','m','e']", "assert split('program') == ['p','r','o','g','r','a','m']"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "41754", "text": "Function: numpy.reference.generated.numpy.char.split\nSnippet: numpy.char.split char.split(a, sep=None, maxsplit=None)[source] For each element in a, return a list of the words in the string, using sep as the delimiter string. Calls str.split element-wise. Parameters aarray_like of str or unicode sepstr or unicode, optional If sep is not specified or None, any whitespace string is a separator. maxsplitint, optional If maxsplit is given, at most maxsplit splits are done. Returns outndarray Array of list objects See also str.split, rsplit", "score": "0.7183547"}, {"id": "24398", "text": "Function: python.library.string\nSnippet: characters are replaced by a single space and leading and trailing whitespace are removed, otherwise sep is used to split and join the words.", "score": "0.70861566"}, {"id": "24377", "text": "Function: python.library.stdtypes#str.split\nSnippet: str.split(sep=None, maxsplit=-1) Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for example, '1,,2'.split(',') returns ['1', '', '2']). The sep argument may consist of multiple characters (for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']). Splitting an empty string with a specified separator returns ['']. For example: >>> '1,2,3'.split(',') ['1', '2', '3'] >>> '1,2,3'.split(',', maxsplit=1) ['1', '2,3'] >>> '1,2,,3,'.split(',') ['1', '2', '', '3', ''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace with a None separator returns []. For example: >>> '1 2 3'.split() ['1', '2', '3'] >>> '1 2 3'.split(maxsplit=1) ['1', '2 3'] >>> ' 1 2 3 '.split() ['1', '2', '3']", "score": "0.7044214"}, {"id": "23368", "text": "Function: python.library.re#re.split\nSnippet: re.split(pattern, string, maxsplit=0, flags=0) Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. >>> re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] >>> re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] >>> re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.", "score": "0.7015742"}, {"id": "25746", "text": "Function: python.library.stdtypes\nSnippet: Return -1 on failure. str.rindex(sub[, start[, end]]) Like rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar]) Return the string right justified in a string of length width. Padding is done using the specified fillchar (default is an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep) Split the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two empty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1) Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except for splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars]) Return a copy of the string with trailing characters removed. The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped: >>> ' spacious '.rstrip() ' spacious' >>> 'mississippi'.rstrip('ipz') 'mississ' See str.removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> 'Monty Python'.rstrip(' Python') 'M' >>> 'Monty Python'.removesuffix(' Python') 'Monty' str.split(sep=None, maxsplit=-1) Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for example, '1,,2'.split(',') returns ['1', '', '2']). The sep argument may consist of multiple characters (for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']). Splitting an empty string with a specified separator returns ['']. For example: >>> '1,2,3'.split(',') ['1', '2', '3'] >>> '1,2,3'.split(',', maxsplit=1) ['1', '2,3'] >>> '1,2,,3,'.split(',') ['1', '2', '', '3', ''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace with a None separator returns []. For example: >>> '1 2 3'.split() ['1', '2', '3'] >>> '1 2 3'.split(maxsplit=1) ['1', '2 3'] >>> ' 1 2 3 '.split() ['1', '2', '3'] str.splitlines([keepends]) Return a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting list unless keepends is given and true. This", "score": "0.7011104"}]}
{"task_id": 566, "text": "Write a function to get the sum of a non-negative integer.", "code": "def sum_digits(n):\r\n  if n == 0:\r\n    return 0\r\n  else:\r\n    return n % 10 + sum_digits(int(n / 10))", "test_list": ["assert sum_digits(345)==12", "assert sum_digits(12)==3", "assert sum_digits(97)==16"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19451", "text": "Function: python.library.decimal#decimal.Context.add\nSnippet: add(x, y) Return the sum of x and y.", "score": "0.68969953"}, {"id": "21774", "text": "Function: python.library.math\nSnippet: m is a float and e is an integer such that x == m * 2**e exactly. If x is zero, returns (0.0, 0), otherwise 0.5 <= abs(m) < 1. This is used to “pick apart” the internal representation of a float in a portable way. math.fsum(iterable) Return an accurate floating point sum of values in the iterable. Avoids loss of precision by tracking multiple intermediate partial sums: >>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]) 0.9999999999999999 >>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1]) 1.0 The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the typical case where the rounding mode is half-even. On some non-Windows builds, the underlying C library uses extended precision addition and may occasionally double-round an intermediate sum causing it to be off in its least significant bit. For further discussion and two alternative approaches, see the ASPN cookbook recipes for accurate floating point summation. math.gcd(*integers) Return the greatest common divisor of the specified integer arguments. If any of the arguments is nonzero, then the returned value is the largest positive integer that is a divisor of all arguments. If all arguments are zero, then the returned value is 0. gcd() without arguments returns 0. New in version 3.5. Changed in version 3.9: Added support for an arbitrary number of arguments. Formerly, only two arguments were supported. math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0) Return True if the values a and b are close to each other and False otherwise. Whether or not two values are considered close is determined according to given absolute and relative tolerances. rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be greater than zero. abs_tol is the minimum absolute tolerance – useful for comparisons near zero. abs_tol must be at least zero. If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol). The IEEE 754 special values of NaN, inf, and -inf will be handled according to IEEE rules. Specifically, NaN is not considered close to any other value, including NaN. inf and -inf are only considered close to themselves. New in version 3.5. See also PEP 485 – A function for testing approximate equality math.isfinite(x) Return True if x is neither an infinity nor a NaN, and False otherwise. (Note that 0.0 is considered finite.) New in version 3.2. math.isinf(x) Return True if x is a positive or negative infinity, and False otherwise. math.isnan(x) Return True if x is a NaN (not a number), and False otherwise. math.isqrt(n) Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or equivalently the greatest integer a such that a² ≤ n. For", "score": "0.6840081"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6833814"}, {"id": "24549", "text": "Function: python.library.functions#sum\nSnippet: sum(iterable, /, start=0) Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument.", "score": "0.6726827"}, {"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.67118317"}]}
{"task_id": 567, "text": "Write a function to check whether a specified list is sorted or not.", "code": "def issort_list(list1):\r\n    result = all(list1[i] <= list1[i+1] for i in range(len(list1)-1))\r\n    return result", "test_list": ["assert issort_list([1,2,4,6,8,10,12,14,16,17])==True", "assert issort_list([1, 2, 4, 6, 8, 10, 12, 14, 20, 17])==False", "assert issort_list([1, 2, 4, 6, 8, 10,15,14,20])==False"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23949", "text": "Function: python.library.functions#sorted\nSnippet: sorted(iterable, *, key=None, reverse=False) Return a new sorted list from the items in iterable. Has two optional arguments which must be specified as keyword arguments. key specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). The default value is None (compare the elements directly). reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed. Use functools.cmp_to_key() to convert an old-style cmp function to a key function. The built-in sorted() function is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting HOW TO.", "score": "0.7228711"}, {"id": "21358", "text": "Function: python.library.stdtypes#list.sort\nSnippet: sort(*, key=None, reverse=False) This method sorts the list in place, using only < comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). sort() accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value. The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function. reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use sorted() to explicitly request a new sorted list instance). The sort() method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting HOW TO. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises ValueError if it can detect that the list has been mutated during a sort.", "score": "0.7186537"}, {"id": "25739", "text": "Function: python.library.stdtypes\nSnippet: a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed. This method modifies the sequence in place for economy of space when sorting a large sequence. To remind users that it operates by side effect, it does not return the sorted sequence (use sorted() to explicitly request a new sorted list instance). The sort() method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade). For sorting examples and a brief sorting tutorial, see Sorting HOW TO. CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the duration, and raises ValueError if it can detect that the list has been mutated during a sort. Tuples Tuples are immutable sequences, typically used to store collections of heterogeneous data (such as the 2-tuples produced by the enumerate() built-in). Tuples are also used for cases where an immutable sequence of homogeneous data is needed (such as allowing storage in a set or dict instance). class tuple([iterable]) Tuples may be constructed in a number of ways: Using a pair of parentheses to denote the empty tuple: () Using a trailing comma for a singleton tuple: a, or (a,) Separating items with commas: a, b, c or (a, b, c) Using the tuple() built-in: tuple() or tuple(iterable) The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, tuple('abc') returns ('a', 'b', 'c') and tuple( [1, 2, 3] ) returns (1, 2, 3). If no argument is given, the constructor creates a new empty tuple, (). Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, f(a, b, c) is a function call with three arguments, while f((a, b, c)) is a function call with a 3-tuple as the sole argument. Tuples implement all of the common sequence operations. For heterogeneous collections of data where access by name is clearer than access by index, collections.namedtuple() may be a more appropriate choice than a simple tuple object. Ranges The range type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in for loops. class range(stop) class range(start, stop[, step]) The arguments to the range constructor must be integers (either built-in int or any object that implements the __index__ special method). If the step argument is omitted, it defaults to 1. If the start argument is", "score": "0.70183134"}, {"id": "20478", "text": "Function: python.library.heapq\nSnippet: key function of one argument that is used to extract a comparison key from each input element. The default value is None (compare the elements directly). reverse is a boolean value. If set to True, then the input elements are merged as if each comparison were reversed. To achieve behavior similar to sorted(itertools.chain(*iterables), reverse=True), all iterables must be sorted from largest to smallest. Changed in version 3.5: Added the optional key and reverse parameters. heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n]. heapq.nsmallest(n, iterable, key=None) Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key)[:n]. The latter two functions perform best for smaller values of n. For larger values, it is more efficient to use the sorted() function. Also, when n==1, it is more efficient to use the built-in min() and max() functions. If repeated usage of these functions is required, consider turning the iterable into an actual heap. Basic Examples A heapsort can be implemented by pushing all values onto a heap and then popping off the smallest values one at a time: >>> def heapsort(iterable): ... h = [] ... for value in iterable: ... heappush(h, value) ... return [heappop(h) for i in range(len(h))] ... >>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0]) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] This is similar to sorted(iterable), but unlike sorted(), this implementation is not stable. Heap elements can be tuples. This is useful for assigning comparison values (such as task priorities) alongside the main record being tracked: >>> h = [] >>> heappush(h, (5, 'write code')) >>> heappush(h, (7, 'release product')) >>> heappush(h, (1, 'write spec')) >>> heappush(h, (3, 'create tests')) >>> heappop(h) (1, 'write spec') Priority Queue Implementation Notes A priority queue is common use for a heap, and it presents several implementation challenges: Sort stability: how do you get two tasks with equal priorities to be returned in the order they were originally added? Tuple comparison breaks for (priority, task) pairs if the priorities are equal and the tasks do not have a default comparison order. If the priority of a task changes, how do you move it to a new position in the heap? Or if a pending task needs to be deleted, how do you find it and remove it from the queue? A solution to the first two challenges is to store entries as 3-element list including the priority, an entry count, and the task. The entry count serves as a tie-breaker so that two tasks with the same priority are returned in the order they were", "score": "0.6908589"}, {"id": "25766", "text": "Function: python.library.stdtypes\nSnippet: is less than another set if and only if the first set is a proper subset of the second set (is a subset, but is not equal). A set is greater than another set if and only if the first set is a proper superset of the second set (is a superset, but is not equal). Instances of set are compared to instances of frozenset based on their members. For example, set('abc') == frozenset('abc') returns True and so does set('abc') in set([frozenset('abc')]). The subset and equality comparisons do not generalize to a total ordering function. For example, any two nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return False: a<b, a==b, or a>b. Since sets only define partial ordering (subset relationships), the output of the list.sort() method is undefined for lists of sets. Set elements, like dictionary keys, must be hashable. Binary operations that mix set instances with frozenset return the type of the first operand. For example: frozenset('ab') | set('bc') returns an instance of frozenset. The following table lists operations available for set that do not apply to immutable instances of frozenset: update(*others) set |= other | ... Update the set, adding elements from all others. intersection_update(*others) set &= other & ... Update the set, keeping only elements found in it and all others. difference_update(*others) set -= other | ... Update the set, removing elements found in others. symmetric_difference_update(other) set ^= other Update the set, keeping only elements found in either set, but not in both. add(elem) Add element elem to the set. remove(elem) Remove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem) Remove element elem from the set if it is present. pop() Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear() Remove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(), and symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To support searching for an equivalent frozenset, a temporary one is created from elem. Mapping Types — dict A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and the collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictionaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (such as 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. (Note however, that since computers store floating-point numbers as approximations it is usually unwise to use them as dictionary keys.) Dictionaries can", "score": "0.6868743"}]}
{"task_id": 568, "text": "Write a function to create a list of empty dictionaries.", "code": "def empty_list(length):\r\n empty_list = [{} for _ in range(length)]\r\n return empty_list", "test_list": ["assert empty_list(5)==[{},{},{},{},{}]", "assert empty_list(6)==[{},{},{},{},{},{}]", "assert empty_list(7)==[{},{},{},{},{},{},{}]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "14689", "text": "Function: pandas.reference.api.pandas.index.empty\nSnippet: pandas.Index.empty propertyIndex.empty", "score": "0.70408064"}, {"id": "18615", "text": "Function: python.library.collections\nSnippet: 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] >>> d = defaultdict(list) >>> for k, v in s: ... d[k].append(v) ... >>> sorted(d.items()) [('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] When each key is encountered for the first time, it is not already in the mapping; so an entry is automatically created using the default_factory function which returns an empty list. The list.append() operation then attaches the value to the new list. When keys are encountered again, the look-up proceeds normally (returning the list for that key) and the list.append() operation adds another value to the list. This technique is simpler and faster than an equivalent technique using dict.setdefault(): >>> d = {} >>> for k, v in s: ... d.setdefault(k, []).append(v) ... >>> sorted(d.items()) [('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] Setting the default_factory to int makes the defaultdict useful for counting (like a bag or multiset in other languages): >>> s = 'mississippi' >>> d = defaultdict(int) >>> for k in s: ... d[k] += 1 ... >>> sorted(d.items()) [('i', 4), ('m', 1), ('p', 2), ('s', 4)] When a letter is first encountered, it is missing from the mapping, so the default_factory function calls int() to supply a default count of zero. The increment operation then builds up the count for each letter. The function int() which always returns zero is just a special case of constant functions. A faster and more flexible way to create constant functions is to use a lambda function which can supply any constant value (not just zero): >>> def constant_factory(value): ... return lambda: value >>> d = defaultdict(constant_factory('<missing>')) >>> d.update(name='John', action='ran') >>> '%(name)s %(action)s to %(object)s' % d 'John ran to <missing>' Setting the default_factory to set makes the defaultdict useful for building a dictionary of sets: >>> s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)] >>> d = defaultdict(set) >>> for k, v in s: ... d[k].add(v) ... >>> sorted(d.items()) [('blue', {2, 4}), ('red', {1, 3})] namedtuple() Factory Function for Tuples with Named Fields Named tuples assign meaning to each position in a tuple and allow for more readable, self-documenting code. They can be used wherever regular tuples are used, and they add the ability to access fields by name instead of position index. collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None) Returns a new tuple subclass named typename. The new subclass is used to create tuple-like objects that have fields accessible by attribute lookup as well as being indexable and iterable. Instances of the subclass also have a helpful docstring (with typename and field_names) and a helpful __repr__() method which lists the tuple contents in a name=value format. The field_names are a sequence of strings such as ['x', 'y']. Alternatively, field_names can be a single string with each fieldname separated by whitespace and/or commas, for example 'x y' or 'x, y'. Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid identifiers consist of letters,", "score": "0.7013234"}, {"id": "8559", "text": "Function: werkzeug.datastructures.index#werkzeug.datastructures.MultiDict.update\nSnippet: update(mapping) update() extends rather than replaces existing key lists: >>> a = MultiDict({'x': 1}) >>> b = MultiDict({'x': 2, 'y': 3}) >>> a.update(b) >>> a MultiDict([('y', 3), ('x', 1), ('x', 2)]) If the value list for a key in other_dict is empty, no new values will be added to the dict and the key will not be created: >>> x = {'empty_list': []} >>> y = MultiDict() >>> y.update(x) >>> y MultiDict([])", "score": "0.6996259"}, {"id": "8539", "text": "Function: werkzeug.datastructures.index#werkzeug.datastructures.MultiDict\nSnippet: If set to False the dict returned will have lists with all the values in it. Otherwise it will only contain the first value for each key. Returns a dict update(mapping) update() extends rather than replaces existing key lists: >>> a = MultiDict({'x': 1}) >>> b = MultiDict({'x': 2, 'y': 3}) >>> a.update(b) >>> a MultiDict([('y', 3), ('x', 1), ('x', 2)]) If the value list for a key in other_dict is empty, no new values will be added to the dict and the key will not be created: >>> x = {'empty_list': []} >>> y = MultiDict() >>> y.update(x) >>> y MultiDict([]) values() Returns an iterator of the first value on every key’s value list.", "score": "0.6902759"}, {"id": "19611", "text": "Function: python.library.stdtypes#dict.clear\nSnippet: clear() Remove all items from the dictionary.", "score": "0.68554413"}]}
{"task_id": 569, "text": "Write a function to sort each sublist of strings in a given list of lists.", "code": "def sort_sublists(list1):\r\n    result = list(map(sorted,list1)) \r\n    return result", "test_list": ["assert sort_sublists([['green', 'orange'], ['black', 'white'], ['white', 'black', 'orange']])==[['green', 'orange'], ['black', 'white'], ['black', 'orange', 'white']]", "assert sort_sublists([['green', 'orange'], ['black'], ['green', 'orange'], ['white']])==[['green', 'orange'], ['black'], ['green', 'orange'], ['white']]", "assert sort_sublists([['a','b'],['d','c'],['g','h'] , ['f','e']])==[['a', 'b'], ['c', 'd'], ['g', 'h'], ['e', 'f']]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42690", "text": "Function: numpy.reference.generated.numpy.chararray\nSnippet: sort this array. copy([order]) Return a copy of the array. count(sub[, start, end]) Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end]. decode([encoding, errors]) Calls str.decode element-wise. dump(file) Dump a pickle of the array to the specified file. dumps() Returns the pickle of the array as a string. encode([encoding, errors]) Calls str.encode element-wise. endswith(suffix[, start, end]) Returns a boolean array which is True where the string element in self ends with suffix, otherwise False. expandtabs([tabsize]) Return a copy of each string element where all tab characters are replaced by one or more spaces. fill(value) Fill the array with a scalar value. find(sub[, start, end]) For each element, return the lowest index in the string where substring sub is found. flatten([order]) Return a copy of the array collapsed into one dimension. getfield(dtype[, offset]) Returns a field of the given array as a certain type. index(sub[, start, end]) Like find, but raises ValueError when the substring is not found. isalnum() Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise. isalpha() Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise. isdecimal() For each element in self, return True if there are only decimal characters in the element. isdigit() Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise. islower() Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise. isnumeric() For each element in self, return True if there are only numeric characters in the element. isspace() Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise. istitle() Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise. isupper() Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise. item(*args) Copy an element of an array to a standard Python scalar and return it. join(seq) Return a string which is the concatenation of the strings in the sequence seq. ljust(width[, fillchar]) Return an array with the elements of self left-justified in a string of length width. lower() Return an array with the elements of self converted to lowercase. lstrip([chars]) For each element in self, return a copy with the leading characters removed. nonzero() Return the indices of the elements that are non-zero. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. replace(old, new[, count]) For each element in self, return a copy of the string with all occurrences of substring old replaced by new. reshape(shape[, order]) Returns an array containing the", "score": "0.7053928"}, {"id": "42687", "text": "Function: numpy.reference.generated.numpy.char.chararray\nSnippet: sort this array. copy([order]) Return a copy of the array. count(sub[, start, end]) Returns an array with the number of non-overlapping occurrences of substring sub in the range [start, end]. decode([encoding, errors]) Calls str.decode element-wise. dump(file) Dump a pickle of the array to the specified file. dumps() Returns the pickle of the array as a string. encode([encoding, errors]) Calls str.encode element-wise. endswith(suffix[, start, end]) Returns a boolean array which is True where the string element in self ends with suffix, otherwise False. expandtabs([tabsize]) Return a copy of each string element where all tab characters are replaced by one or more spaces. fill(value) Fill the array with a scalar value. find(sub[, start, end]) For each element, return the lowest index in the string where substring sub is found. flatten([order]) Return a copy of the array collapsed into one dimension. getfield(dtype[, offset]) Returns a field of the given array as a certain type. index(sub[, start, end]) Like find, but raises ValueError when the substring is not found. isalnum() Returns true for each element if all characters in the string are alphanumeric and there is at least one character, false otherwise. isalpha() Returns true for each element if all characters in the string are alphabetic and there is at least one character, false otherwise. isdecimal() For each element in self, return True if there are only decimal characters in the element. isdigit() Returns true for each element if all characters in the string are digits and there is at least one character, false otherwise. islower() Returns true for each element if all cased characters in the string are lowercase and there is at least one cased character, false otherwise. isnumeric() For each element in self, return True if there are only numeric characters in the element. isspace() Returns true for each element if there are only whitespace characters in the string and there is at least one character, false otherwise. istitle() Returns true for each element if the element is a titlecased string and there is at least one character, false otherwise. isupper() Returns true for each element if all cased characters in the string are uppercase and there is at least one character, false otherwise. item(*args) Copy an element of an array to a standard Python scalar and return it. join(seq) Return a string which is the concatenation of the strings in the sequence seq. ljust(width[, fillchar]) Return an array with the elements of self left-justified in a string of length width. lower() Return an array with the elements of self converted to lowercase. lstrip([chars]) For each element in self, return a copy with the leading characters removed. nonzero() Return the indices of the elements that are non-zero. put(indices, values[, mode]) Set a.flat[n] = values[n] for all n in indices. ravel([order]) Return a flattened array. repeat(repeats[, axis]) Repeat elements of an array. replace(old, new[, count]) For each element in self, return a copy of the string with all occurrences of substring old replaced by new. reshape(shape[, order]) Returns an array containing the", "score": "0.6966418"}, {"id": "15305", "text": "Function: pandas.reference.api.pandas.series.sort_index\nSnippet: s = pd.Series([1, 2, 3, 4], index=['A', 'b', 'C', 'd']) >>> s.sort_index(key=lambda x : x.str.lower()) A 1 b 2 C 3 d 4 dtype: int64", "score": "0.6856837"}, {"id": "41764", "text": "Function: numpy.reference.generated.numpy.chararray.argsort\nSnippet: numpy.chararray.argsort method chararray.argsort(axis=- 1, kind=None, order=None)[source] Returns the indices that would sort this array. Refer to numpy.argsort for full documentation. See also numpy.argsort equivalent function", "score": "0.68373907"}, {"id": "41639", "text": "Function: numpy.reference.generated.numpy.char.chararray.argsort\nSnippet: numpy.char.chararray.argsort method char.chararray.argsort(axis=- 1, kind=None, order=None)[source] Returns the indices that would sort this array. Refer to numpy.argsort for full documentation. See also numpy.argsort equivalent function", "score": "0.681903"}]}
{"task_id": 570, "text": "Write a function to remove words from a given list of strings containing a character or string.", "code": "def remove_words(list1, charlist):\r\n    new_list = []\r\n    for line in list1:\r\n        new_words = ' '.join([word for word in line.split() if not any([phrase in word for phrase in charlist])])\r\n        new_list.append(new_words)\r\n    return new_list", "test_list": ["assert remove_words(['Red color', 'Orange#', 'Green', 'Orange @', \"White\"],['#', 'color', '@'])==['Red', '', 'Green', 'Orange', 'White']", "assert remove_words(['Red &', 'Orange+', 'Green', 'Orange @', 'White'],['&', '+', '@'])==['Red', '', 'Green', 'Orange', 'White']", "assert remove_words(['Red &', 'Orange+', 'Green', 'Orange @', 'White'],['@'])==['Red &', 'Orange+', 'Green', 'Orange', 'White']"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "24376", "text": "Function: python.library.stdtypes#str.rstrip\nSnippet: str.rstrip([chars]) Return a copy of the string with trailing characters removed. The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped: >>> ' spacious '.rstrip() ' spacious' >>> 'mississippi'.rstrip('ipz') 'mississ' See str.removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> 'Monty Python'.rstrip(' Python') 'M' >>> 'Monty Python'.removesuffix(' Python') 'Monty'", "score": "0.69672567"}, {"id": "23308", "text": "Function: python.library.re\nSnippet: the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string. re.findall(pattern, string, flags=0) Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.finditer(pattern, string, flags=0) Return an iterator yielding match objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.sub(pattern, repl, string, count=0, flags=0) Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. For example: >>> re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', ... r'static PyObject*\\npy_\\1(void)\\n{', ... 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. For example: >>> def dashrepl(matchobj): ... if matchobj.group(0) == '-': return ' ' ... else: return '-' >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' >>> re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' The pattern may be a string or a pattern object. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern", "score": "0.68737847"}, {"id": "24398", "text": "Function: python.library.string\nSnippet: characters are replaced by a single space and leading and trailing whitespace are removed, otherwise sep is used to split and join the words.", "score": "0.6828176"}, {"id": "25746", "text": "Function: python.library.stdtypes\nSnippet: Return -1 on failure. str.rindex(sub[, start[, end]]) Like rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar]) Return the string right justified in a string of length width. Padding is done using the specified fillchar (default is an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep) Split the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the separator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two empty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1) Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except for splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars]) Return a copy of the string with trailing characters removed. The chars argument is a string specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The chars argument is not a suffix; rather, all combinations of its values are stripped: >>> ' spacious '.rstrip() ' spacious' >>> 'mississippi'.rstrip('ipz') 'mississ' See str.removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> 'Monty Python'.rstrip(' Python') 'M' >>> 'Monty Python'.removesuffix(' Python') 'Monty' str.split(sep=None, maxsplit=-1) Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for example, '1,,2'.split(',') returns ['1', '', '2']). The sep argument may consist of multiple characters (for example, '1<>2<>3'.split('<>') returns ['1', '2', '3']). Splitting an empty string with a specified separator returns ['']. For example: >>> '1,2,3'.split(',') ['1', '2', '3'] >>> '1,2,3'.split(',', maxsplit=1) ['1', '2,3'] >>> '1,2,,3,'.split(',') ['1', '2', '', '3', ''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the string has leading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace with a None separator returns []. For example: >>> '1 2 3'.split() ['1', '2', '3'] >>> '1 2 3'.split(maxsplit=1) ['1', '2 3'] >>> ' 1 2 3 '.split() ['1', '2', '3'] str.splitlines([keepends]) Return a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting list unless keepends is given and true. This", "score": "0.67614615"}, {"id": "25756", "text": "Function: python.library.stdtypes\nSnippet: binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example: >>> b'Monty Python'.rstrip(b' Python') b'M' >>> b'Monty Python'.removesuffix(b' Python') b'Monty' Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. bytes.split(sep=None, maxsplit=-1) bytearray.split(sep=None, maxsplit=-1) Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object. For example: >>> b'1,2,3'.split(b',') [b'1', b'2', b'3'] >>> b'1,2,3'.split(b',', maxsplit=1) [b'1', b'2,3'] >>> b'1,2,,3,'.split(b',') [b'1', b'2', b'', b'3', b''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns []. For example: >>> b'1 2 3'.split() [b'1', b'2', b'3'] >>> b'1 2 3'.split(maxsplit=1) [b'1', b'2 3'] >>> b' 1 2 3 '.split() [b'1', b'2', b'3'] bytes.strip([chars]) bytearray.strip([chars]) Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a binary sequence specifying the set of byte values to be removed - the name refers to the fact this method is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped: >>> b' spacious '.strip() b'spacious' >>> b'www.example.com'.strip(b'cmowz.') b'example' The binary sequence of byte values to remove may be any bytes-like object. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made. The following methods on bytes and bytearray objects assume the use of ASCII compatible binary formats and should not be applied to arbitrary binary data. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects. bytes.capitalize() bytearray.capitalize() Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized and the rest", "score": "0.667563"}]}
{"task_id": 571, "text": "Write a function to find maximum possible sum of disjoint pairs for the given array of integers and a number k.", "code": "def max_sum_pair_diff_lessthan_K(arr, N, K): \r\n\tarr.sort() \r\n\tdp = [0] * N \r\n\tdp[0] = 0\r\n\tfor i in range(1, N): \r\n\t\tdp[i] = dp[i-1] \r\n\t\tif (arr[i] - arr[i-1] < K): \r\n\t\t\tif (i >= 2): \r\n\t\t\t\tdp[i] = max(dp[i], dp[i-2] + arr[i] + arr[i-1]); \r\n\t\t\telse: \r\n\t\t\t\tdp[i] = max(dp[i], arr[i] + arr[i-1]); \r\n\treturn dp[N - 1]", "test_list": ["assert max_sum_pair_diff_lessthan_K([3, 5, 10, 15, 17, 12, 9], 7, 4) == 62", "assert max_sum_pair_diff_lessthan_K([5, 15, 10, 300], 4, 12) == 25", "assert max_sum_pair_diff_lessthan_K([1, 2, 3, 4, 5, 6], 6, 6) == 21"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.63849"}, {"id": "19646", "text": "Function: python.library.difflib#difflib.SequenceMatcher.find_longest_match\nSnippet: find_longest_match(alo=0, ahi=None, blo=0, bhi=None) Find longest matching block in a[alo:ahi] and b[blo:bhi]. If isjunk was omitted or None, find_longest_match() returns (i, j, k) such that a[i:i+k] is equal to b[j:j+k], where alo <= i <= i+k <= ahi and blo <= j <= j+k <= bhi. For all (i', j', k') meeting those conditions, the additional conditions k >= k', i <= i', and if i == i', j <= j' are also met. In other words, of all maximal matching blocks, return one that starts earliest in a, and of all those maximal matching blocks that start earliest in a, return the one that starts earliest in b. >>> s = SequenceMatcher(None, \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=0, b=4, size=5) If isjunk was provided, first the longest matching block is determined as above, but with the additional restriction that no junk element appears in the block. Then that block is extended as far as possible by matching (only) junk elements on both sides. So the resulting block never matches on junk except as identical junk happens to be adjacent to an interesting match. Here’s the same example as before, but considering blanks to be junk. That prevents ' abcd' from matching the ' abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence: >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=1, b=0, size=4) If no blocks match, this returns (alo, blo, 0). This method returns a named tuple Match(a, b, size). Changed in version 3.9: Added default arguments.", "score": "0.63709414"}, {"id": "21290", "text": "Function: python.library.itertools\nSnippet: iterables are exhausted. Used for treating consecutive sequences as a single sequence. Roughly equivalent to: def chain(*iterables): # chain('ABC', 'DEF') --> A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily. Roughly equivalent to: def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n", "score": "0.6339107"}, {"id": "12719", "text": "Function: sklearn.modules.generated.sklearn.metrics.pairwise_distances_chunked\nSnippet: neigh, avg_dist >>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func) >>> neigh, avg_dist = next(gen) >>> neigh [array([0, 3]), array([1]), array([2]), array([0, 3]), array([4])] >>> avg_dist array([0.039..., 0. , 0. , 0.039..., 0. ]) Where r is defined per sample, we need to make use of start: >>> r = [.2, .4, .4, .3, .1] >>> def reduce_func(D_chunk, start): ... neigh = [np.flatnonzero(d < r[i]) ... for i, d in enumerate(D_chunk, start)] ... return neigh >>> neigh = next(pairwise_distances_chunked(X, reduce_func=reduce_func)) >>> neigh [array([0, 3]), array([0, 1]), array([2]), array([0, 3]), array([4])] Force row-by-row generation by reducing working_memory: >>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func, ... working_memory=0) >>> next(gen) [array([0, 3])] >>> next(gen) [array([0, 1])]", "score": "0.6309427"}, {"id": "21823", "text": "Function: python.library.math#math.perm\nSnippet: math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8.", "score": "0.6301332"}]}
{"task_id": 572, "text": "Write a python function to remove two duplicate numbers from a given number of lists.", "code": "def two_unique_nums(nums):\r\n  return [i for i in nums if nums.count(i)==1]", "test_list": ["assert two_unique_nums([1,2,3,2,3,4,5]) == [1, 4, 5]", "assert two_unique_nums([1,2,3,2,4,5]) == [1, 3, 4, 5]", "assert two_unique_nums([1,2,3,4,5]) == [1, 2, 3, 4, 5]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42960", "text": "Function: numpy.user.basics.rec#numpy.lib.recfunctions.find_duplicates\nSnippet: numpy.lib.recfunctions.find_duplicates(a, key=None, ignoremask=True, return_index=False)[source] Find the duplicates in a structured array along a given key Parameters aarray-like Input array key{string, None}, optional Name of the fields along which to check the duplicates. If None, the search is performed by records ignoremask{True, False}, optional Whether masked data should be discarded or considered as duplicates. return_index{False, True}, optional Whether to return the indices of the duplicated values. Examples >>> from numpy.lib import recfunctions as rfn >>> ndtype = [('a', int)] >>> a = np.ma.array([1, 1, 1, 2, 2, 3, 3], ... mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype) >>> rfn.find_duplicates(a, ignoremask=True, return_index=True) (masked_array(data=[(1,), (1,), (2,), (2,)], mask=[(False,), (False,), (False,), (False,)], fill_value=(999999,), dtype=[('a', '<i8')]), array([0, 1, 3, 4]))", "score": "0.718468"}, {"id": "17642", "text": "Function: python.library.array#array.array.remove\nSnippet: array.remove(x) Remove the first occurrence of x from the array.", "score": "0.6702922"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.6662189"}, {"id": "21310", "text": "Function: python.library.itertools#itertools.permutations\nSnippet: itertools.permutations(iterable, r=None) Return successive r length permutations of elements in the iterable. If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.6630063"}, {"id": "25738", "text": "Function: python.library.stdtypes\nSnippet: from s (2) s.remove(x) remove the first item from s where s[i] is equal to x (3) s.reverse() reverses the items of s in place (4) Notes: t must have the same length as the slice it is replacing. The optional argument i defaults to -1, so that by default the last item is removed and returned. remove() raises ValueError when x is not found in s. The reverse() method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence. clear() and copy() are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as dict and set). copy() is not part of the collections.abc.MutableSequence ABC, but most concrete mutable sequence classes provide it. New in version 3.3: clear() and copy() methods. The value n is an integer, or an object implementing __index__(). Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for s * n under Common Sequence Operations. Lists Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). class list([iterable]) Lists may be constructed in several ways: Using a pair of square brackets to denote the empty list: [] Using square brackets, separating items with commas: [a], [a, b, c] Using a list comprehension: [x for x in iterable] Using the type constructor: list() or list(iterable) The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to iterable[:]. For example, list('abc') returns ['a', 'b', 'c'] and list( (1, 2, 3) ) returns [1, 2, 3]. If no argument is given, the constructor creates a new empty list, []. Many other operations also produce lists, including the sorted() built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: sort(*, key=None, reverse=False) This method sorts the list in place, using only < comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). sort() accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value. The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function. reverse is", "score": "0.6617149"}]}
{"task_id": 573, "text": "Write a python function to calculate the product of the unique numbers of a given list.", "code": "def unique_product(list_data):\r\n    temp = list(set(list_data))\r\n    p = 1\r\n    for i in temp:\r\n        p *= i\r\n    return p", "test_list": ["assert unique_product([10, 20, 30, 40, 20, 50, 60, 40]) ==  720000000", "assert unique_product([1, 2, 3, 1,]) == 6", "assert unique_product([7, 8, 9, 0, 1, 1]) == 0"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21826", "text": "Function: python.library.math#math.prod\nSnippet: math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8.", "score": "0.7009449"}, {"id": "21311", "text": "Function: python.library.itertools#itertools.product\nSnippet: itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs.", "score": "0.6996006"}, {"id": "43260", "text": "Function: numpy.reference.generated.numpy.unique\nSnippet: the unique values: >>> a = np.array(['a', 'b', 'b', 'c', 'a']) >>> u, indices = np.unique(a, return_index=True) >>> u array(['a', 'b', 'c'], dtype='<U1') >>> indices array([0, 1, 3]) >>> a[indices] array(['a', 'b', 'c'], dtype='<U1') Reconstruct the input array from the unique values and inverse: >>> a = np.array([1, 2, 6, 4, 2, 3, 2]) >>> u, indices = np.unique(a, return_inverse=True) >>> u array([1, 2, 3, 4, 6]) >>> indices array([0, 1, 4, 3, 1, 2, 1]) >>> u[indices] array([1, 2, 6, 4, 2, 3, 2]) Reconstruct the input values from the unique values and counts: >>> a = np.array([1, 2, 6, 4, 2, 3, 2]) >>> values, counts = np.unique(a, return_counts=True) >>> values array([1, 2, 3, 4, 6]) >>> counts array([1, 3, 1, 1, 1]) >>> np.repeat(values, counts) array([1, 2, 2, 2, 3, 4, 6]) # original order not preserved", "score": "0.6963531"}, {"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.6919449"}, {"id": "21310", "text": "Function: python.library.itertools#itertools.permutations\nSnippet: itertools.permutations(iterable, r=None) Return successive r length permutations of elements in the iterable. If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.68555623"}]}
{"task_id": 574, "text": "Write a function to find the surface area of a cylinder.", "code": "def surfacearea_cylinder(r,h):\r\n  surfacearea=((2*3.1415*r*r) +(2*3.1415*r*h))\r\n  return surfacearea", "test_list": ["assert surfacearea_cylinder(10,5)==942.45", "assert surfacearea_cylinder(4,5)==226.18800000000002", "assert surfacearea_cylinder(4,10)==351.848"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "33487", "text": "Function: matplotlib._as_gen.matplotlib.quiver.barbs#matplotlib.quiver.Barbs.barbs_doc\nSnippet: barbs_doc='\\nPlot a 2D field of barbs.\\n\\nCall signature::\\n\\n barbs([X, Y], U, V, [C], **kw)\\n\\nWhere *X*, *Y* define the barb locations, *U*, *V* define the barb\\ndirections, and *C* optionally sets the color.\\n\\nAll arguments may be 1D or 2D. *U*, *V*, *C* may be masked arrays, but masked\\n*X*, *Y* are not supported at present.\\n\\nBarbs are traditionally used in meteorology as a way to plot the speed\\nand direction of wind observations, but can technically be used to\\nplot any two dimensional vector quantity. As opposed to arrows, which\\ngive vector magnitude by the length of the arrow, the barbs give more\\nquantitative information about the vector magnitude by putting slanted\\nlines or a triangle for various increments in magnitude, as show\\nschematically below::\\n\\n : /\\\\ \\\\\\n : / \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : / \\\\ \\\\ \\\\\\n : ------------------------------\\n\\nThe largest increment is given by a triangle (or \"flag\"). After those\\ncome full lines (barbs). The smallest increment is a half line. There\\nis only, of course, ever at most 1 half line. If the magnitude is\\nsmall and only needs a single half-line and no full lines or\\ntriangles, the half-line is offset from the end of the barb so that it\\ncan be easily distinguished from barbs with a single full line. The\\nmagnitude for the barb shown above would nominally be 65, using the\\nstandard increments of 50, 10, and 5.\\n\\nSee also https://en.wikipedia.org/wiki/Wind_barb.\\n\\nParameters\\n----------\\nX, Y : 1D or 2D array-like, optional\\n The x and y coordinates of the barb locations. See *pivot* for how the\\n barbs are drawn to the x, y positions.\\n\\n If not given, they will be generated as a uniform integer meshgrid based\\n on the dimensions of *U* and *V*.\\n\\n If *X* and *Y* are 1D but *U*, *V* are 2D, *X*, *Y* are expanded to 2D\\n using ``X, Y = np.meshgrid(X, Y)``. In this case ``len(X)`` and ``len(Y)``\\n must match the column and row dimensions of *U* and *V*.\\n\\nU, V : 1D or 2D array-like\\n The x and y components of the barb shaft.\\n\\nC : 1D or 2D array-like, optional\\n Numeric data that defines the barb colors by colormapping via *norm* and\\n *cmap*.\\n\\n This does not support explicit colors. If you want to set colors directly,\\n use *barbcolor* instead.\\n\\nlength : float, default: 7\\n Length of the barb in points; the other parts of the barb\\n are scaled against this.\\n\\npivot : {\\'tip\\', \\'middle\\'} or float, default: \\'tip\\'\\n The part of the arrow that is anchored to the *X*, *Y* grid. The barb\\n rotates about this point. This can also be a number, which shifts the\\n start of the barb that many points away from grid point.\\n\\nbarbcolor : color or color sequence\\n The color of all parts of the barb except for the flags. This parameter\\n is analogous to the *edgecolor* parameter for polygons, which can be used\\n instead. However this parameter will override facecolor.\\n\\nflagcolor : color or color sequence\\n The color of any flags on the barb. This parameter is analogous to the\\n *facecolor* parameter for polygons, which can be used instead. However,\\n this parameter will override facecolor. If", "score": "0.65540737"}, {"id": "17024", "text": "Function: skimage.api.skimage.measure#skimage.measure.mesh_surface_area\nSnippet: skimage.measure.mesh_surface_area(verts, faces) [source] Compute surface area, given vertices & triangular faces Parameters verts(V, 3) array of floats Array containing (x, y, z) coordinates for V unique mesh vertices. faces(F, 3) array of ints List of length-3 lists of integers, referencing vertex coordinates as provided in verts Returns areafloat Surface area of mesh. Units now [coordinate units] ** 2. See also skimage.measure.marching_cubes skimage.measure.marching_cubes_classic Notes The arguments expected by this function are the first two outputs from skimage.measure.marching_cubes. For unit correct output, ensure correct spacing was passed to skimage.measure.marching_cubes. This algorithm works properly only if the faces provided are all triangles.", "score": "0.648706"}, {"id": "25627", "text": "Function: python.library.turtle#turtle.dot\nSnippet: turtle.dot(size=None, *color) Parameters size – an integer >= 1 (if given) color – a colorstring or a numeric color tuple Draw a circular dot with diameter size, using color. If size is not given, the maximum of pensize+4 and 2*pensize is used. >>> turtle.home() >>> turtle.dot() >>> turtle.fd(50); turtle.dot(20, \"blue\"); turtle.fd(50) >>> turtle.position() (100.00,-0.00) >>> turtle.heading() 0.0", "score": "0.64419055"}, {"id": "13179", "text": "Function: pygame.ref.draw\nSnippet: the given surface. The line has a thickness of one pixel and the endpoints have a height and width of one pixel each. The way a line and it's endpoints are drawn: If both endpoints are equal, only a single pixel is drawn (after rounding floats to nearest integer). Otherwise if the line is not steep (i.e. if the length along the x-axis is greater than the height along the y-axis): For each endpoint: If x, the endpoint's x-coordinate, is a whole number find which pixels would be covered by it and draw them. Otherwise: Calculate the position of the nearest point with a whole number for it's x-coordinate, when extending the line past the endpoint. Find which pixels would be covered and how much by that point. If the endpoint is the left one, multiply the coverage by (1 - the decimal part of x). Otherwise multiply the coverage by the decimal part of x. Then draw those pixels. e.g.: The left endpoint of the line ((1, 1.3), (5, 3)) would cover 70% of the pixel (1, 1) and 30% of the pixel (1, 2) while the right one would cover 100% of the pixel (5, 3). The left endpoint of the line ((1.2, 1.4), (4.6, 3.1)) would cover 56% (i.e. 0.8 * 70%) of the pixel (1, 1) and 24% (i.e. 0.8 * 30%) of the pixel (1, 2) while the right one would cover 42% (i.e. 0.6 * 70%) of the pixel (5, 3) and 18% (i.e. 0.6 * 30%) of the pixel (5, 4) while the right Then for each point between the endpoints, along the line, whose x-coordinate is a whole number: Find which pixels would be covered and how much by that point and draw them. e.g.: The points along the line ((1, 1), (4, 2.5)) would be (2, 1.5) and (3, 2) and would cover 50% of the pixel (2, 1), 50% of the pixel (2, 2) and 100% of the pixel (3, 2). The points along the line ((1.2, 1.4), (4.6, 3.1)) would be (2, 1.8) (covering 20% of the pixel (2, 1) and 80% of the pixel (2, 2)), (3, 2.3) (covering 70% of the pixel (3, 2) and 30% of the pixel (3, 3)) and (4, 2.8) (covering 20% of the pixel (2, 1) and 80% of the pixel (2, 2)) Otherwise do the same for steep lines as for non-steep lines except along the y-axis instead of the x-axis (using y instead of x, top instead of left and bottom instead of right). Note Regarding float values for coordinates, a point with coordinate consisting of two whole numbers is considered being right in the center of said pixel (and having a height and width of 1 pixel would therefore completely cover it), while a point with coordinate where one (or both) of the numbers have non-zero decimal parts would be partially covering two (or four if both numbers have decimal parts) adjacent pixels, e.g. the point (1.4, 2) covers", "score": "0.63825715"}, {"id": "16631", "text": "Function: skimage.api.skimage.draw\nSnippet: ellipsoid_stats skimage.draw.ellipsoid_stats(a, b, c) [source] Calculates analytical surface area and volume for ellipsoid with semimajor axes aligned with grid dimensions of specified spacing. Parameters afloat Length of semimajor axis aligned with x-axis. bfloat Length of semimajor axis aligned with y-axis. cfloat Length of semimajor axis aligned with z-axis. Returns volfloat Calculated volume of ellipsoid. surffloat Calculated surface area of ellipsoid. line skimage.draw.line(r0, c0, r1, c1) [source] Generate line pixel coordinates. Parameters r0, c0int Starting position (row, column). r1, c1int End position (row, column). Returns rr, cc(N,) ndarray of int Indices of pixels that belong to the line. May be used to directly index into an array, e.g. img[rr, cc] = 1. Notes Anti-aliased line generator is available with line_aa. Examples >>> from skimage.draw import line >>> img = np.zeros((10, 10), dtype=np.uint8) >>> rr, cc = line(1, 1, 8, 8) >>> img[rr, cc] = 1 >>> img array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8) line_aa skimage.draw.line_aa(r0, c0, r1, c1) [source] Generate anti-aliased line pixel coordinates. Parameters r0, c0int Starting position (row, column). r1, c1int End position (row, column). Returns rr, cc, val(N,) ndarray (int, int, float) Indices of pixels (rr, cc) and intensity values (val). img[rr, cc] = val. References 1 A Rasterizing Algorithm for Drawing Curves, A. Zingl, 2012 http://members.chello.at/easyfilter/Bresenham.pdf Examples >>> from skimage.draw import line_aa >>> img = np.zeros((10, 10), dtype=np.uint8) >>> rr, cc, val = line_aa(1, 1, 8, 8) >>> img[rr, cc] = val * 255 >>> img array([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 255, 74, 0, 0, 0, 0, 0, 0, 0], [ 0, 74, 255, 74, 0, 0, 0, 0, 0, 0], [ 0, 0, 74, 255, 74, 0, 0, 0, 0, 0], [ 0, 0, 0, 74, 255, 74, 0, 0, 0, 0], [ 0, 0, 0, 0, 74, 255, 74, 0, 0, 0], [ 0, 0, 0, 0, 0, 74, 255, 74, 0, 0], [ 0, 0, 0, 0, 0, 0, 74, 255, 74, 0], [ 0, 0, 0, 0, 0, 0, 0, 74, 255, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8) line_nd skimage.draw.line_nd(start, stop, *, endpoint=False, integer=True) [source] Draw a single-pixel thick line in n dimensions. The line produced will be ndim-connected. That is, two subsequent pixels in the line will be either direct or diagonal neighbours in n dimensions. Parameters startarray-like, shape (N,) The start coordinates of the line. stoparray-like, shape (N,) The end coordinates", "score": "0.6366138"}]}
{"task_id": 575, "text": "Write a python function to find nth number in a sequence which is not a multiple of a given number.", "code": "def count_no (A,N,L,R): \r\n    count = 0\r\n    for i in range (L,R + 1): \r\n        if (i % A != 0): \r\n            count += 1\r\n        if (count == N): \r\n            break\r\n    return (i) ", "test_list": ["assert count_no(2,3,1,10) == 5", "assert count_no(3,6,4,20) == 11", "assert count_no(5,10,4,20) == 16"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.7034973"}, {"id": "21297", "text": "Function: python.library.itertools\nSnippet: * (n - k + i) // i if index < 0: index += c if index < 0 or index >= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index >= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)", "score": "0.69690555"}, {"id": "42785", "text": "Function: numpy.reference.distutils.misc_util#numpy.distutils.misc_util.is_sequence\nSnippet: numpy.distutils.misc_util.is_sequence(seq)[source]", "score": "0.693024"}, {"id": "19644", "text": "Function: python.library.difflib#difflib.SequenceMatcher\nSnippet: abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence: >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=1, b=0, size=4) If no blocks match, this returns (alo, blo, 0). This method returns a named tuple Match(a, b, size). Changed in version 3.9: Added default arguments. get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution:", "score": "0.6904703"}, {"id": "19648", "text": "Function: python.library.difflib#difflib.SequenceMatcher.get_matching_blocks\nSnippet: get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]", "score": "0.68829596"}]}
{"task_id": 576, "text": "Write a python function to check whether an array is subarray of another or not.", "code": "def is_Sub_Array(A,B,n,m): \r\n    i = 0; j = 0; \r\n    while (i < n and j < m):  \r\n        if (A[i] == B[j]): \r\n            i += 1; \r\n            j += 1; \r\n            if (j == m): \r\n                return True;  \r\n        else: \r\n            i = i - j + 1; \r\n            j = 0;       \r\n    return False; ", "test_list": ["assert is_Sub_Array([1,4,3,5],[1,2],4,2) == False", "assert is_Sub_Array([1,2,1],[1,2,1],3,3) == True", "assert is_Sub_Array([1,0,2,2],[2,2,0],4,3) ==False"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42206", "text": "Function: numpy.reference.generated.numpy.ma.maskedarray.__isub__\nSnippet: numpy.ma.MaskedArray.__isub__ method ma.MaskedArray.__isub__(other)[source] Subtract other from self in-place.", "score": "0.7384145"}, {"id": "20225", "text": "Function: python.library.stdtypes#frozenset.issubset\nSnippet: issubset(other) set <= other Test whether every element in the set is in other.", "score": "0.72327346"}, {"id": "42474", "text": "Function: numpy.reference.generated.numpy.ndarray.__isub__\nSnippet: numpy.ndarray.__isub__ method ndarray.__isub__(value, /) Return self-=value.", "score": "0.71923006"}, {"id": "42928", "text": "Function: numpy.reference.generated.numpy.issubdtype\nSnippet: numpy.issubdtype numpy.issubdtype(arg1, arg2)[source] Returns True if first argument is a typecode lower/equal in type hierarchy. This is like the builtin issubclass, but for dtypes. Parameters arg1, arg2dtype_like dtype or object coercible to one Returns outbool See also Scalars Overview of the numpy type hierarchy. issubsctype, issubclass_ Examples issubdtype can be used to check the type of arrays: >>> ints = np.array([1, 2, 3], dtype=np.int32) >>> np.issubdtype(ints.dtype, np.integer) True >>> np.issubdtype(ints.dtype, np.floating) False >>> floats = np.array([1, 2, 3], dtype=np.float32) >>> np.issubdtype(floats.dtype, np.integer) False >>> np.issubdtype(floats.dtype, np.floating) True Similar types of different sizes are not subdtypes of each other: >>> np.issubdtype(np.float64, np.float32) False >>> np.issubdtype(np.float32, np.float64) False but both are subtypes of floating: >>> np.issubdtype(np.float64, np.floating) True >>> np.issubdtype(np.float32, np.floating) True For convenience, dtype-like objects are allowed too: >>> np.issubdtype('S1', np.string_) True >>> np.issubdtype('i4', np.signedinteger) True", "score": "0.7033496"}, {"id": "42927", "text": "Function: numpy.reference.generated.numpy.issubclass_\nSnippet: numpy.issubclass_ numpy.issubclass_(arg1, arg2)[source] Determine if a class is a subclass of a second class. issubclass_ is equivalent to the Python built-in issubclass, except that it returns False instead of raising a TypeError if one of the arguments is not a class. Parameters arg1class Input class. True is returned if arg1 is a subclass of arg2. arg2class or tuple of classes. Input class. If a tuple of classes, True is returned if arg1 is a subclass of any of the tuple elements. Returns outbool Whether arg1 is a subclass of arg2 or not. See also issubsctype, issubdtype, issctype Examples >>> np.issubclass_(np.int32, int) False >>> np.issubclass_(np.int32, float) False >>> np.issubclass_(np.float64, float) True", "score": "0.69935524"}]}
{"task_id": 577, "text": "Write a python function to find the last digit in factorial of a given number.", "code": "def last_Digit_Factorial(n): \r\n    if (n == 0): return 1\r\n    elif (n <= 2): return n  \r\n    elif (n == 3): return 6\r\n    elif (n == 4): return 4 \r\n    else: \r\n      return 0", "test_list": ["assert last_Digit_Factorial(4) == 4", "assert last_Digit_Factorial(21) == 0", "assert last_Digit_Factorial(30) == 0"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21799", "text": "Function: python.library.math#math.factorial\nSnippet: math.factorial(x) Return x factorial as an integer. Raises ValueError if x is not integral or is negative. Deprecated since version 3.9: Accepting floats with integral values (like 5.0) is deprecated.", "score": "0.71929586"}, {"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6900576"}, {"id": "20209", "text": "Function: python.library.fractions#fractions.Fraction.numerator\nSnippet: numerator Numerator of the Fraction in lowest term.", "score": "0.6689516"}, {"id": "20203", "text": "Function: python.library.fractions#fractions.Fraction\nSnippet: a given floating-point number: >>> from fractions import Fraction >>> Fraction('3.1415926535897932').limit_denominator(1000) Fraction(355, 113) or for recovering a rational number that’s represented as a float: >>> from math import pi, cos >>> Fraction(cos(pi/3)) Fraction(4503599627370497, 9007199254740992) >>> Fraction(cos(pi/3)).limit_denominator() Fraction(1, 2) >>> Fraction(1.1).limit_denominator() Fraction(11, 10) __floor__() Returns the greatest int <= self. This method can also be accessed through the math.floor() function: >>> from math import floor >>> floor(Fraction(355, 113)) 3 __ceil__() Returns the least int >= self. This method can also be accessed through the math.ceil() function. __round__() __round__(ndigits) The first version returns the nearest int to self, rounding half to even. The second version rounds self to the nearest multiple of Fraction(1, 10**ndigits) (logically, if ndigits is negative), again rounding half toward even. This method can also be accessed through the round() function.", "score": "0.66672957"}, {"id": "21828", "text": "Function: python.library.math#math.remainder\nSnippet: math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7.", "score": "0.66560876"}]}
{"task_id": 578, "text": "Write a function to interleave lists of the same length.", "code": "def interleave_lists(list1,list2,list3):\r\n    result = [el for pair in zip(list1, list2, list3) for el in pair]\r\n    return result", "test_list": ["assert interleave_lists([1,2,3,4,5,6,7],[10,20,30,40,50,60,70],[100,200,300,400,500,600,700])==[1, 10, 100, 2, 20, 200, 3, 30, 300, 4, 40, 400, 5, 50, 500, 6, 60, 600, 7, 70, 700]", "assert interleave_lists([10,20],[15,2],[5,10])==[10,15,5,20,2,10]", "assert interleave_lists([11,44], [10,15], [20,5])==[11,10,20,44,15,5]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "8065", "text": "Function: torch.tensors#torch.Tensor.repeat_interleave\nSnippet: repeat_interleave(repeats, dim=None) → Tensor See torch.repeat_interleave().", "score": "0.69724995"}, {"id": "21290", "text": "Function: python.library.itertools\nSnippet: iterables are exhausted. Used for treating consecutive sequences as a single sequence. Roughly equivalent to: def chain(*iterables): # chain('ABC', 'DEF') --> A B C D E F for it in iterables: for element in it: yield element classmethod chain.from_iterable(iterable) Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily. Roughly equivalent to: def from_iterable(iterables): # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F for it in iterables: for element in it: yield element itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n", "score": "0.6871746"}, {"id": "25737", "text": "Function: python.library.stdtypes\nSnippet: a sequence by repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime cost, you must switch to one of the alternatives below: if concatenating str objects, you can build a list and use str.join() at the end or else write to an io.StringIO instance and retrieve its value when complete if concatenating bytes objects, you can similarly use bytes.join() or io.BytesIO, or you can do in-place concatenation with a bytearray object. bytearray objects are mutable and have an efficient overallocation mechanism if concatenating tuple objects, extend a list instead for other types, investigate the relevant class documentation Some sequence types (such as range) only support item sequences that follow specific patterns, and hence don’t support sequence concatenation or repetition. index raises ValueError when x is not found in s. Not all implementations support passing the additional arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra arguments is roughly equivalent to using s[i:j].index(x), only without copying any data and with the returned index being relative to the start of the sequence rather than the start of the slice. Immutable Sequence Types The only operation that immutable sequence types generally implement that is not also implemented by mutable sequence types is support for the hash() built-in. This support allows immutable sequences, such as tuple instances, to be used as dict keys and stored in set and frozenset instances. Attempting to hash an immutable sequence that contains unhashable values will result in TypeError. Mutable Sequence Types The operations in the following table are defined on mutable sequence types. The collections.abc.MutableSequence ABC is provided to make it easier to correctly implement these operations on custom sequence types. In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets any type and value restrictions imposed by s (for example, bytearray only accepts integers that meet the value restriction 0 <= x <= 255). Operation Result Notes s[i] = x item i of s is replaced by x s[i:j] = t slice of s from i to j is replaced by the contents of the iterable t del s[i:j] same as s[i:j] = [] s[i:j:k] = t the elements of s[i:j:k] are replaced by those of t (1) del s[i:j:k] removes the elements of s[i:j:k] from the list s.append(x) appends x to the end of the sequence (same as s[len(s):len(s)] = [x]) s.clear() removes all items from s (same as del s[:]) (5) s.copy() creates a shallow copy of s (same as s[:]) (5) s.extend(t) or s += t extends s with the contents of t (for the most part the same as s[len(s):len(s)] = t) s *= n updates s with its contents repeated n times (6) s.insert(i, x) inserts x into s at the index given by i (same as s[i:i] = [x]) s.pop([i]) retrieves the item at i and also removes it", "score": "0.6744914"}, {"id": "17646", "text": "Function: python.library.array#array.array.tolist\nSnippet: array.tolist() Convert the array to an ordinary list with the same items.", "score": "0.67282325"}, {"id": "42756", "text": "Function: numpy.reference.distutils.misc_util#numpy.distutils.misc_util.as_list\nSnippet: numpy.distutils.misc_util.as_list(seq)[source]", "score": "0.6726435"}]}
{"task_id": 579, "text": "Write a function to find the dissimilar elements in the given two tuples.", "code": "def find_dissimilar(test_tup1, test_tup2):\r\n  res = tuple(set(test_tup1) ^ set(test_tup2))\r\n  return (res) ", "test_list": ["assert find_dissimilar((3, 4, 5, 6), (5, 7, 4, 10)) == (3, 6, 7, 10)", "assert find_dissimilar((1, 2, 3, 4), (7, 2, 3, 9)) == (1, 4, 7, 9)", "assert find_dissimilar((21, 11, 25, 26), (26, 34, 21, 36)) == (34, 36, 11, 25)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "19651", "text": "Function: python.library.difflib#difflib.SequenceMatcher.ratio\nSnippet: ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5", "score": "0.7061536"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.70061797"}, {"id": "19644", "text": "Function: python.library.difflib#difflib.SequenceMatcher\nSnippet: abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence: >>> s = SequenceMatcher(lambda x: x==\" \", \" abcd\", \"abcd abcd\") >>> s.find_longest_match(0, 5, 0, 9) Match(a=1, b=0, size=4) If no blocks match, this returns (alo, blo, 0). This method returns a named tuple Match(a, b, size). Changed in version 3.9: Added default arguments. get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution:", "score": "0.69596606"}, {"id": "25766", "text": "Function: python.library.stdtypes\nSnippet: is less than another set if and only if the first set is a proper subset of the second set (is a subset, but is not equal). A set is greater than another set if and only if the first set is a proper superset of the second set (is a superset, but is not equal). Instances of set are compared to instances of frozenset based on their members. For example, set('abc') == frozenset('abc') returns True and so does set('abc') in set([frozenset('abc')]). The subset and equality comparisons do not generalize to a total ordering function. For example, any two nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return False: a<b, a==b, or a>b. Since sets only define partial ordering (subset relationships), the output of the list.sort() method is undefined for lists of sets. Set elements, like dictionary keys, must be hashable. Binary operations that mix set instances with frozenset return the type of the first operand. For example: frozenset('ab') | set('bc') returns an instance of frozenset. The following table lists operations available for set that do not apply to immutable instances of frozenset: update(*others) set |= other | ... Update the set, adding elements from all others. intersection_update(*others) set &= other & ... Update the set, keeping only elements found in it and all others. difference_update(*others) set -= other | ... Update the set, removing elements found in others. symmetric_difference_update(other) set ^= other Update the set, keeping only elements found in either set, but not in both. add(elem) Add element elem to the set. remove(elem) Remove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem) Remove element elem from the set if it is present. pop() Remove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear() Remove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(), and symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To support searching for an equivalent frozenset, a temporary one is created from elem. Mapping Types — dict A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only one standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and the collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictionaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (such as 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. (Note however, that since computers store floating-point numbers as approximations it is usually unwise to use them as dictionary keys.) Dictionaries can", "score": "0.6900825"}, {"id": "19648", "text": "Function: python.library.difflib#difflib.SequenceMatcher.get_matching_blocks\nSnippet: get_matching_blocks() Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]", "score": "0.69006854"}]}
{"task_id": 580, "text": "Write a function to extract the even elements in the nested mixed tuple.", "code": "def even_ele(test_tuple, even_fnc): \r\n\tres = tuple() \r\n\tfor ele in test_tuple: \r\n\t\tif isinstance(ele, tuple): \r\n\t\t\tres += (even_ele(ele, even_fnc), ) \r\n\t\telif even_fnc(ele): \r\n\t\t\tres += (ele, ) \r\n\treturn res \r\ndef extract_even(test_tuple):\r\n  res = even_ele(test_tuple, lambda x: x % 2 == 0)\r\n  return (res) ", "test_list": ["assert extract_even((4, 5, (7, 6, (2, 4)), 6, 8)) == (4, (6, (2, 4)), 6, 8)", "assert extract_even((5, 6, (8, 7, (4, 8)), 7, 9)) == (6, (8, (4, 8)))", "assert extract_even((5, 6, (9, 8, (4, 6)), 8, 10)) == (6, (8, (4, 6)), 8, 10)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21293", "text": "Function: python.library.itertools\nSnippet: to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n. itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs. itertools.repeat(object[, times]) Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified. Used as argument to map() for", "score": "0.684795"}, {"id": "13035", "text": "Function: sklearn.modules.generated.sklearn.utils.gen_even_slices#sklearn.utils.gen_even_slices\nSnippet: sklearn.utils.gen_even_slices(n, n_packs, *, n_samples=None) [source] Generator to create n_packs slices going up to n. Parameters nint n_packsint Number of slices to generate. n_samplesint, default=None Number of samples. Pass n_samples when the slices are to be used for sparse matrix indexing; slicing off-the-end raises an exception, while it works for NumPy arrays. Yields slice Examples >>> from sklearn.utils import gen_even_slices >>> list(gen_even_slices(10, 1)) [slice(0, 10, None)] >>> list(gen_even_slices(10, 10)) [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)] >>> list(gen_even_slices(10, 5)) [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)] >>> list(gen_even_slices(10, 3)) [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]", "score": "0.67708117"}, {"id": "21301", "text": "Function: python.library.itertools#itertools.combinations\nSnippet: itertools.combinations(iterable, r) Return r length subsequences of elements from the input iterable. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each combination. Roughly equivalent to: def combinations(iterable, r): # combinations('ABCD', 2) --> AB AC AD BC BD CD # combinations(range(4), 3) --> 012 013 023 123 pool = tuple(iterable) n = len(pool) if r > n: return indices = list(range(r)) yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != i + n - r: break else: return indices[i] += 1 for j in range(i+1, r): indices[j] = indices[j-1] + 1 yield tuple(pool[i] for i in indices) The code for combinations() can be also expressed as a subsequence of permutations() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations(iterable, r): pool = tuple(iterable) n = len(pool) for indices in permutations(range(n), r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is n! / r! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.6744477"}, {"id": "21310", "text": "Function: python.library.itertools#itertools.permutations\nSnippet: itertools.permutations(iterable, r=None) Return successive r length permutations of elements in the iterable. If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permutations are generated. The permutation tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, there will be no repeat values in each permutation. Roughly equivalent to: def permutations(iterable, r=None): # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) --> 012 021 102 120 201 210 pool = tuple(iterable) n = len(pool) r = n if r is None else r if r > n: return indices = list(range(n)) cycles = list(range(n, n-r, -1)) yield tuple(pool[i] for i in indices[:r]) while n: for i in reversed(range(r)): cycles[i] -= 1 if cycles[i] == 0: indices[i:] = indices[i+1:] + indices[i:i+1] cycles[i] = n - i else: j = cycles[i] indices[i], indices[-j] = indices[-j], indices[i] yield tuple(pool[i] for i in indices[:r]) break else: return The code for permutations() can be also expressed as a subsequence of product(), filtered to exclude entries with repeated elements (those from the same position in the input pool): def permutations(iterable, r=None): pool = tuple(iterable) n = len(pool) r = n if r is None else r for indices in product(range(n), repeat=r): if len(set(indices)) == r: yield tuple(pool[i] for i in indices) The number of items returned is n! / (n-r)! when 0 <= r <= n or zero when r > n.", "score": "0.67397976"}, {"id": "21302", "text": "Function: python.library.itertools#itertools.combinations_with_replacement\nSnippet: itertools.combinations_with_replacement(iterable, r) Return r length subsequences of elements from the input iterable allowing individual elements to be repeated more than once. The combination tuples are emitted in lexicographic ordering according to the order of the input iterable. So, if the input iterable is sorted, the combination tuples will be produced in sorted order. Elements are treated as unique based on their position, not on their value. So if the input elements are unique, the generated combinations will also be unique. Roughly equivalent to: def combinations_with_replacement(iterable, r): # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC pool = tuple(iterable) n = len(pool) if not n and r: return indices = [0] * r yield tuple(pool[i] for i in indices) while True: for i in reversed(range(r)): if indices[i] != n - 1: break else: return indices[i:] = [indices[i] + 1] * (r - i) yield tuple(pool[i] for i in indices) The code for combinations_with_replacement() can be also expressed as a subsequence of product() after filtering entries where the elements are not in sorted order (according to their position in the input pool): def combinations_with_replacement(iterable, r): pool = tuple(iterable) n = len(pool) for indices in product(range(n), repeat=r): if sorted(indices) == list(indices): yield tuple(pool[i] for i in indices) The number of items returned is (n+r-1)! / r! / (n-1)! when n > 0. New in version 3.1.", "score": "0.6736862"}]}
{"task_id": 581, "text": "Write a python function to find the surface area of the square pyramid.", "code": "def surface_Area(b,s): \r\n    return 2 * b * s + pow(b,2) ", "test_list": ["assert surface_Area(3,4) == 33", "assert surface_Area(4,5) == 56", "assert surface_Area(1,2) == 5"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "14440", "text": "Function: pandas.reference.api.pandas.dataframe.pow\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.65933675"}, {"id": "17024", "text": "Function: skimage.api.skimage.measure#skimage.measure.mesh_surface_area\nSnippet: skimage.measure.mesh_surface_area(verts, faces) [source] Compute surface area, given vertices & triangular faces Parameters verts(V, 3) array of floats Array containing (x, y, z) coordinates for V unique mesh vertices. faces(F, 3) array of ints List of length-3 lists of integers, referencing vertex coordinates as provided in verts Returns areafloat Surface area of mesh. Units now [coordinate units] ** 2. See also skimage.measure.marching_cubes skimage.measure.marching_cubes_classic Notes The arguments expected by this function are the first two outputs from skimage.measure.marching_cubes. For unit correct output, ensure correct spacing was passed to skimage.measure.marching_cubes. This algorithm works properly only if the faces provided are all triangles.", "score": "0.658929"}, {"id": "21777", "text": "Function: python.library.math\nSnippet: Unlike the built-in ** operator, math.pow() converts both its arguments to type float. Use ** or the built-in pow() function for computing exact integer powers. math.sqrt(x) Return the square root of x. Trigonometric functions math.acos(x) Return the arc cosine of x, in radians. The result is between 0 and pi. math.asin(x) Return the arc sine of x, in radians. The result is between -pi/2 and pi/2. math.atan(x) Return the arc tangent of x, in radians. The result is between -pi/2 and pi/2. math.atan2(y, x) Return atan(y / x), in radians. The result is between -pi and pi. The vector in the plane from the origin to point (x, y) makes this angle with the positive X axis. The point of atan2() is that the signs of both inputs are known to it, so it can compute the correct quadrant for the angle. For example, atan(1) and atan2(1, 1) are both pi/4, but atan2(-1, -1) is -3*pi/4. math.cos(x) Return the cosine of x radians. math.dist(p, q) Return the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Roughly equivalent to: sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q))) New in version 3.8. math.hypot(*coordinates) Return the Euclidean norm, sqrt(sum(x**2 for x in coordinates)). This is the length of the vector from the origin to the point given by the coordinates. For a two dimensional point (x, y), this is equivalent to computing the hypotenuse of a right triangle using the Pythagorean theorem, sqrt(x*x + y*y). Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two dimensional case was supported. math.sin(x) Return the sine of x radians. math.tan(x) Return the tangent of x radians. Angular conversion math.degrees(x) Convert angle x from radians to degrees. math.radians(x) Convert angle x from degrees to radians. Hyperbolic functions Hyperbolic functions are analogs of trigonometric functions that are based on hyperbolas instead of circles. math.acosh(x) Return the inverse hyperbolic cosine of x. math.asinh(x) Return the inverse hyperbolic sine of x. math.atanh(x) Return the inverse hyperbolic tangent of x. math.cosh(x) Return the hyperbolic cosine of x. math.sinh(x) Return the hyperbolic sine of x. math.tanh(x) Return the hyperbolic tangent of x. Special functions math.erf(x) Return the error function at x. The erf() function can be used to compute traditional statistical functions such as the cumulative standard normal distribution: def phi(x): 'Cumulative distribution function for the standard normal distribution' return (1.0 + erf(x / sqrt(2.0))) / 2.0 New in version 3.2. math.erfc(x) Return the complementary error function at x. The complementary error function is defined as 1.0 - erf(x). It is used for large values of x where a subtraction from one would cause a loss of significance. New in version 3.2. math.gamma(x) Return the Gamma function at x. New in version 3.2. math.lgamma(x) Return the natural logarithm of the absolute value of the Gamma function at x. New in version 3.2. Constants math.pi The mathematical constant π =", "score": "0.65886164"}, {"id": "14476", "text": "Function: pandas.reference.api.pandas.dataframe.rpow\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.6546219"}, {"id": "14351", "text": "Function: pandas.reference.api.pandas.dataframe.floordiv\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.6534714"}]}
{"task_id": 582, "text": "Write a function to check if a dictionary is empty or not.", "code": "def my_dict(dict1):\r\n  if bool(dict1):\r\n     return False\r\n  else:\r\n     return True", "test_list": ["assert my_dict({10})==False", "assert my_dict({11})==False", "assert my_dict({})==True"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "17971", "text": "Function: python.library.asyncio-queue#asyncio.Queue.empty\nSnippet: empty() Return True if the queue is empty, False otherwise.", "score": "0.7284756"}, {"id": "17578", "text": "Function: python.library.functions#any\nSnippet: any(iterable) Return True if any element of the iterable is true. If the iterable is empty, return False. Equivalent to: def any(iterable): for element in iterable: if element: return True return False", "score": "0.72335345"}, {"id": "25768", "text": "Function: python.library.stdtypes\nSnippet: The example above shows part of the implementation of collections.Counter. A different __missing__ method is used by collections.defaultdict. d[key] = value Set d[key] to value. del d[key] Remove d[key] from d. Raises a KeyError if key is not in the map. key in d Return True if d has a key key, else False. key not in d Equivalent to not key in d. iter(d) Return an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear() Remove all items from the dictionary. copy() Return a shallow copy of the dictionary. classmethod fromkeys(iterable[, value]) Create a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values refer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as an empty list. To get distinct values, use a dict comprehension instead. get(key[, default]) Return the value for key if key is in the dictionary, else default. If default is not given, it defaults to None, so that this method never raises a KeyError. items() Return a new view of the dictionary’s items ((key, value) pairs). See the documentation of view objects. keys() Return a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default]) If key is in the dictionary, remove it and return its value, else return default. If default is not given and key is not in the dictionary, a KeyError is raised. popitem() Remove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the dictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an arbitrary key/value pair. reversed(d) Return a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). New in version 3.8. setdefault(key[, default]) If key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other]) Update the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another dictionary object or an iterable of key/value pairs (as tuples or other iterables of length two). If keyword arguments are specified, the dictionary is then updated with those key/value pairs: d.update(red=1, blue=2). values() Return a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This also applies when comparing dict.values() to itself: >>> d = {'a': 1} >>> d.values() == d.values() False d | other Create a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys.", "score": "0.7174116"}, {"id": "29194", "text": "Function: matplotlib.cbook_api#matplotlib.cbook.Stack.empty\nSnippet: empty()[source] Return whether the stack is empty.", "score": "0.7131879"}, {"id": "22202", "text": "Function: python.library.multiprocessing#multiprocessing.SimpleQueue.empty\nSnippet: empty() Return True if the queue is empty, False otherwise.", "score": "0.7061902"}]}
{"task_id": 583, "text": "Write a function for nth catalan number.", "code": "def catalan_number(num):\r\n    if num <=1:\r\n         return 1   \r\n    res_num = 0\r\n    for i in range(num):\r\n        res_num += catalan_number(i) * catalan_number(num-i-1)\r\n    return res_num", "test_list": ["assert catalan_number(10)==16796", "assert catalan_number(9)==4862", "assert catalan_number(7)==429"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "35797", "text": "Function: django.ref.models.database-functions#django.db.models.functions.NthValue\nSnippet: class NthValue(expression, nth=1, **extra)", "score": "0.7307558"}, {"id": "43141", "text": "Function: numpy.reference.generated.numpy.ravel\nSnippet: 3, 4, 5, 6, 7, 8, 9, 10, 11])", "score": "0.7096339"}, {"id": "7524", "text": "Function: torch.generated.torch.polygamma#torch.polygamma\nSnippet: torch.polygamma(n, input, *, out=None) → Tensor Computes the nthn^{th} derivative of the digamma function on input. n≥0n \\geq 0 is called the order of the polygamma function. ψ(n)(x)=d(n)dx(n)ψ(x)\\psi^{(n)}(x) = \\frac{d^{(n)}}{dx^{(n)}} \\psi(x) Note This function is implemented only for nonnegative integers n≥0n \\geq 0 . Parameters n (int) – the order of the polygamma function input (Tensor) – the input tensor. Keyword Arguments out (Tensor, optional) – the output tensor. Example:: >>> a = torch.tensor([1, 0.5]) >>> torch.polygamma(1, a) tensor([1.64493, 4.9348]) >>> torch.polygamma(2, a) tensor([ -2.4041, -16.8288]) >>> torch.polygamma(3, a) tensor([ 6.4939, 97.4091]) >>> torch.polygamma(4, a) tensor([ -24.8863, -771.4742])", "score": "0.66723347"}, {"id": "21787", "text": "Function: python.library.math#math.comb\nSnippet: math.comb(n, k) Return the number of ways to choose k items from n items without repetition and without order. Evaluates to n! / (k! * (n - k)!) when k <= n and evaluates to zero when k > n. Also called the binomial coefficient because it is equivalent to the coefficient of k-th term in polynomial expansion of the expression (1 + x) ** n. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8.", "score": "0.66325533"}, {"id": "21297", "text": "Function: python.library.itertools\nSnippet: * (n - k + i) // i if index < 0: index += c if index < 0 or index >= c: raise IndexError result = [] while r: c, n, r = c*r//n, n-1, r-1 while index >= c: index -= c c, n = c*(n-r)//n, n-1 result.append(pool[-1-n]) return tuple(result)", "score": "0.6622073"}]}
{"task_id": 584, "text": "Write a function to find all adverbs and their positions in a given sentence by using regex.", "code": "import re\r\ndef find_adverbs(text):\r\n  for m in re.finditer(r\"\\w+ly\", text):\r\n    return ('%d-%d: %s' % (m.start(), m.end(), m.group(0)))", "test_list": ["assert find_adverbs(\"Clearly, he has no excuse for such behavior.\") == '0-7: Clearly'", "assert find_adverbs(\"Please handle the situation carefuly\") == '28-36: carefuly'", "assert find_adverbs(\"Complete the task quickly\") == '18-25: quickly'"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "23315", "text": "Function: python.library.re\nSnippet: ['carefully', 'quickly'] Finding all Adverbs and their Positions If one wants more information about all matches of a pattern than the matched text, finditer() is useful as it provides match objects instead of strings. Continuing with the previous example, if a writer wanted to find all of the adverbs and their positions in some text, they would use finditer() in the following manner: >>> text = \"He was carefully disguised but captured quickly by police.\" >>> for m in re.finditer(r\"\\w+ly\", text): ... print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0))) 07-16: carefully 40-47: quickly Raw String Notation Raw string notation (r\"text\") keeps regular expressions sane. Without it, every backslash ('\\') in a regular expression would have to be prefixed with another one to escape it. For example, the two following lines of code are functionally identical: >>> re.match(r\"\\W(.)\\1\\W\", \" ff \") <re.Match object; span=(0, 4), match=' ff '> >>> re.match(\"\\\\W(.)\\\\1\\\\W\", \" ff \") <re.Match object; span=(0, 4), match=' ff '> When one wants to match a literal backslash, it must be escaped in the regular expression. With raw string notation, this means r\"\\\\\". Without raw string notation, one must use \"\\\\\\\\\", making the following lines of code functionally identical: >>> re.match(r\"\\\\\", r\"\\\\\") <re.Match object; span=(0, 1), match='\\\\'> >>> re.match(\"\\\\\\\\\", r\"\\\\\") <re.Match object; span=(0, 1), match='\\\\'> Writing a Tokenizer A tokenizer or scanner analyzes a string to categorize groups of characters. This is a useful first step in writing a compiler or interpreter. The text categories are specified with regular expressions. The technique is to combine those into a single master regular expression and to loop over successive matches: from typing import NamedTuple import re class Token(NamedTuple): type: str value: str line: int column: int def tokenize(code): keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'} token_specification = [ ('NUMBER', r'\\d+(\\.\\d*)?'), # Integer or decimal number ('ASSIGN', r':='), # Assignment operator ('END', r';'), # Statement terminator ('ID', r'[A-Za-z]+'), # Identifiers ('OP', r'[+\\-*/]'), # Arithmetic operators ('NEWLINE', r'\\n'), # Line endings ('SKIP', r'[ \\t]+'), # Skip over spaces and tabs ('MISMATCH', r'.'), # Any other character ] tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification) line_num = 1 line_start = 0 for mo in re.finditer(tok_regex, code): kind = mo.lastgroup value = mo.group() column = mo.start() - line_start if kind == 'NUMBER': value = float(value) if '.' in value else int(value) elif kind == 'ID' and value in keywords: kind = value elif kind == 'NEWLINE': line_start = mo.end() line_num += 1 continue elif kind == 'SKIP': continue elif kind == 'MISMATCH': raise RuntimeError(f'{value!r} unexpected on line {line_num}') yield Token(kind, value, line_num, column) statements = ''' IF quantity THEN total := total + price * quantity; tax := price * 0.05; ENDIF; ''' for token in tokenize(statements): print(token) The tokenizer produces the following output: Token(type='IF', value='IF', line=2, column=4) Token(type='ID', value='quantity', line=2, column=7) Token(type='THEN', value='THEN', line=2, column=16) Token(type='ID', value='total', line=3, column=8) Token(type='ASSIGN', value=':=', line=3, column=14) Token(type='ID', value='total', line=3, column=17) Token(type='OP', value='+', line=3, column=23) Token(type='ID', value='price', line=3, column=25) Token(type='OP', value='*', line=3, column=31) Token(type='ID', value='quantity', line=3, column=33)", "score": "0.7543756"}, {"id": "23308", "text": "Function: python.library.re\nSnippet: the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string. re.findall(pattern, string, flags=0) Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.finditer(pattern, string, flags=0) Return an iterator yielding match objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match. re.sub(pattern, repl, string, count=0, flags=0) Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. For example: >>> re.sub(r'def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\\s*\\):', ... r'static PyObject*\\npy_\\1(void)\\n{', ... 'def myfunc():') 'static PyObject*\\npy_myfunc(void)\\n{' If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. For example: >>> def dashrepl(matchobj): ... if matchobj.group(0) == '-': return ' ' ... else: return '-' >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files') 'pro--gram files' >>> re.sub(r'\\sAND\\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE) 'Baked Beans & Spam' The pattern may be a string or a pattern object. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern", "score": "0.67811906"}, {"id": "23310", "text": "Function: python.library.re\nSnippet: for the first location where this regular expression produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string. The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0. This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning of the string and at positions just after a newline, but not necessarily at the index where the search is to start. The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos characters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string, 0, 50) is equivalent to rx.search(string[:50], 0). >>> pattern = re.compile(\"d\") >>> pattern.search(\"dog\") # Match at index 0 <re.Match object; span=(0, 1), match='d'> >>> pattern.search(\"dog\", 1) # No match; search doesn't include the \"d\" Pattern.match(string[, pos[, endpos]]) If zero or more characters at the beginning of string match this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o\") >>> pattern.match(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.match(\"dog\", 1) # Match as \"o\" is the 2nd character of \"dog\". <re.Match object; span=(1, 2), match='o'> If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()). Pattern.fullmatch(string[, pos[, endpos]]) If the whole string matches this regular expression, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match. The optional pos and endpos parameters have the same meaning as for the search() method. >>> pattern = re.compile(\"o[gh]\") >>> pattern.fullmatch(\"dog\") # No match as \"o\" is not at the start of \"dog\". >>> pattern.fullmatch(\"ogre\") # No match as not the full string matches. >>> pattern.fullmatch(\"doggie\", 1, 3) # Matches within given limits. <re.Match object; span=(1, 3), match='og'> New in version 3.4. Pattern.split(string, maxsplit=0) Identical to the split() function, using the compiled pattern. Pattern.findall(string[, pos[, endpos]]) Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.finditer(string[, pos[, endpos]]) Similar to the finditer() function, using the compiled pattern, but also accepts optional pos and endpos parameters that limit the search region like for search(). Pattern.sub(repl, string, count=0) Identical to the sub() function, using the compiled pattern. Pattern.subn(repl, string, count=0) Identical to the subn() function, using the compiled pattern. Pattern.flags The regex", "score": "0.6764418"}, {"id": "23368", "text": "Function: python.library.re#re.split\nSnippet: re.split(pattern, string, maxsplit=0, flags=0) Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. >>> re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] >>> re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] >>> re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.", "score": "0.6672783"}, {"id": "23329", "text": "Function: python.library.re#re.findall\nSnippet: re.findall(pattern, string, flags=0) Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result. Changed in version 3.7: Non-empty matches can now start just after a previous empty match.", "score": "0.66470575"}]}
{"task_id": 585, "text": "Write a function to find the n - expensive price items from a given dataset using heap queue algorithm.", "code": "import heapq\r\ndef expensive_items(items,n):\r\n  expensive_items = heapq.nlargest(n, items, key=lambda s: s['price'])\r\n  return expensive_items", "test_list": ["assert expensive_items([{'name': 'Item-1', 'price': 101.1},{'name': 'Item-2', 'price': 555.22}],1)==[{'name': 'Item-2', 'price': 555.22}]", "assert expensive_items([{'name': 'Item-1', 'price': 101.1},{'name': 'Item-2', 'price': 555.22}, {'name': 'Item-3', 'price': 45.09}],2)==[{'name': 'Item-2', 'price': 555.22},{'name': 'Item-1', 'price': 101.1}]", "assert expensive_items([{'name': 'Item-1', 'price': 101.1},{'name': 'Item-2', 'price': 555.22}, {'name': 'Item-3', 'price': 45.09},{'name': 'Item-4', 'price': 22.75}],1)==[{'name': 'Item-2', 'price': 555.22}]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "20477", "text": "Function: python.library.heapq\nSnippet: heapq — Heap queue algorithm Source code: Lib/heapq.py This module provides an implementation of the heap queue algorithm, also known as the priority queue algorithm. Heaps are binary trees for which every parent node has a value less than or equal to any of its children. This implementation uses arrays for which heap[k] <= heap[2*k+1] and heap[k] <= heap[2*k+2] for all k, counting elements from zero. For the sake of comparison, non-existing elements are considered to be infinite. The interesting property of a heap is that its smallest element is always the root, heap[0]. The API below differs from textbook heap algorithms in two aspects: (a) We use zero-based indexing. This makes the relationship between the index for a node and the indexes for its children slightly less obvious, but is more suitable since Python uses zero-based indexing. (b) Our pop method returns the smallest item, not the largest (called a “min heap” in textbooks; a “max heap” is more common in texts because of its suitability for in-place sorting). These two make it possible to view the heap as a regular Python list without surprises: heap[0] is the smallest item, and heap.sort() maintains the heap invariant! To create a heap, use a list initialized to [], or you can transform a populated list into a heap via function heapify(). The following functions are provided: heapq.heappush(heap, item) Push the value item onto the heap, maintaining the heap invariant. heapq.heappop(heap) Pop and return the smallest item from the heap, maintaining the heap invariant. If the heap is empty, IndexError is raised. To access the smallest item without popping it, use heap[0]. heapq.heappushpop(heap, item) Push item on the heap, then pop and return the smallest item from the heap. The combined action runs more efficiently than heappush() followed by a separate call to heappop(). heapq.heapify(x) Transform list x into a heap, in-place, in linear time. heapq.heapreplace(heap, item) Pop and return the smallest item from the heap, and also push the new item. The heap size doesn’t change. If the heap is empty, IndexError is raised. This one step operation is more efficient than a heappop() followed by heappush() and can be more appropriate when using a fixed-size heap. The pop/push combination always returns an element from the heap and replaces it with item. The value returned may be larger than the item added. If that isn’t desired, consider using heappushpop() instead. Its push/pop combination returns the smaller of the two values, leaving the larger value on the heap. The module also offers three general purpose functions based on heaps. heapq.merge(*iterables, key=None, reverse=False) Merge multiple sorted inputs into a single sorted output (for example, merge timestamped entries from multiple log files). Returns an iterator over the sorted values. Similar to sorted(itertools.chain(*iterables)) but returns an iterable, does not pull the data into memory all at once, and assumes that each of the input streams is already sorted (smallest to largest). Has two optional arguments which must be specified as keyword arguments. key specifies a", "score": "0.69448125"}, {"id": "20488", "text": "Function: python.library.heapq#heapq.nlargest\nSnippet: heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n].", "score": "0.69347507"}, {"id": "20478", "text": "Function: python.library.heapq\nSnippet: key function of one argument that is used to extract a comparison key from each input element. The default value is None (compare the elements directly). reverse is a boolean value. If set to True, then the input elements are merged as if each comparison were reversed. To achieve behavior similar to sorted(itertools.chain(*iterables), reverse=True), all iterables must be sorted from largest to smallest. Changed in version 3.5: Added the optional key and reverse parameters. heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n]. heapq.nsmallest(n, iterable, key=None) Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key)[:n]. The latter two functions perform best for smaller values of n. For larger values, it is more efficient to use the sorted() function. Also, when n==1, it is more efficient to use the built-in min() and max() functions. If repeated usage of these functions is required, consider turning the iterable into an actual heap. Basic Examples A heapsort can be implemented by pushing all values onto a heap and then popping off the smallest values one at a time: >>> def heapsort(iterable): ... h = [] ... for value in iterable: ... heappush(h, value) ... return [heappop(h) for i in range(len(h))] ... >>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0]) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] This is similar to sorted(iterable), but unlike sorted(), this implementation is not stable. Heap elements can be tuples. This is useful for assigning comparison values (such as task priorities) alongside the main record being tracked: >>> h = [] >>> heappush(h, (5, 'write code')) >>> heappush(h, (7, 'release product')) >>> heappush(h, (1, 'write spec')) >>> heappush(h, (3, 'create tests')) >>> heappop(h) (1, 'write spec') Priority Queue Implementation Notes A priority queue is common use for a heap, and it presents several implementation challenges: Sort stability: how do you get two tasks with equal priorities to be returned in the order they were originally added? Tuple comparison breaks for (priority, task) pairs if the priorities are equal and the tasks do not have a default comparison order. If the priority of a task changes, how do you move it to a new position in the heap? Or if a pending task needs to be deleted, how do you find it and remove it from the queue? A solution to the first two challenges is to store entries as 3-element list including the priority, an entry count, and the task. The entry count serves as a tie-breaker so that two tasks with the same priority are returned in the order they were", "score": "0.69052136"}, {"id": "20479", "text": "Function: python.library.heapq\nSnippet: added. And since no two entry counts are the same, the tuple comparison will never attempt to directly compare two tasks. Another solution to the problem of non-comparable tasks is to create a wrapper class that ignores the task item and only compares the priority field: from dataclasses import dataclass, field from typing import Any @dataclass(order=True) class PrioritizedItem: priority: int item: Any=field(compare=False) The remaining challenges revolve around finding a pending task and making changes to its priority or removing it entirely. Finding a task can be done with a dictionary pointing to an entry in the queue. Removing the entry or changing its priority is more difficult because it would break the heap structure invariants. So, a possible solution is to mark the entry as removed and add a new entry with the revised priority: pq = [] # list of entries arranged in a heap entry_finder = {} # mapping of tasks to entries REMOVED = '<removed-task>' # placeholder for a removed task counter = itertools.count() # unique sequence count def add_task(task, priority=0): 'Add a new task or update the priority of an existing task' if task in entry_finder: remove_task(task) count = next(counter) entry = [priority, count, task] entry_finder[task] = entry heappush(pq, entry) def remove_task(task): 'Mark an existing task as REMOVED. Raise KeyError if not found.' entry = entry_finder.pop(task) entry[-1] = REMOVED def pop_task(): 'Remove and return the lowest priority task. Raise KeyError if empty.' while pq: priority, count, task = heappop(pq) if task is not REMOVED: del entry_finder[task] return task raise KeyError('pop from an empty priority queue') Theory Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for all k, counting elements from 0. For the sake of comparison, non-existing elements are considered to be infinite. The interesting property of a heap is that a[0] is always its smallest element. The strange invariant above is meant to be an efficient memory representation for a tournament. The numbers below are k, not a[k]: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 In the tree above, each cell k is topping 2*k+1 and 2*k+2. In a usual binary tournament we see in sports, each cell is the winner over the two cells it tops, and we can trace the winner down the tree to see all opponents s/he had. However, in many computer applications of such tournaments, we do not need to trace the history of a winner. To be more memory efficient, when a winner is promoted, we try to replace it by something else at a lower level, and the rule becomes that a cell and the two cells it tops contain three different items, but the top cell “wins” over the two topped cells. If this heap invariant is protected at all time, index 0 is clearly the overall winner. The simplest algorithmic way to remove it and find the “next”", "score": "0.67567664"}, {"id": "20489", "text": "Function: python.library.heapq#heapq.nsmallest\nSnippet: heapq.nsmallest(n, iterable, key=None) Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key)[:n].", "score": "0.6704826"}]}
{"task_id": 586, "text": "Write a python function to split the array and add the first part to the end.", "code": "def split_Arr(a,n,k):  \r\n   b = a[:k] \r\n   return (a[k::]+b[::]) ", "test_list": ["assert split_Arr([12,10,5,6,52,36],6,2) == [5,6,52,36,12,10]", "assert split_Arr([1,2,3,4],4,1) == [2,3,4,1]", "assert split_Arr([0,1,2,3,4,5,6,7],8,3) == [3,4,5,6,7,0,1,2]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "17629", "text": "Function: python.library.array#array.array.append\nSnippet: array.append(x) Append a new item with value x to the end of the array.", "score": "0.7120765"}, {"id": "23368", "text": "Function: python.library.re#re.split\nSnippet: re.split(pattern, string, maxsplit=0, flags=0) Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. >>> re.split(r'\\W+', 'Words, words, words.') ['Words', 'words', 'words', ''] >>> re.split(r'(\\W+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '.', ''] >>> re.split(r'\\W+', 'Words, words, words.', 1) ['Words', 'words, words.'] >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE) ['0', '3', '9'] If there are capturing groups in the separator and it matches at the start of the string, the result will start with an empty string. The same holds for the end of the string: >>> re.split(r'(\\W+)', '...words, words...') ['', '...', 'words', ', ', 'words', '...', ''] That way, separator components are always found at the same relative indices within the result list. Empty matches for the pattern split the string only when not adjacent to a previous empty match. >>> re.split(r'\\b', 'Words, words, words.') ['', 'Words', ', ', 'words', ', ', 'words', '.'] >>> re.split(r'\\W*', '...words...') ['', '', 'w', 'o', 'r', 'd', 's', '', ''] >>> re.split(r'(\\W*)', '...words...') ['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', ''] Changed in version 3.1: Added the optional flags argument. Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.", "score": "0.6762495"}, {"id": "18291", "text": "Function: python.library.stdtypes#bytearray.split\nSnippet: bytes.split(sep=None, maxsplit=-1) bytearray.split(sep=None, maxsplit=-1) Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object. For example: >>> b'1,2,3'.split(b',') [b'1', b'2', b'3'] >>> b'1,2,3'.split(b',', maxsplit=1) [b'1', b'2,3'] >>> b'1,2,,3,'.split(b',') [b'1', b'2', b'', b'3', b''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns []. For example: >>> b'1 2 3'.split() [b'1', b'2', b'3'] >>> b'1 2 3'.split(maxsplit=1) [b'1', b'2 3'] >>> b' 1 2 3 '.split() [b'1', b'2', b'3']", "score": "0.6736466"}, {"id": "42643", "text": "Function: numpy.reference.generated.numpy.array_split\nSnippet: numpy.array_split numpy.array_split(ary, indices_or_sections, axis=0)[source] Split an array into multiple sub-arrays. Please refer to the split documentation. The only difference between these functions is that array_split allows indices_or_sections to be an integer that does not equally divide the axis. For an array of length l that should be split into n sections, it returns l % n sub-arrays of size l//n + 1 and the rest of size l//n. See also split Split array into multiple sub-arrays of equal size. Examples >>> x = np.arange(8.0) >>> np.array_split(x, 3) [array([0., 1., 2.]), array([3., 4., 5.]), array([6., 7.])] >>> x = np.arange(9) >>> np.array_split(x, 4) [array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]", "score": "0.67072654"}, {"id": "18335", "text": "Function: python.library.stdtypes#bytes.split\nSnippet: bytes.split(sep=None, maxsplit=-1) bytearray.split(sep=None, maxsplit=-1) Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or is -1, then there is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences (for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a multibyte sequence (for example, b'1<>2<>3'.split(b'<>') returns [b'1', b'2', b'3']). Splitting an empty sequence with a specified separator returns [b''] or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like object. For example: >>> b'1,2,3'.split(b',') [b'1', b'2', b'3'] >>> b'1,2,3'.split(b',', maxsplit=1) [b'1', b'2,3'] >>> b'1,2,,3,'.split(b',') [b'1', b'2', b'', b'3', b''] If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely of ASCII whitespace without a specified separator returns []. For example: >>> b'1 2 3'.split() [b'1', b'2', b'3'] >>> b'1 2 3'.split(maxsplit=1) [b'1', b'2 3'] >>> b' 1 2 3 '.split() [b'1', b'2', b'3']", "score": "0.6674508"}]}
{"task_id": 587, "text": "Write a function to convert a list to a tuple.", "code": "def list_tuple(listx):\r\n  tuplex = tuple(listx)\r\n  return tuplex", "test_list": ["assert list_tuple([5, 10, 7, 4, 15, 3])==(5, 10, 7, 4, 15, 3)", "assert list_tuple([2, 4, 5, 6, 2, 3, 4, 4, 7])==(2, 4, 5, 6, 2, 3, 4, 4, 7)", "assert list_tuple([58,44,56])==(58,44,56)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "25588", "text": "Function: python.library.stdtypes#tuple\nSnippet: class tuple([iterable]) Tuples may be constructed in a number of ways: Using a pair of parentheses to denote the empty tuple: () Using a trailing comma for a singleton tuple: a, or (a,) Separating items with commas: a, b, c or (a, b, c) Using the tuple() built-in: tuple() or tuple(iterable) The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it is returned unchanged. For example, tuple('abc') returns ('a', 'b', 'c') and tuple( [1, 2, 3] ) returns (1, 2, 3). If no argument is given, the constructor creates a new empty tuple, (). Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional, except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, f(a, b, c) is a function call with three arguments, while f((a, b, c)) is a function call with a 3-tuple as the sole argument. Tuples implement all of the common sequence operations.", "score": "0.70039815"}, {"id": "17646", "text": "Function: python.library.array#array.array.tolist\nSnippet: array.tolist() Convert the array to an ordinary list with the same items.", "score": "0.6911295"}, {"id": "25902", "text": "Function: python.library.typing#typing.Tuple\nSnippet: typing.Tuple Tuple type; Tuple[X, Y] is the type of a tuple of two items with the first item of type X and the second of type Y. The type of the empty tuple can be written as Tuple[()]. Example: Tuple[T1, T2] is a tuple of two elements corresponding to type variables T1 and T2. Tuple[int, float, str] is a tuple of an int, a float and a string. To specify a variable-length tuple of homogeneous type, use literal ellipsis, e.g. Tuple[int, ...]. A plain Tuple is equivalent to Tuple[Any, ...], and in turn to tuple. Deprecated since version 3.9: builtins.tuple now supports []. See PEP 585 and Generic Alias Type.", "score": "0.68944013"}, {"id": "25589", "text": "Function: python.library.functions#tuple\nSnippet: class tuple([iterable]) Rather than being a function, tuple is actually an immutable sequence type, as documented in Tuples and Sequence Types — list, tuple, range.", "score": "0.68336195"}, {"id": "36422", "text": "Function: django.ref.contrib.gis.gdal#django.contrib.gis.gdal.Envelope.tuple\nSnippet: tuple", "score": "0.6816778"}]}
{"task_id": 588, "text": "Write a python function to find the difference between largest and smallest value in a given array.", "code": "def big_diff(nums):\r\n     diff= max(nums)-min(nums)\r\n     return diff", "test_list": ["assert big_diff([1,2,3,4]) == 3", "assert big_diff([4,5,12]) == 8", "assert big_diff([9,2,3]) == 7"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "17638", "text": "Function: python.library.array#array.array.index\nSnippet: array.index(x) Return the smallest i such that i is the index of the first occurrence of x in the array.", "score": "0.7208048"}, {"id": "43968", "text": "Function: numpy.reference.generated.numpy.testing.assert_array_max_ulp\nSnippet: numpy.testing.assert_array_max_ulp testing.assert_array_max_ulp(a, b, maxulp=1, dtype=None)[source] Check that all items of arrays differ in at most N Units in the Last Place. Parameters a, barray_like Input arrays to be compared. maxulpint, optional The maximum number of units in the last place that elements of a and b can differ. Default is 1. dtypedtype, optional Data-type to convert a and b to if given. Default is None. Returns retndarray Array containing number of representable floating point numbers between items in a and b. Raises AssertionError If one or more elements differ by more than maxulp. See also assert_array_almost_equal_nulp Compare two arrays relatively to their spacing. Notes For computing the ULP difference, this API does not differentiate between various representations of NAN (ULP difference between 0x7fc00000 and 0xffc00000 is zero). Examples >>> a = np.linspace(0., 1., 100) >>> res = np.testing.assert_array_max_ulp(a, np.arcsin(np.sin(a)))", "score": "0.71078676"}, {"id": "19496", "text": "Function: python.library.decimal#decimal.Context.next_minus\nSnippet: next_minus(x) Returns the largest representable number smaller than x.", "score": "0.70632267"}, {"id": "13013", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos#sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.7001451"}, {"id": "12778", "text": "Function: sklearn.modules.generated.sklearn.utils.arrayfuncs.min_pos\nSnippet: sklearn.utils.arrayfuncs.min_pos sklearn.utils.arrayfuncs.min_pos() Find the minimum value of an array over positive values Returns a huge value if none of the values are positive", "score": "0.69445884"}]}
{"task_id": 589, "text": "Write a function to find perfect squares between two given numbers.", "code": "def perfect_squares(a, b):\r\n    lists=[]\r\n    for i in range (a,b+1):\r\n        j = 1;\r\n        while j*j <= i:\r\n            if j*j == i:\r\n                 lists.append(i)  \r\n            j = j+1\r\n        i = i+1\r\n    return lists", "test_list": ["assert perfect_squares(1,30)==[1, 4, 9, 16, 25]", "assert perfect_squares(50,100)==[64, 81, 100]", "assert perfect_squares(100,200)==[100, 121, 144, 169, 196]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21775", "text": "Function: python.library.math\nSnippet: some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n - 1). New in version 3.8. math.lcm(*integers) Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is zero, then the returned value is 0. lcm() without arguments returns 1. New in version 3.9. math.ldexp(x, i) Return x * (2**i). This is essentially the inverse of function frexp(). math.modf(x) Return the fractional and integer parts of x. Both results carry the sign of x and are floats. math.nextafter(x, y) Return the next floating-point value after x towards y. If x is equal to y, return y. Examples: math.nextafter(x, math.inf) goes up: towards positive infinity. math.nextafter(x, -math.inf) goes down: towards minus infinity. math.nextafter(x, 0.0) goes towards zero. math.nextafter(x, math.copysign(math.inf, x)) goes away from zero. See also math.ulp(). New in version 3.9. math.perm(n, k=None) Return the number of ways to choose k items from n items without repetition and with order. Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n. If k is not specified or is None, then k defaults to n and the function returns n!. Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments are negative. New in version 3.8. math.prod(iterable, *, start=1) Calculate the product of all the elements in the input iterable. The default start value for the product is 1. When the iterable is empty, return the start value. This function is intended specifically for use with numeric values and may reject non-numeric types. New in version 3.8. math.remainder(x, y) Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r = remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y). Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result of the remainder operation is zero, that zero will have the same sign as x. On platforms using IEEE 754 binary floating-point, the result of this operation is always exactly representable: no rounding error is introduced. New in version 3.7. math.trunc(x) Return the Real value x truncated to an Integral (usually an integer). Delegates to x.__trunc__(). math.ulp(x) Return the value of the least significant bit of the float x: If x is a NaN", "score": "0.6576246"}, {"id": "21777", "text": "Function: python.library.math\nSnippet: Unlike the built-in ** operator, math.pow() converts both its arguments to type float. Use ** or the built-in pow() function for computing exact integer powers. math.sqrt(x) Return the square root of x. Trigonometric functions math.acos(x) Return the arc cosine of x, in radians. The result is between 0 and pi. math.asin(x) Return the arc sine of x, in radians. The result is between -pi/2 and pi/2. math.atan(x) Return the arc tangent of x, in radians. The result is between -pi/2 and pi/2. math.atan2(y, x) Return atan(y / x), in radians. The result is between -pi and pi. The vector in the plane from the origin to point (x, y) makes this angle with the positive X axis. The point of atan2() is that the signs of both inputs are known to it, so it can compute the correct quadrant for the angle. For example, atan(1) and atan2(1, 1) are both pi/4, but atan2(-1, -1) is -3*pi/4. math.cos(x) Return the cosine of x radians. math.dist(p, q) Return the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Roughly equivalent to: sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q))) New in version 3.8. math.hypot(*coordinates) Return the Euclidean norm, sqrt(sum(x**2 for x in coordinates)). This is the length of the vector from the origin to the point given by the coordinates. For a two dimensional point (x, y), this is equivalent to computing the hypotenuse of a right triangle using the Pythagorean theorem, sqrt(x*x + y*y). Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two dimensional case was supported. math.sin(x) Return the sine of x radians. math.tan(x) Return the tangent of x radians. Angular conversion math.degrees(x) Convert angle x from radians to degrees. math.radians(x) Convert angle x from degrees to radians. Hyperbolic functions Hyperbolic functions are analogs of trigonometric functions that are based on hyperbolas instead of circles. math.acosh(x) Return the inverse hyperbolic cosine of x. math.asinh(x) Return the inverse hyperbolic sine of x. math.atanh(x) Return the inverse hyperbolic tangent of x. math.cosh(x) Return the hyperbolic cosine of x. math.sinh(x) Return the hyperbolic sine of x. math.tanh(x) Return the hyperbolic tangent of x. Special functions math.erf(x) Return the error function at x. The erf() function can be used to compute traditional statistical functions such as the cumulative standard normal distribution: def phi(x): 'Cumulative distribution function for the standard normal distribution' return (1.0 + erf(x / sqrt(2.0))) / 2.0 New in version 3.2. math.erfc(x) Return the complementary error function at x. The complementary error function is defined as 1.0 - erf(x). It is used for large values of x where a subtraction from one would cause a loss of significance. New in version 3.2. math.gamma(x) Return the Gamma function at x. New in version 3.2. math.lgamma(x) Return the natural logarithm of the absolute value of the Gamma function at x. New in version 3.2. Constants math.pi The mathematical constant π =", "score": "0.6550848"}, {"id": "8112", "text": "Function: torch.tensors#torch.Tensor.square\nSnippet: square() → Tensor See torch.square()", "score": "0.6485139"}, {"id": "14324", "text": "Function: pandas.reference.api.pandas.dataframe.div\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.64357346"}, {"id": "21792", "text": "Function: python.library.math#math.dist\nSnippet: math.dist(p, q) Return the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates. The two points must have the same dimension. Roughly equivalent to: sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q))) New in version 3.8.", "score": "0.6423369"}]}
{"task_id": 590, "text": "Write a function to convert polar coordinates to rectangular coordinates.", "code": "import cmath\r\ndef polar_rect(x,y):\r\n cn = complex(x,y)\r\n cn=cmath.polar(cn)\r\n cn1 = cmath.rect(2, cmath.pi)\r\n return (cn,cn1)", "test_list": ["assert polar_rect(3,4)==((5.0, 0.9272952180016122), (-2+2.4492935982947064e-16j))", "assert polar_rect(4,7)==((8.06225774829855, 1.0516502125483738), (-2+2.4492935982947064e-16j))", "assert polar_rect(15,17)==((22.67156809750927, 0.8478169733934057), (-2+2.4492935982947064e-16j))"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "33154", "text": "Function: matplotlib.projections_api#matplotlib.projections.polar.PolarAxes.format_coord\nSnippet: format_coord(theta, r)[source] Return a format string formatting the x, y coordinates.", "score": "0.70421183"}, {"id": "33038", "text": "Function: matplotlib.projections_api\nSnippet: integers) in the subclass. transform_non_affine(xy)[source] Apply only the non-affine part of this transformation. transform(values) is always equivalent to transform_affine(transform_non_affine(values)). In non-affine transformations, this is generally equivalent to transform(values). In affine transformations, this is always a no-op. Parameters valuesarray The input values as NumPy array of length input_dims or shape (N x input_dims). Returns array The output values as NumPy array of length input_dims or shape (N x output_dims), depending on the input. classmatplotlib.projections.polar.PolarAffine(scale_transform, limits)[source] Bases: matplotlib.transforms.Affine2DBase The affine part of the polar projection. Scales the output so that maximum radius rests on the edge of the axes circle. limits is the view limit of the data. The only part of its bounds that is used is the y limits (for the radius limits). The theta range is handled by the non-affine transform. get_matrix()[source] Get the matrix for the affine part of this transform. classmatplotlib.projections.polar.PolarAxes(*args, theta_offset=0, theta_direction=1, rlabel_position=22.5, **kwargs)[source] Bases: matplotlib.axes._axes.Axes A polar graph projection, where the input dimensions are theta, r. Theta starts pointing east and goes anti-clockwise. Build an Axes in a figure. Parameters figFigure The Axes is built in the Figure fig. rect[left, bottom, width, height] The Axes is built in the rectangle rect. rect is in Figure coordinates. sharex, shareyAxes, optional The x or y axis is shared with the x or y axis in the input Axes. frameonbool, default: True Whether the Axes frame is visible. box_aspectfloat, optional Set a fixed aspect for the Axes box, i.e. the ratio of height to width. See set_box_aspect for details. **kwargs Other optional keyword arguments: Property Description adjustable {'box', 'datalim'} agg_filter a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array alpha scalar or None anchor (float, float) or {'C', 'SW', 'S', 'SE', 'E', 'NE', ...} animated bool aspect {'auto', 'equal'} or float autoscale_on bool autoscalex_on bool autoscaley_on bool axes_locator Callable[[Axes, Renderer], Bbox] axisbelow bool or 'line' box_aspect float or None clip_box Bbox clip_on bool clip_path Patch or (Path, Transform) or None facecolor or fc color figure Figure frame_on bool gid str in_layout bool label object navigate bool navigate_mode unknown path_effects AbstractPathEffect picker None or bool or float or callable position [left, bottom, width, height] or Bbox prop_cycle unknown rasterization_zorder float or None rasterized bool sketch_params (scale: float, length: float, randomness: float) snap bool or None title str transform Transform url str visible bool xbound unknown xlabel str xlim (bottom: float, top: float) xmargin float greater than -0.5 xscale {\"linear\", \"log\", \"symlog\", \"logit\", ...} or ScaleBase xticklabels unknown xticks unknown ybound unknown ylabel str ylim (bottom: float, top: float) ymargin float greater than -0.5 yscale {\"linear\", \"log\", \"symlog\", \"logit\", ...} or ScaleBase yticklabels unknown yticks unknown zorder float Returns Axes The new Axes object. classInvertedPolarTransform(axis=None, use_rmin=True, _apply_theta_transforms=True)[source] Bases: matplotlib.transforms.Transform The inverse of the polar transform, mapping Cartesian coordinate space x and y back to theta and r. Parameters shorthand_namestr A string representing the \"name\" of the transform. The name carries no significance other than to improve the", "score": "0.69734544"}, {"id": "14467", "text": "Function: pandas.reference.api.pandas.dataframe.rfloordiv\nSnippet: triangle 1.0 1.0 rectangle 1.0 1.0 B square 0.0 0.0 pentagon 0.0 0.0 hexagon 0.0 0.0", "score": "0.6923703"}, {"id": "42734", "text": "Function: numpy.reference.generated.numpy.deg2rad\nSnippet: numpy.deg2rad numpy.deg2rad(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'deg2rad'> Convert angles from degrees to radians. Parameters xarray_like Angles in degrees. outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns yndarray The corresponding angle in radians. This is a scalar if x is a scalar. See also rad2deg Convert angles from radians to degrees. unwrap Remove large jumps in angle by wrapping. Notes New in version 1.3.0. deg2rad(x) is x * pi / 180. Examples >>> np.deg2rad(180) 3.1415926535897931", "score": "0.68979716"}, {"id": "18480", "text": "Function: python.library.cmath#cmath.polar\nSnippet: cmath.polar(x) Return the representation of x in polar coordinates. Returns a pair (r, phi) where r is the modulus of x and phi is the phase of x. polar(x) is equivalent to (abs(x), phase(x)).", "score": "0.6896436"}]}
{"task_id": 591, "text": "Write a python function to interchange the first and last elements in a list.", "code": "def swap_List(newList): \r\n    size = len(newList) \r\n    temp = newList[0] \r\n    newList[0] = newList[size - 1] \r\n    newList[size - 1] = temp  \r\n    return newList ", "test_list": ["assert swap_List([12, 35, 9, 56, 24]) == [24, 35, 9, 56, 12]", "assert swap_List([1, 2, 3]) == [3, 2, 1]", "assert swap_List([4, 5, 6]) == [6, 5, 4]"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18679", "text": "Function: python.library.collections#collections.OrderedDict.move_to_end\nSnippet: move_to_end(key, last=True) Move an existing key to either end of an ordered dictionary. The item is moved to the right end if last is true (the default) or to the beginning if last is false. Raises KeyError if the key does not exist: >>> d = OrderedDict.fromkeys('abcde') >>> d.move_to_end('b') >>> ''.join(d.keys()) 'acdeb' >>> d.move_to_end('b', last=False) >>> ''.join(d.keys()) 'bacde' New in version 3.2.", "score": "0.6911365"}, {"id": "18248", "text": "Function: python.library.bisect#bisect.insort_right\nSnippet: bisect.insort_right(a, x, lo=0, hi=len(a)) bisect.insort(a, x, lo=0, hi=len(a)) Similar to insort_left(), but inserting x in a after any existing entries of x.", "score": "0.68452275"}, {"id": "15772", "text": "Function: pandas.reference.api.pandas.tseries.offsets.byearend.n\nSnippet: pandas.tseries.offsets.BYearEnd.n BYearEnd.n", "score": "0.67861396"}, {"id": "25738", "text": "Function: python.library.stdtypes\nSnippet: from s (2) s.remove(x) remove the first item from s where s[i] is equal to x (3) s.reverse() reverses the items of s in place (4) Notes: t must have the same length as the slice it is replacing. The optional argument i defaults to -1, so that by default the last item is removed and returned. remove() raises ValueError when x is not found in s. The reverse() method modifies the sequence in place for economy of space when reversing a large sequence. To remind users that it operates by side effect, it does not return the reversed sequence. clear() and copy() are included for consistency with the interfaces of mutable containers that don’t support slicing operations (such as dict and set). copy() is not part of the collections.abc.MutableSequence ABC, but most concrete mutable sequence classes provide it. New in version 3.3: clear() and copy() methods. The value n is an integer, or an object implementing __index__(). Zero and negative values of n clear the sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for s * n under Common Sequence Operations. Lists Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application). class list([iterable]) Lists may be constructed in several ways: Using a pair of square brackets to denote the empty list: [] Using square brackets, separating items with commas: [a], [a, b, c] Using a list comprehension: [x for x in iterable] Using the type constructor: list() or list(iterable) The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is made and returned, similar to iterable[:]. For example, list('abc') returns ['a', 'b', 'c'] and list( (1, 2, 3) ) returns [1, 2, 3]. If no argument is given, the constructor creates a new empty list, []. Many other operations also produce lists, including the sorted() built-in. Lists implement all of the common and mutable sequence operations. Lists also provide the following additional method: sort(*, key=None, reverse=False) This method sorts the list in place, using only < comparisons between items. Exceptions are not suppressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state). sort() accepts two arguments that can only be passed by keyword (keyword-only arguments): key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value. The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function. reverse is", "score": "0.67857385"}, {"id": "18246", "text": "Function: python.library.bisect#bisect.insort\nSnippet: bisect.insort_right(a, x, lo=0, hi=len(a)) bisect.insort(a, x, lo=0, hi=len(a)) Similar to insort_left(), but inserting x in a after any existing entries of x.", "score": "0.6781524"}]}
{"task_id": 592, "text": "Write a python function to find sum of product of binomial co-efficients.", "code": "def binomial_Coeff(n,k): \r\n    C = [0] * (k + 1); \r\n    C[0] = 1; # nC0 is 1 \r\n    for i in range(1,n + 1):  \r\n        for j in range(min(i, k),0,-1): \r\n            C[j] = C[j] + C[j - 1]; \r\n    return C[k]; \r\ndef sum_Of_product(n): \r\n    return binomial_Coeff(2 * n,n - 1); ", "test_list": ["assert sum_Of_product(3) == 15", "assert sum_Of_product(4) == 56", "assert sum_Of_product(1) == 1"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.6739446"}, {"id": "21289", "text": "Function: python.library.itertools\nSnippet: AD BB BC BD CC CD DD Itertool functions The following module functions all construct and return iterators. Some provide streams of infinite length, so they should only be accessed by functions or loops that truncate the stream. itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter. itertools.chain(*iterables) Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the", "score": "0.6658808"}, {"id": "21311", "text": "Function: python.library.itertools#itertools.product\nSnippet: itertools.product(*iterables, repeat=1) Cartesian product of input iterables. Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the same as ((x,y) for x in A for y in B). The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in sorted order. To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A). This function is roughly equivalent to the following code, except that the actual implementation does not build up intermediate results in memory: def product(*args, repeat=1): # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111 pools = [tuple(pool) for pool in args] * repeat result = [[]] for pool in pools: result = [x+[y] for x in result for y in pool] for prod in result: yield tuple(prod) Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to generate the products. Accordingly, it is only useful with finite inputs.", "score": "0.6625676"}, {"id": "19451", "text": "Function: python.library.decimal#decimal.Context.add\nSnippet: add(x, y) Return the sum of x and y.", "score": "0.6596716"}, {"id": "19495", "text": "Function: python.library.decimal#decimal.Context.multiply\nSnippet: multiply(x, y) Return the product of x and y.", "score": "0.658859"}]}
{"task_id": 593, "text": "Write a function to remove leading zeroes from an ip address.", "code": "import re\r\ndef removezero_ip(ip):\r\n string = re.sub('\\.[0]*', '.', ip)\r\n return string\r", "test_list": ["assert removezero_ip(\"216.08.094.196\")==('216.8.94.196') ", "assert removezero_ip(\"12.01.024\")==('12.1.24') ", "assert removezero_ip(\"216.08.094.0196\")==('216.8.94.196') "], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "21171", "text": "Function: python.library.ipaddress#ipaddress.IPv4Address.compressed\nSnippet: compressed", "score": "0.71280456"}, {"id": "21221", "text": "Function: python.library.ipaddress#ipaddress.IPv6Address.compressed\nSnippet: compressed", "score": "0.70423263"}, {"id": "21172", "text": "Function: python.library.ipaddress#ipaddress.IPv4Address.exploded\nSnippet: exploded The string representation in dotted decimal notation. Leading zeroes are never included in the representation. As IPv4 does not define a shorthand notation for addresses with octets set to zero, these two attributes are always the same as str(addr) for IPv4 addresses. Exposing these attributes makes it easier to write display code that can handle both IPv4 and IPv6 addresses.", "score": "0.703376"}, {"id": "21264", "text": "Function: python.library.ipaddress#ipaddress.IPv6Network.num_addresses\nSnippet: num_addresses", "score": "0.6998831"}, {"id": "21238", "text": "Function: python.library.ipaddress#ipaddress.IPv6Address.version\nSnippet: version", "score": "0.6974308"}]}
{"task_id": 594, "text": "Write a function to find the difference of first even and odd number of a given list.", "code": "def diff_even_odd(list1):\r\n    first_even = next((el for el in list1 if el%2==0),-1)\r\n    first_odd = next((el for el in list1 if el%2!=0),-1)\r\n    return (first_even-first_odd)", "test_list": ["assert diff_even_odd([1,3,5,7,4,1,6,8])==3", "assert diff_even_odd([1,2,3,4,5,6,7,8,9,10])==1", "assert diff_even_odd([1,5,7,9,10])==9"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "25736", "text": "Function: python.library.stdtypes\nSnippet: s.index(x[, i[, j]]) index of the first occurrence of x in s (at or after index i and before index j) (8) s.count(x) total number of occurrences of x in s Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see Comparisons in the language reference.) Notes: While the in and not in operations are used only for simple containment testing in the general case, some specialised sequences (such as str, bytes and bytearray) also use them for subsequence testing: >>> \"gg\" in \"eggs\" True Values of n less than 0 are treated as 0 (which yields an empty sequence of the same type as s). Note that items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python programmers; consider: >>> lists = [[]] * 3 >>> lists [[], [], []] >>> lists[0].append(3) >>> lists [[3], [3], [3]] What has happened is that [[]] is a one-element list containing an empty list, so all three elements of [[]] * 3 are references to this single empty list. Modifying any of the elements of lists modifies this single list. You can create a list of different lists this way: >>> lists = [[] for i in range(3)] >>> lists[0].append(3) >>> lists[1].append(5) >>> lists[2].append(7) >>> lists [[3], [5], [7]] Further explanation is available in the FAQ entry How do I create a multidimensional list?. If i or j is negative, the index is relative to the end of sequence s: len(s) + i or len(s) + j is substituted. But note that -0 is still 0. The slice of s from i to j is defined as the sequence of items with index k such that i <= k < j. If i or j is greater than len(s), use len(s). If i is omitted or None, use 0. If j is omitted or None, use len(s). If i is greater than or equal to j, the slice is empty. The slice of s from i to j with step k is defined as the sequence of items with index x = i + n*k such that 0 <= n < (j-i)/k. In other words, the indices are i, i+k, i+2*k, i+3*k and so on, stopping when j is reached (but never including j). When k is positive, i and j are reduced to len(s) if they are greater. When k is negative, i and j are reduced to len(s) - 1 if they are greater. If i or j are omitted or None, they become “end” values (which end depends on the sign of k). Note, k cannot be zero. If k is None, it is treated like 1. Concatenating immutable sequences always results in a new object. This means that building up", "score": "0.671974"}, {"id": "42129", "text": "Function: numpy.reference.generated.numpy.ma.ediff1d\nSnippet: numpy.ma.ediff1d ma.ediff1d(arr, to_end=None, to_begin=None)[source] Compute the differences between consecutive elements of an array. This function is the equivalent of numpy.ediff1d that takes masked values into account, see numpy.ediff1d for details. See also numpy.ediff1d Equivalent function for ndarrays.", "score": "0.66405255"}, {"id": "22322", "text": "Function: python.library.operator#operator.indexOf\nSnippet: operator.indexOf(a, b) Return the index of the first of occurrence of b in a.", "score": "0.6618965"}, {"id": "19627", "text": "Function: python.library.difflib\nSnippet: describing non-overlapping matching subsequences. Each triple is of the form (i, j, n), and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j. The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks. >>> s = SequenceMatcher(None, \"abxcd\", \"abcd\") >>> s.get_matching_blocks() [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)] get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f' get_grouped_opcodes(n=3) Return a generator of groups with up to n lines of context. Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes. The groups are returned in the same format as get_opcodes(). ratio() Return a measure of the sequences’ similarity as a float in the range [0, 1]. Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common. This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound. Note Caution: The result of a ratio() call may depend on the order of the arguments. For instance: >>> SequenceMatcher(None, 'tide', 'diet').ratio() 0.25 >>> SequenceMatcher(None, 'diet', 'tide').ratio() 0.5 quick_ratio() Return an upper bound on ratio() relatively quickly. real_quick_ratio() Return an upper bound on ratio() very quickly. The three methods that return the ratio of matching to total characters can give different results due to differing levels of approximation, although quick_ratio() and real_quick_ratio() are always at least", "score": "0.6618141"}, {"id": "19629", "text": "Function: python.library.difflib\nSnippet: of file-like objects): >>> text1 = ''' 1. Beautiful is better than ugly. ... 2. Explicit is better than implicit. ... 3. Simple is better than complex. ... 4. Complex is better than complicated. ... '''.splitlines(keepends=True) >>> len(text1) 4 >>> text1[0][-1] '\\n' >>> text2 = ''' 1. Beautiful is better than ugly. ... 3. Simple is better than complex. ... 4. Complicated is better than complex. ... 5. Flat is better than nested. ... '''.splitlines(keepends=True) Next we instantiate a Differ object: >>> d = Differ() Note that when instantiating a Differ object we may pass functions to filter out line and character “junk.” See the Differ() constructor for details. Finally, we compare the two: >>> result = list(d.compare(text1, text2)) result is a list of strings, so let’s pretty-print it: >>> from pprint import pprint >>> pprint(result) [' 1. Beautiful is better than ugly.\\n', '- 2. Explicit is better than implicit.\\n', '- 3. Simple is better than complex.\\n', '+ 3. Simple is better than complex.\\n', '? ++\\n', '- 4. Complex is better than complicated.\\n', '? ^ ---- ^\\n', '+ 4. Complicated is better than complex.\\n', '? ++++ ^ ^\\n', '+ 5. Flat is better than nested.\\n'] As a single multi-line string it looks like this: >>> import sys >>> sys.stdout.writelines(result) 1. Beautiful is better than ugly. - 2. Explicit is better than implicit. - 3. Simple is better than complex. + 3. Simple is better than complex. ? ++ - 4. Complex is better than complicated. ? ^ ---- ^ + 4. Complicated is better than complex. ? ++++ ^ ^ + 5. Flat is better than nested. A command-line interface to difflib This example shows how to use difflib to create a diff-like utility. It is also contained in the Python source distribution, as Tools/scripts/diff.py. #!/usr/bin/env python3 \"\"\" Command line interface to difflib.py providing diffs in four formats: * ndiff: lists every line and highlights interline changes. * context: highlights clusters of changes in a before/after format. * unified: highlights clusters of changes in an inline format. * html: generates side by side comparison with change highlights. \"\"\" import sys, os, difflib, argparse from datetime import datetime, timezone def file_mtime(path): t = datetime.fromtimestamp(os.stat(path).st_mtime, timezone.utc) return t.astimezone().isoformat() def main(): parser = argparse.ArgumentParser() parser.add_argument('-c', action='store_true', default=False, help='Produce a context format diff (default)') parser.add_argument('-u', action='store_true', default=False, help='Produce a unified format diff') parser.add_argument('-m', action='store_true', default=False, help='Produce HTML side by side diff ' '(can use -c and -l in conjunction)') parser.add_argument('-n', action='store_true', default=False, help='Produce a ndiff format diff') parser.add_argument('-l', '--lines', type=int, default=3, help='Set number of context lines (default 3)') parser.add_argument('fromfile') parser.add_argument('tofile') options = parser.parse_args() n = options.lines fromfile = options.fromfile tofile = options.tofile fromdate = file_mtime(fromfile) todate = file_mtime(tofile) with open(fromfile) as ff: fromlines = ff.readlines() with open(tofile) as tf: tolines = tf.readlines() if options.u: diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n) elif options.n: diff = difflib.ndiff(fromlines, tolines) elif options.m: diff = difflib.HtmlDiff().make_file(fromlines,tolines,fromfile,tofile,context=options.c,numlines=n) else: diff = difflib.context_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n) sys.stdout.writelines(diff) if __name__ == '__main__': main()", "score": "0.6603446"}]}
{"task_id": 595, "text": "Write a python function to count minimum number of swaps required to convert one binary string to another.", "code": "def min_Swaps(str1,str2) : \r\n    count = 0\r\n    for i in range(len(str1)) :  \r\n        if str1[i] != str2[i] : \r\n            count += 1\r\n    if count % 2 == 0 : \r\n        return (count // 2) \r\n    else : \r\n        return (\"Not Possible\") ", "test_list": ["assert min_Swaps(\"1101\",\"1110\") == 1", "assert min_Swaps(\"111\",\"000\") == \"Not Possible\"", "assert min_Swaps(\"111\",\"110\") == \"Not Possible\""], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "18295", "text": "Function: python.library.stdtypes#bytearray.swapcase\nSnippet: bytes.swapcase() bytearray.swapcase() Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart and vice-versa. For example: >>> b'Hello World'.swapcase() b'hELLO wORLD' Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'. Unlike str.swapcase(), it is always the case that bin.swapcase().swapcase() == bin for the binary versions. Case conversions are symmetrical in ASCII, even though that is not generally true for arbitrary Unicode code points. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "score": "0.73078936"}, {"id": "18339", "text": "Function: python.library.stdtypes#bytes.swapcase\nSnippet: bytes.swapcase() bytearray.swapcase() Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart and vice-versa. For example: >>> b'Hello World'.swapcase() b'hELLO wORLD' Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'. Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'. Unlike str.swapcase(), it is always the case that bin.swapcase().swapcase() == bin for the binary versions. Case conversions are symmetrical in ASCII, even though that is not generally true for arbitrary Unicode code points. Note The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.", "score": "0.7278477"}, {"id": "24381", "text": "Function: python.library.stdtypes#str.swapcase\nSnippet: str.swapcase() Return a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is not necessarily true that s.swapcase().swapcase() == s.", "score": "0.70425975"}, {"id": "19649", "text": "Function: python.library.difflib#difflib.SequenceMatcher.get_opcodes\nSnippet: get_opcodes() Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2). The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2. The tag values are strings, with these meanings: Value Meaning 'replace' a[i1:i2] should be replaced by b[j1:j2]. 'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal). For example: >>> a = \"qabxcd\" >>> b = \"abycdf\" >>> s = SequenceMatcher(None, a, b) >>> for tag, i1, i2, j1, j2 in s.get_opcodes(): ... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2])) delete a[0:1] --> b[0:0] 'q' --> '' equal a[1:3] --> b[0:2] 'ab' --> 'ab' replace a[3:4] --> b[2:3] 'x' --> 'y' equal a[4:6] --> b[3:5] 'cd' --> 'cd' insert a[6:6] --> b[5:6] '' --> 'f'", "score": "0.7026436"}, {"id": "20478", "text": "Function: python.library.heapq\nSnippet: key function of one argument that is used to extract a comparison key from each input element. The default value is None (compare the elements directly). reverse is a boolean value. If set to True, then the input elements are merged as if each comparison were reversed. To achieve behavior similar to sorted(itertools.chain(*iterables), reverse=True), all iterables must be sorted from largest to smallest. Changed in version 3.5: Added the optional key and reverse parameters. heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n]. heapq.nsmallest(n, iterable, key=None) Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key)[:n]. The latter two functions perform best for smaller values of n. For larger values, it is more efficient to use the sorted() function. Also, when n==1, it is more efficient to use the built-in min() and max() functions. If repeated usage of these functions is required, consider turning the iterable into an actual heap. Basic Examples A heapsort can be implemented by pushing all values onto a heap and then popping off the smallest values one at a time: >>> def heapsort(iterable): ... h = [] ... for value in iterable: ... heappush(h, value) ... return [heappop(h) for i in range(len(h))] ... >>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0]) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] This is similar to sorted(iterable), but unlike sorted(), this implementation is not stable. Heap elements can be tuples. This is useful for assigning comparison values (such as task priorities) alongside the main record being tracked: >>> h = [] >>> heappush(h, (5, 'write code')) >>> heappush(h, (7, 'release product')) >>> heappush(h, (1, 'write spec')) >>> heappush(h, (3, 'create tests')) >>> heappop(h) (1, 'write spec') Priority Queue Implementation Notes A priority queue is common use for a heap, and it presents several implementation challenges: Sort stability: how do you get two tasks with equal priorities to be returned in the order they were originally added? Tuple comparison breaks for (priority, task) pairs if the priorities are equal and the tasks do not have a default comparison order. If the priority of a task changes, how do you move it to a new position in the heap? Or if a pending task needs to be deleted, how do you find it and remove it from the queue? A solution to the first two challenges is to store entries as 3-element list including the priority, an entry count, and the task. The entry count serves as a tie-breaker so that two tasks with the same priority are returned in the order they were", "score": "0.70002043"}]}
{"task_id": 596, "text": "Write a function to find the size of the given tuple.", "code": "import sys \r\ndef tuple_size(tuple_list):\r\n  return (sys.getsizeof(tuple_list)) ", "test_list": ["assert tuple_size((\"A\", 1, \"B\", 2, \"C\", 3) ) == sys.getsizeof((\"A\", 1, \"B\", 2, \"C\", 3))", "assert tuple_size((1, \"Raju\", 2, \"Nikhil\", 3, \"Deepanshu\") ) == sys.getsizeof((1, \"Raju\", 2, \"Nikhil\", 3, \"Deepanshu\"))", "assert tuple_size(((1, \"Lion\"), ( 2, \"Tiger\"), (3, \"Fox\"), (4, \"Wolf\"))  ) == sys.getsizeof(((1, \"Lion\"), ( 2, \"Tiger\"), (3, \"Fox\"), (4, \"Wolf\")))"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "24790", "text": "Function: python.library.tarfile#tarfile.TarInfo.size\nSnippet: TarInfo.size Size in bytes.", "score": "0.71910036"}, {"id": "19005", "text": "Function: python.library.ctypes#ctypes.sizeof\nSnippet: ctypes.sizeof(obj_or_type) Returns the size in bytes of a ctypes type or instance memory buffer. Does the same as the C sizeof operator.", "score": "0.7135558"}, {"id": "18444", "text": "Function: python.library.chunk#chunk.Chunk.getsize\nSnippet: getsize() Returns the size of the chunk.", "score": "0.7125776"}, {"id": "42010", "text": "Function: numpy.reference.generated.numpy.generic.size\nSnippet: numpy.generic.size attribute generic.size The number of elements in the gentype.", "score": "0.7086815"}, {"id": "25567", "text": "Function: python.library.tracemalloc#tracemalloc.Statistic.size\nSnippet: size Total size of memory blocks in bytes (int).", "score": "0.7041296"}]}
{"task_id": 597, "text": "Write a function to find kth element from the given two sorted arrays.", "code": "def find_kth(arr1, arr2, m, n, k):\r\n\tsorted1 = [0] * (m + n)\r\n\ti = 0\r\n\tj = 0\r\n\td = 0\r\n\twhile (i < m and j < n):\r\n\t\tif (arr1[i] < arr2[j]):\r\n\t\t\tsorted1[d] = arr1[i]\r\n\t\t\ti += 1\r\n\t\telse:\r\n\t\t\tsorted1[d] = arr2[j]\r\n\t\t\tj += 1\r\n\t\td += 1\r\n\twhile (i < m):\r\n\t\tsorted1[d] = arr1[i]\r\n\t\td += 1\r\n\t\ti += 1\r\n\twhile (j < n):\r\n\t\tsorted1[d] = arr2[j]\r\n\t\td += 1\r\n\t\tj += 1\r\n\treturn sorted1[k - 1]", "test_list": ["assert find_kth([2, 3, 6, 7, 9], [1, 4, 8, 10], 5, 4, 5) == 6", "assert find_kth([100, 112, 256, 349, 770], [72, 86, 113, 119, 265, 445, 892], 5, 7, 7) == 256", "assert find_kth([3, 4, 7, 8, 10], [2, 5, 9, 11], 5, 4, 6) == 8"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "20488", "text": "Function: python.library.heapq#heapq.nlargest\nSnippet: heapq.nlargest(n, iterable, key=None) Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a function of one argument that is used to extract a comparison key from each element in iterable (for example, key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n].", "score": "0.672662"}, {"id": "43864", "text": "Function: numpy.reference.generated.numpy.recarray.partition\nSnippet: numpy.recarray.partition method recarray.partition(kth, axis=- 1, kind='introselect', order=None) Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. All elements smaller than the kth element are moved before this element and all equal or greater are moved behind it. The ordering of the elements in the two partitions is undefined. New in version 1.8.0. Parameters kthint or sequence of ints Element index to partition by. The kth element value will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of kth it will partition all elements indexed by kth of them into their sorted position at once. Deprecated since version 1.22.0: Passing booleans as index is deprecated. axisint, optional Axis along which to sort. Default is -1, which means sort along the last axis. kind{‘introselect’}, optional Selection algorithm. Default is ‘introselect’. orderstr or list of str, optional When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need to be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties. See also numpy.partition Return a parititioned copy of an array. argpartition Indirect partition. sort Full sort. Notes See np.partition for notes on the different algorithms. Examples >>> a = np.array([3, 4, 2, 1]) >>> a.partition(3) >>> a array([2, 1, 3, 4]) >>> a.partition((1, 3)) >>> a array([1, 2, 3, 4])", "score": "0.6689513"}, {"id": "42414", "text": "Function: numpy.reference.generated.numpy.matrix.partition\nSnippet: numpy.matrix.partition method matrix.partition(kth, axis=- 1, kind='introselect', order=None) Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. All elements smaller than the kth element are moved before this element and all equal or greater are moved behind it. The ordering of the elements in the two partitions is undefined. New in version 1.8.0. Parameters kthint or sequence of ints Element index to partition by. The kth element value will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of kth it will partition all elements indexed by kth of them into their sorted position at once. Deprecated since version 1.22.0: Passing booleans as index is deprecated. axisint, optional Axis along which to sort. Default is -1, which means sort along the last axis. kind{‘introselect’}, optional Selection algorithm. Default is ‘introselect’. orderstr or list of str, optional When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need to be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties. See also numpy.partition Return a parititioned copy of an array. argpartition Indirect partition. sort Full sort. Notes See np.partition for notes on the different algorithms. Examples >>> a = np.array([3, 4, 2, 1]) >>> a.partition(3) >>> a array([2, 1, 3, 4]) >>> a.partition((1, 3)) >>> a array([1, 2, 3, 4])", "score": "0.66714454"}, {"id": "42550", "text": "Function: numpy.reference.generated.numpy.ndarray.partition\nSnippet: numpy.ndarray.partition method ndarray.partition(kth, axis=- 1, kind='introselect', order=None) Rearranges the elements in the array in such a way that the value of the element in kth position is in the position it would be in a sorted array. All elements smaller than the kth element are moved before this element and all equal or greater are moved behind it. The ordering of the elements in the two partitions is undefined. New in version 1.8.0. Parameters kthint or sequence of ints Element index to partition by. The kth element value will be in its final sorted position and all smaller elements will be moved before it and all equal or greater elements behind it. The order of all elements in the partitions is undefined. If provided with a sequence of kth it will partition all elements indexed by kth of them into their sorted position at once. Deprecated since version 1.22.0: Passing booleans as index is deprecated. axisint, optional Axis along which to sort. Default is -1, which means sort along the last axis. kind{‘introselect’}, optional Selection algorithm. Default is ‘introselect’. orderstr or list of str, optional When a is an array with fields defined, this argument specifies which fields to compare first, second, etc. A single field can be specified as a string, and not all fields need to be specified, but unspecified fields will still be used, in the order in which they come up in the dtype, to break ties. See also numpy.partition Return a parititioned copy of an array. argpartition Indirect partition. sort Full sort. Notes See np.partition for notes on the different algorithms. Examples >>> a = np.array([3, 4, 2, 1]) >>> a.partition(3) >>> a array([2, 1, 3, 4]) >>> a.partition((1, 3)) >>> a array([1, 2, 3, 4])", "score": "0.6653989"}, {"id": "43258", "text": "Function: numpy.reference.generated.numpy.union1d\nSnippet: numpy.union1d numpy.union1d(ar1, ar2)[source] Find the union of two arrays. Return the unique, sorted array of values that are in either of the two input arrays. Parameters ar1, ar2array_like Input arrays. They are flattened if they are not already 1D. Returns union1dndarray Unique, sorted union of the input arrays. See also numpy.lib.arraysetops Module with a number of other functions for performing set operations on arrays. Examples >>> np.union1d([-1, 0, 1], [-2, 0, 2]) array([-2, -1, 0, 1, 2]) To find the union of more than two arrays, use functools.reduce: >>> from functools import reduce >>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2])) array([1, 2, 3, 4, 6])", "score": "0.6616556"}]}
{"task_id": 598, "text": "Write a function to check whether the given number is armstrong or not.", "code": "def armstrong_number(number):\r\n sum = 0\r\n times = 0\r\n temp = number\r\n while temp > 0:\r\n           times = times + 1\r\n           temp = temp // 10\r\n temp = number\r\n while temp > 0:\r\n           reminder = temp % 10\r\n           sum = sum + (reminder ** times)\r\n           temp //= 10\r\n if number == sum:\r\n           return True\r\n else:\r\n           return False", "test_list": ["assert armstrong_number(153)==True", "assert armstrong_number(259)==False", "assert armstrong_number(4458)==False"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "14026", "text": "Function: pandas.reference.api.pandas.api.types.is_number\nSnippet: pandas.api.types.is_number pandas.api.types.is_number(obj)[source] Check if the object is a number. Returns True when the object is a number, and False if is not. Parameters obj:any type The object to check if is a number. Returns is_number:bool Whether obj is a number or not. See also api.types.is_integer Checks a subgroup of numbers. Examples >>> from pandas.api.types import is_number >>> is_number(1) True >>> is_number(7.15) True Booleans are valid because they are int subclass. >>> is_number(False) True >>> is_number(\"foo\") False >>> is_number(\"5\") False", "score": "0.6622959"}, {"id": "22329", "text": "Function: python.library.operator#operator.is_\nSnippet: operator.is_(a, b) Return a is b. Tests object identity.", "score": "0.6598095"}, {"id": "21811", "text": "Function: python.library.math#math.isnan\nSnippet: math.isnan(x) Return True if x is a NaN (not a number), and False otherwise.", "score": "0.6531653"}, {"id": "14037", "text": "Function: pandas.reference.api.pandas.api.types.is_timedelta64_ns_dtype\nSnippet: pandas.api.types.is_timedelta64_ns_dtype pandas.api.types.is_timedelta64_ns_dtype(arr_or_dtype)[source] Check whether the provided array or dtype is of the timedelta64[ns] dtype. This is a very specific dtype, so generic ones like np.timedelta64 will return False if passed into this function. Parameters arr_or_dtype:array-like or dtype The array or dtype to check. Returns boolean Whether or not the array or dtype is of the timedelta64[ns] dtype. Examples >>> is_timedelta64_ns_dtype(np.dtype('m8[ns]')) True >>> is_timedelta64_ns_dtype(np.dtype('m8[ps]')) # Wrong frequency False >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype='m8[ns]')) True >>> is_timedelta64_ns_dtype(np.array([1, 2], dtype=np.timedelta64)) False", "score": "0.6430899"}, {"id": "21810", "text": "Function: python.library.math#math.isinf\nSnippet: math.isinf(x) Return True if x is a positive or negative infinity, and False otherwise.", "score": "0.6408837"}]}
{"task_id": 599, "text": "Write a function to find sum and average of first n natural numbers.", "code": "def sum_average(number):\r\n total = 0\r\n for value in range(1, number + 1):\r\n    total = total + value\r\n average = total / number\r\n return (total,average)", "test_list": ["assert sum_average(10)==(55, 5.5)", "assert sum_average(15)==(120, 8.0)", "assert sum_average(20)==(210, 10.5)"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "42657", "text": "Function: numpy.reference.generated.numpy.average\nSnippet: >>> avg = np.average(a, weights=w) >>> print(avg.dtype) complex256", "score": "0.66999334"}, {"id": "21298", "text": "Function: python.library.itertools#itertools.accumulate\nSnippet: itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter.", "score": "0.66663843"}, {"id": "24549", "text": "Function: python.library.functions#sum\nSnippet: sum(iterable, /, start=0) Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally numbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of strings is by calling ''.join(sequence). To add floating point values with extended precision, see math.fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument.", "score": "0.6566581"}, {"id": "21289", "text": "Function: python.library.itertools\nSnippet: AD BB BC BD CC CD DD Itertool functions The following module functions all construct and return iterators. Some provide streams of infinite length, so they should only be accessed by functions or loops that truncate the stream. itertools.accumulate(iterable[, func, *, initial=None]) Make an iterator that returns accumulated sums, or accumulated results of other binary functions (specified via the optional func argument). If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.) Usually, the number of elements output matches the input iterable. However, if the keyword argument initial is provided, the accumulation leads off with the initial value so that the output has one more element than the input iterable. Roughly equivalent to: def accumulate(iterable, func=operator.add, *, initial=None): 'Return running totals' # accumulate([1,2,3,4,5]) --> 1 3 6 10 15 # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120 it = iter(iterable) total = initial if initial is None: try: total = next(it) except StopIteration: return yield total for element in it: total = func(total, element) yield total There are a number of uses for the func argument. It can be set to min() for a running minimum, max() for a running maximum, or operator.mul() for a running product. Amortization tables can be built by accumulating interest and applying payments. First-order recurrence relations can be modeled by supplying the initial value in the iterable and using only the accumulated total in func argument: >>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8] >>> list(accumulate(data, operator.mul)) # running product [3, 12, 72, 144, 144, 1296, 0, 0, 0, 0] >>> list(accumulate(data, max)) # running maximum [3, 4, 6, 6, 6, 9, 9, 9, 9, 9] # Amortize a 5% loan of 1000 with 4 annual payments of 90 >>> cashflows = [1000, -90, -90, -90, -90] >>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt)) [1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001] # Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map >>> logistic_map = lambda x, _: r * x * (1 - x) >>> r = 3.8 >>> x0 = 0.4 >>> inputs = repeat(x0, 36) # only the initial value is used >>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)] ['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63', '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57', '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32', '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60'] See functools.reduce() for a similar function that returns only the final accumulated value. New in version 3.2. Changed in version 3.3: Added the optional func parameter. Changed in version 3.8: Added the optional initial parameter. itertools.chain(*iterables) Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next iterable, until all of the", "score": "0.6487858"}, {"id": "42656", "text": "Function: numpy.reference.generated.numpy.average\nSnippet: numpy.average numpy.average(a, axis=None, weights=None, returned=False)[source] Compute the weighted average along the specified axis. Parameters aarray_like Array containing data to be averaged. If a is not an array, a conversion is attempted. axisNone or int or tuple of ints, optional Axis or axes along which to average a. The default, axis=None, will average over all of the elements of the input array. If axis is negative it counts from the last to the first axis. New in version 1.7.0. If axis is a tuple of ints, averaging is performed on all of the axes specified in the tuple instead of a single axis or all the axes as before. weightsarray_like, optional An array of weights associated with the values in a. Each value in a contributes to the average according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as a. If weights=None, then all data in a are assumed to have a weight equal to one. The 1-D calculation is: avg = sum(a * weights) / sum(weights) The only constraint on weights is that sum(weights) must not be 0. returnedbool, optional Default is False. If True, the tuple (average, sum_of_weights) is returned, otherwise only the average is returned. If weights=None, sum_of_weights is equivalent to the number of elements over which the average is taken. Returns retval, [sum_of_weights]array_type or double Return the average along the specified axis. When returned is True, return a tuple with the average as the first element and the sum of the weights as the second element. sum_of_weights is of the same type as retval. The result dtype follows a genereal pattern. If weights is None, the result dtype will be that of a , or float64 if a is integral. Otherwise, if weights is not None and a is non- integral, the result type will be the type of lowest precision capable of representing values of both a and weights. If a happens to be integral, the previous rules still applies but the result dtype will at least be float64. Raises ZeroDivisionError When all weights along axis are zero. See numpy.ma.average for a version robust to this type of error. TypeError When the length of 1D weights is not the same as the shape of a along axis. See also mean ma.average average for masked arrays – useful if your data contains “missing” values numpy.result_type Returns the type that results from applying the numpy type promotion rules to the arguments. Examples >>> data = np.arange(1, 5) >>> data array([1, 2, 3, 4]) >>> np.average(data) 2.5 >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1)) 4.0 >>> data = np.arange(6).reshape((3,2)) >>> data array([[0, 1], [2, 3], [4, 5]]) >>> np.average(data, axis=1, weights=[1./4, 3./4]) array([0.75, 2.75, 4.75]) >>> np.average(data, weights=[1./4, 3./4]) Traceback (most recent call last): ... TypeError: Axis must be specified when shapes of a and weights differ. >>> a = np.ones(5, dtype=np.float128) >>> w = np.ones(5, dtype=np.complex64)", "score": "0.64150906"}]}
{"task_id": 600, "text": "Write a python function to check whether the given number is even or not using bitwise operator.", "code": "def is_Even(n) : \r\n    if (n^1 == n+1) :\r\n        return True; \r\n    else :\r\n        return False; ", "test_list": ["assert is_Even(1) == False", "assert is_Even(2) == True", "assert is_Even(3) == False"], "test_setup_code": "", "challenge_test_list": [], "ctxs": [{"id": "22345", "text": "Function: python.library.operator#operator.or_\nSnippet: operator.or_(a, b) operator.__or__(a, b) Return the bitwise or of a and b.", "score": "0.7143816"}, {"id": "22391", "text": "Function: python.library.operator#operator.__or__\nSnippet: operator.or_(a, b) operator.__or__(a, b) Return the bitwise or of a and b.", "score": "0.71149874"}, {"id": "19597", "text": "Function: python.library.decimal#decimal.ROUND_HALF_EVEN\nSnippet: decimal.ROUND_HALF_EVEN Round to nearest with ties going to nearest even integer.", "score": "0.6970305"}, {"id": "42664", "text": "Function: numpy.reference.generated.numpy.bitwise_or\nSnippet: numpy.bitwise_or numpy.bitwise_or(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'bitwise_or'> Compute the bit-wise OR of two arrays element-wise. Computes the bit-wise OR of the underlying binary representation of the integers in the input arrays. This ufunc implements the C/Python operator |. Parameters x1, x2array_like Only integer and boolean types are handled. If x1.shape != x2.shape, they must be broadcastable to a common shape (which becomes the shape of the output). outndarray, None, or tuple of ndarray and None, optional A location into which the result is stored. If provided, it must have a shape that the inputs broadcast to. If not provided or None, a freshly-allocated array is returned. A tuple (possible only as a keyword argument) must have length equal to the number of outputs. wherearray_like, optional This condition is broadcast over the input. At locations where the condition is True, the out array will be set to the ufunc result. Elsewhere, the out array will retain its original value. Note that if an uninitialized out array is created via the default out=None, locations within it where the condition is False will remain uninitialized. **kwargs For other keyword-only arguments, see the ufunc docs. Returns outndarray or scalar Result. This is a scalar if both x1 and x2 are scalars. See also logical_or bitwise_and bitwise_xor binary_repr Return the binary representation of the input number as a string. Examples The number 13 has the binary representation 00001101. Likewise, 16 is represented by 00010000. The bit-wise OR of 13 and 16 is then 000111011, or 29: >>> np.bitwise_or(13, 16) 29 >>> np.binary_repr(29) '11101' >>> np.bitwise_or(32, 2) 34 >>> np.bitwise_or([33, 4], 1) array([33, 5]) >>> np.bitwise_or([33, 4], [1, 2]) array([33, 6]) >>> np.bitwise_or(np.array([2, 5, 255]), np.array([4, 4, 4])) array([ 6, 5, 255]) >>> np.array([2, 5, 255]) | np.array([4, 4, 4]) array([ 6, 5, 255]) >>> np.bitwise_or(np.array([2, 5, 255, 2147483647], dtype=np.int32), ... np.array([4, 4, 4, 2147483647], dtype=np.int32)) array([ 6, 5, 255, 2147483647]) >>> np.bitwise_or([True, True], [False, True]) array([ True, True]) The | operator can be used as a shorthand for np.bitwise_or on ndarrays. >>> x1 = np.array([2, 5, 255]) >>> x2 = np.array([4, 4, 4]) >>> x1 | x2 array([ 6, 5, 255])", "score": "0.6910775"}, {"id": "19436", "text": "Function: python.library.decimal\nSnippet: if x is negative; otherwise returns False. is_snan(x) Returns True if x is a signaling NaN; otherwise returns False. is_subnormal(x) Returns True if x is subnormal; otherwise returns False. is_zero(x) Returns True if x is a zero; otherwise returns False. ln(x) Returns the natural (base e) logarithm of x. log10(x) Returns the base 10 logarithm of x. logb(x) Returns the exponent of the magnitude of the operand’s MSD. logical_and(x, y) Applies the logical operation and between each operand’s digits. logical_invert(x) Invert all the digits in x. logical_or(x, y) Applies the logical operation or between each operand’s digits. logical_xor(x, y) Applies the logical operation xor between each operand’s digits. max(x, y) Compares two values numerically and returns the maximum. max_mag(x, y) Compares the values numerically with their sign ignored. min(x, y) Compares two values numerically and returns the minimum. min_mag(x, y) Compares the values numerically with their sign ignored. minus(x) Minus corresponds to the unary prefix minus operator in Python. multiply(x, y) Return the product of x and y. next_minus(x) Returns the largest representable number smaller than x. next_plus(x) Returns the smallest representable number larger than x. next_toward(x, y) Returns the number closest to x, in direction towards y. normalize(x) Reduces x to its simplest form. number_class(x) Returns an indication of the class of x. plus(x) Plus corresponds to the unary prefix plus operator in Python. This operation applies the context precision and rounding, so it is not an identity operation. power(x, y, modulo=None) Return x to the power of y, reduced modulo modulo if given. With two arguments, compute x**y. If x is negative then y must be integral. The result will be inexact unless y is integral and the result is finite and can be expressed exactly in ‘precision’ digits. The rounding mode of the context is used. Results are always correctly-rounded in the Python version. Decimal(0) ** Decimal(0) results in InvalidOperation, and if InvalidOperation is not trapped, then results in Decimal('NaN'). Changed in version 3.3: The C module computes power() in terms of the correctly-rounded exp() and ln() functions. The result is well-defined but only “almost always correctly-rounded”. With three arguments, compute (x**y) % modulo. For the three argument form, the following restrictions on the arguments hold: all three arguments must be integral y must be nonnegative at least one of x or y must be nonzero modulo must be nonzero and have at most ‘precision’ digits The value resulting from Context.power(x, y, modulo) is equal to the value that would be obtained by computing (x**y) % modulo with unbounded precision, but is computed more efficiently. The exponent of the result is zero, regardless of the exponents of x, y and modulo. The result is always exact. quantize(x, y) Returns a value equal to x (rounded), having the exponent of y. radix() Just returns 10, as this is Decimal, :) remainder(x, y) Returns the remainder from integer division. The sign of the result, if non-zero, is the same as that of the original dividend. remainder_near(x, y) Returns x", "score": "0.68616337"}]}
